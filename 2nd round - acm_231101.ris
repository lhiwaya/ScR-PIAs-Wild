TY  - CONF
TI  - Supporting Privacy Impact Assessment by Model-Based Privacy Analysis
AU  - Ahmadian, Amir Shayan
AU  - Strüber, Daniel
AU  - Riediger, Volker
AU  - Jürjens, Jan
T3  - SAC '18
AB  - According to Article 35 of the General Data Protection Regulation (GDPR), data controllers are obligated to conduct a privacy impact assessment (PIA) to ensure the protection of sensitive data. Failure to properly protect sensitive data may affect data subjects negatively, and damage the reputation of data processors. Existing PIA approaches cannot be easily conducted, since they are mainly abstract or imprecise. Moreover, they lack a methodology to conduct the assessment concerning the design of IT systems. We propose a novel methodology to support PIA by performing model-based privacy and security analyses in the early phases of the system development. In our methodology, the design of a system is analyzed and, where necessary, appropriate security and privacy controls are suggested to improve the design. Hence, this methodology facilitates privacy by design as prescribed in Article 25 of the GDPR. We evaluated our methodology based on three industrial case studies and a quality-based comparison to the state of the art.
C1  - New York, NY, USA
C3  - Proceedings of the 33rd Annual ACM Symposium on Applied Computing
DA  - 2018///
PY  - 2018
DO  - 10.1145/3167132.3167288
SP  - 1467
EP  - 1474
PB  - Association for Computing Machinery
SN  - 978-1-4503-5191-1
UR  - https://doi.org/10.1145/3167132.3167288
KW  - GDPR
KW  - model-based engineering
KW  - privacy
KW  - privacy by design
KW  - privacy impact assessment
ER  - 

TY  - CONF
TI  - Privacy Impact Assessment of Cyber Attacks on Connected and Autonomous Vehicles
AU  - Panda, Sakshyam
AU  - Panaousis, Emmanouil
AU  - Loukas, George
AU  - Kentrotis, Konstantinos
T3  - ARES '23
AB  - Connected and autonomous vehicles (CAVs) are vulnerable to security gaps that can result in serious consequences, including cyber-physical and privacy risks. For example, an attacker can reconstruct a vehicle’s location trajectory by knowing the speed and steering wheel position of the vehicle. Such inferences not only lead to safety issues but also significantly threaten privacy. This paper assesses the privacy impacts of cyber threats on vehicular networks. We augment the Privacy Risk Assessment Methodology (PRAM), proposed by the National Institute of Standards and Technology, with cyber threats, with cyber threats, which are, in practice, mapped to PRAM impact metrics. We demonstrate the practical application of the enhanced PRAM methodology through a use case that highlights attacks leading to privacy risks in CAVs. The consideration of cyber attacks for privacy risk assessment addresses a major gap in current practices, which is to integrate privacy risk into cyber risk management.
C1  - New York, NY, USA
C3  - Proceedings of the 18th International Conference on Availability, Reliability and Security
DA  - 2023///
PY  - 2023
DO  - 10.1145/3600160.3605073
PB  - Association for Computing Machinery
SN  - 9798400707728
UR  - https://doi.org/10.1145/3600160.3605073
KW  - Connected and autonomous vehicles
KW  - Cyber threats
KW  - Privacy risk assessment
ER  - 

TY  - CONF
TI  - Fairness and Data Protection Impact Assessments
AU  - Kasirzadeh, Atoosa
AU  - Clifford, Damian
T3  - AIES '21
AB  - In this paper, we critically examine the effectiveness of the requirement to conduct a Data Protection Impact Assessment (DPIA) in Article 35 of the General Data Protection Regulation (GDPR) in light of fairness metrics. Through this analysis, we explore the role of the fairness principle as introduced in Article 5(1)(a) and its multifaceted interpretation in the obligation to conduct a DPIA. Our paper argues that although there is a significant theoretical role for the considerations of fairness in the DPIA process, an analysis of the various guidance documents issued by data protection authorities on the obligation to conduct a DPIA reveals that they rarely mention the fairness principle in practice. Our analysis questions this omission, and assesses the capacity of fairness metrics to be truly operationalized within DPIAs. We conclude by exploring the practical effectiveness of DPIA with particular reference to (1) technical challenges that have an impact on the usefulness of DPIAs irrespective of a controller's willingness to actively engage in the process, (2) the context dependent nature of the fairness principle, and (3) the key role played by data controllers in the determination of what is fair.
C1  - New York, NY, USA
C3  - Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society
DA  - 2021///
PY  - 2021
DO  - 10.1145/3461702.3462528
SP  - 146
EP  - 153
PB  - Association for Computing Machinery
SN  - 978-1-4503-8473-5
UR  - https://doi.org/10.1145/3461702.3462528
KW  - algorithmic fairness
KW  - data protection impact assessments
KW  - ethics of artificial intelligence
KW  - fairness principle
KW  - general data protection regulation
KW  - regulation of artificial intelligence
ER  - 

TY  - CONF
TI  - Approaching the Data Protection Impact Assessment as a Legal Methodology to Evaluate the Degree of Privacy by Design Achieved in Technological Proposals. A Special Reference to Identity Management Systems
AU  - Timón López, Cristina
AU  - Alamillo Domingo, Ignacio
AU  - Valero Torrijos, Julián
T3  - ARES '21
AB  - The process of digitalization of societies and innovation is involving the fast introduction of new technologies in different sectors. However, the development of technology represents a challenge as it involves technical, legal, economic and social aspects that have to be considered since its conception or design. The aim of this paper is to offer an adaptation of an existing legal methodology, the Data Protection Impact Assessment, as a legal obligation to evaluate technological proposals and assure compliance with privacy by design requirements. For that purpose, we will refer to the specific case of Identity Management technologies. We introduce the main challenges in the sector of Digital Identity Management as well as the importance of covering the “architecture” and “user” sides in the development of safer technologies by citing concrete examples. Finally, in order to provide a more practical view of the methodology to adapt the Data Protection Impact Assessment, we refer to the work developed in the research project OLYMPUS in the evaluation of its privacy implications. By introducing this example, the paper offers a specific methodology directly reusable for the study of technological proposals in IdM but that can be adapted to any other sector.
C1  - New York, NY, USA
C3  - Proceedings of the 16th International Conference on Availability, Reliability and Security
DA  - 2021///
PY  - 2021
DO  - 10.1145/3465481.3469207
PB  - Association for Computing Machinery
SN  - 978-1-4503-9051-4
UR  - https://doi.org/10.1145/3465481.3469207
KW  - Data Protection Impact Assessment
KW  - GDPR
KW  - Identity Management
KW  - Privacy by design
ER  - 

TY  - CONF
TI  - GDPR Compliance in Cybersecurity Software: A Case Study of DPIA in Information Sharing Platform
AU  - Horák, Martin
AU  - Stupka, Václav
AU  - Husák, Martin
T3  - ARES '19
AB  - In this article, we discuss the issues of GDPR's impact on cyber-security software and operations, namely automated information sharing. We illustrate the topic on an example of an intrusion detection alert sharing platform. First, we had to investigate the risks to privacy in the alert sharing platform and ensure its compliance with the GDPR's obligations. Second, fears and uncertainties emerged in the alert sharing community regarding the GDPR and its obligations and, thus, willingness to share the information was negatively impacted. We conducted DPIA to investigate risks related to information sharing in cyber security and dismiss doubts within the community. Although our results suggest that the risks are not high, we point out that the hype around GDPR caused substantial development of the sharing platform. The DPIA helped in a deeper understanding of risks and their management and is a solid argument for information sharing in cyber security under GDPR.
C1  - New York, NY, USA
C3  - Proceedings of the 14th International Conference on Availability, Reliability and Security
DA  - 2019///
PY  - 2019
DO  - 10.1145/3339252.3340516
PB  - Association for Computing Machinery
SN  - 978-1-4503-7164-3
UR  - https://doi.org/10.1145/3339252.3340516
KW  - CSIRT
KW  - GDPR
KW  - Information sharing
KW  - Intrusion detection
KW  - Personal data
KW  - Privacy
ER  - 

TY  - CONF
TI  - Multi-Layered Explanations from Algorithmic Impact Assessments in the GDPR
AU  - Kaminski, Margot E.
AU  - Malgieri, Gianclaudio
T3  - FAT* '20
AB  - Impact assessments have received particular attention on both sides of the Atlantic as a tool for implementing algorithmic accountability. The aim of this paper is to address how Data Protection Impact Assessments (DPIAs) (Art. 35) in the European Union (EU)'s General Data Protection Regulation (GDPR) link the GDPR's two approaches to algorithmic accountability—individual rights and systemic governance— and potentially lead to more accountable and explainable algorithms. We argue that algorithmic explanation should not be understood as a static statement, but as a circular and multi-layered transparency process based on several layers (general information about an algorithm, group-based explanations, and legal justification of individual decisions taken). We argue that the impact assessment process plays a crucial role in connecting internal company heuristics and risk mitigation to outward-facing rights, and in forming the substance of several kinds of explanations.
C1  - New York, NY, USA
C3  - Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency
DA  - 2020///
PY  - 2020
DO  - 10.1145/3351095.3372875
SP  - 68
EP  - 79
PB  - Association for Computing Machinery
SN  - 978-1-4503-6936-7
UR  - https://doi.org/10.1145/3351095.3372875
KW  - general data protection regulation
KW  - impact assessments
KW  - law
ER  - 

TY  - JOUR
TI  - Should Privacy Impact Assessments Be Mandatory?
AU  - Wright, David
T2  - Commun. ACM
AB  - Privacy impact assessments should be integrated into the overall approach to risk management with other strategic planning instruments.This article considers the issue of whether privacy impact assessments (PIAs) should be mandatory. I will examine the benefits and disadvantages of PIAs, the case for and against mandatory PIAs, and ultimately conclude they should be mandatory. Even if they are made mandatory, however, other factors, such as independent audits, must be taken into account to make them truly effective.
DA  - 2011/08//
PY  - 2011
DO  - 10.1145/1978542.1978568
VL  - 54
IS  - 8
SP  - 121
EP  - 131
SN  - 0001-0782
UR  - https://doi.org/10.1145/1978542.1978568
ER  - 

TY  - CONF
TI  - A Systematic Study on the Impact of GDPR Compliance on Organizations
AU  - Machado, Pedro
AU  - Vilela, Jéssyka
AU  - Peixoto, Mariana
AU  - Silva, Carla
T3  - SBSI '23
AB  - Abstract. Context: To achieve compliance with the General Data Protection Regulation (GDPR), organizational changes need to be made. Problem: To perform these changes, it is necessary to understand the challenges faced by organizations to comply with GDPR, as well as the practices they have been adopting to achieve such compliance. Proposed Solution: To provide a preliminary guide to organizations that have not achieved compliance with GDPR yet, this paper presents the results of a study in the literature seeking to identify the areas impacted by GDPR compliance, as well as the challenges faced and practices adopted by organizations in each of the identified areas. IS Theory: This work was conceived under the aegis of Argumentation Theory, presenting information from selected studies on the topic and evidence regarding the conclusions presented. Method: a Systematic Mapping of the Literature was conducted through automatic search in scientific databases seeking for quality papers published from 2018 to 2022 to answer the main research question regarding the impact of GDPR compliance on organizations. Results: The study has found affected areas, challenges faced by organizations and methods, technologies and practices they used to comply with GDPR. Contributions and impacts to the IS area: The results found can be used by other organizations in the same areas that are in the process of compliance with GDPR. In fact, these organizations can benefit from the lessons learned reported in the selected papers and synthesized in this study.
C1  - New York, NY, USA
C3  - Proceedings of the XIX Brazilian Symposium on Information Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3592813.3592935
SP  - 435
EP  - 442
PB  - Association for Computing Machinery
SN  - 9798400707599
UR  - https://doi.org/10.1145/3592813.3592935
KW  - compliance
KW  - GDPR
KW  - impact
KW  - privacy
ER  - 

TY  - CONF
TI  - Governing Algorithmic Systems with Impact Assessments: Six Observations
AU  - Watkins, Elizabeth Anne
AU  - Moss, Emanuel
AU  - Metcalf, Jacob
AU  - Singh, Ranjit
AU  - Elish, Madeleine Clare
T3  - AIES '21
AB  - Algorithmic decision-making and decision-support systems (ADS) are gaining influence over how society distributes resources, administers justice, and provides access to opportunities. Yet collectively we do not adequately study how these systems affect people or document the actual or potential harms resulting from their integration with important social functions. This is a significant challenge for computational justice efforts of measuring and governing AI systems. Impact assessments are often used as instruments to create accountability relationships and grant some measure of agency and voice to communities affected by projects with environmental, financial, and human rights ramifications. Applying these tools-through Algorithmic Impact Assessments (AIA)-is a plausible way to establish accountability relationships for ADSs. At the same time, what an AIA would entail remains under-specified; they raise as many questions as they answer. Choices about the methods, scope, and purpose of AIAs structure the conditions of possibility for AI governance. In this paper, we present our research on the history of impact assessments across diverse domains, through a sociotechnical lens, to present six observations on how they co-constitute accountability. Decisions about what type of effects count as an impact; when impacts are assessed; whose interests are considered; who is invited to participate; who conducts the assessment; how assessments are made publicly available, and what the outputs of the assessment might be; all shape the forms of accountability that AIAs engender. Because AlAs are still an incipient governance strategy, approaching them as social constructions that do not require a single or universal approach offers a chance to produce interventions that emerge from careful deliberation.
C1  - New York, NY, USA
C3  - Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society
DA  - 2021///
PY  - 2021
DO  - 10.1145/3461702.3462580
SP  - 1010
EP  - 1022
PB  - Association for Computing Machinery
SN  - 978-1-4503-8473-5
UR  - https://doi.org/10.1145/3461702.3462580
KW  - accountability
KW  - algorithmic impact assessment
KW  - governance
KW  - harm
KW  - impact
ER  - 

TY  - JOUR
TI  - PARROT: Interactive Privacy-Aware Internet of Things Application Design Tool
AU  - Alhirabi, Nada
AU  - Beaumont, Stephanie
AU  - Llanos, Jose Tomas
AU  - Meedeniya, Dulani
AU  - Rana, Omer
AU  - Perera, Charith
T2  - Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.
AB  - Internet of Things (IoT) applications typically collect and analyse personal data that is categorised as sensitive or special category of personal data. These data are subject to a higher degree of protection under data privacy laws. Regardless of legal requirements to support privacy practices, such as in Privacy by Design (PbD) schemes, these practices are not yet commonly followed by software developers. The difficulty of developing privacy-preserving applications emphasises the importance of exploring the problems developers face to embed privacy techniques, suggesting the need for a supporting tool. An interactive IoT application design tool - PARROT (PrivAcy by design tool foR inteRnet Of Things) - is presented. This tool helps developers to design privacy-aware IoT applications, taking account of privacy compliance during the design process and providing real-time feedback on potential privacy violations. A user study with 18 developers was conducted, comprising a semi-structured interview and a design exercise to understand how developers typically handle privacy within the design process. Collaboration with a privacy lawyer was used to review designs produced by developers to uncover privacy limitations that could be addressed by developing a software tool. Based on the findings, a proof-of-concept prototype of PARROT was implemented and evaluated in two controlled lab studies. The outcome of the study indicates that IoT applications designed with PARROT addressed privacy concerns better and managed to reduce several of the limitations identified. From a privacy compliance perspective, PARROT helps developers to address compliance requirements throughout the design and testing process. This is achieved by incorporating privacy specific design features into the IoT application from the beginning rather than retrospectively. (Demo Video).
DA  - 2023/03//
PY  - 2023
DO  - 10.1145/3580880
VL  - 7
IS  - 1
UR  - https://doi.org/10.1145/3580880
KW  - Data Protection
KW  - Human-centered Methods
KW  - Interactive Tools
KW  - Internet of Things
KW  - IoT Design
KW  - IoT Privacy
KW  - Privacy by Design
KW  - Privacy Laws
KW  - Software Design
KW  - Software Developers
ER  - 

TY  - CONF
TI  - What to Account for When Accounting for Algorithms: A Systematic Literature Review on Algorithmic Accountability
AU  - Wieringa, Maranke
T3  - FAT* '20
AB  - As research on algorithms and their impact proliferates, so do calls for scrutiny/accountability of algorithms. A systematic review of the work that has been done in the field of 'algorithmic accountability' has so far been lacking. This contribution puts forth such a systematic review, following the PRISMA statement. 242 English articles from the period 2008 up to and including 2018 were collected and extracted from Web of Science and SCOPUS, using a recursive query design coupled with computational methods. The 242 articles were prioritized and ordered using affinity mapping, resulting in 93 'core articles' which are presented in this contribution. The recursive search strategy made it possible to look beyond the term 'algorithmic accountability'. That is, the query also included terms closely connected to the theme (e.g. ethics and AI, regulation of algorithms). This approach allows for a perspective not just from critical algorithm studies, but an interdisciplinary overview drawing on material from data studies to law, and from computer science to governance studies. To structure the material, Bovens's widely accepted definition of accountability serves as a focal point. The material is analyzed on the five points Bovens identified as integral to accountability: its arguments on (1) the actor, (2) the forum, (3) the relationship between the two, (3) the content and criteria of the account, and finally (5) the consequences which may result from the account. The review makes three contributions. First, an integration of accountability theory in the algorithmic accountability discussion. Second, a cross-sectoral overview of the that same discussion viewed in light of accountability theory which pays extra attention to accountability risks in algorithmic systems. Lastly, it provides a definition of algorithmic accountability based on accountability theory and algorithmic accountability literature.
C1  - New York, NY, USA
C3  - Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency
DA  - 2020///
PY  - 2020
DO  - 10.1145/3351095.3372833
SP  - 1
EP  - 18
PB  - Association for Computing Machinery
SN  - 978-1-4503-6936-7
UR  - https://doi.org/10.1145/3351095.3372833
KW  - accountability theory
KW  - algorithmic accountability
KW  - algorithmic systems
KW  - data-driven governance
ER  - 

TY  - JOUR
TI  - Assessing Cyber Risk in Cyber-Physical Systems Using the ATT&amp;CK Framework
AU  - Amro, Ahmed
AU  - Gkioulos, Vasileios
AU  - Katsikas, Sokratis
T2  - ACM Trans. Priv. Secur.
AB  - Autonomous transport is receiving increasing attention, with research and development activities already providing prototype implementations. In this article we focus on Autonomous Passenger Ships (APS), which are being considered as a solution for passenger transport across urban waterways. The ambition of the authors has been to examine the safety and security implications of such a Cyber Physical System (CPS), particularly focusing on threats that endanger the passengers and the operational environment of the APS. Accordingly, the article presents a new risk assessment approach based on a Failure Modes Effects and Criticality Analysis (FMECA) that is enriched with selected semantics and components of the MITRE ATT&amp;CK framework, in order to utilize the encoded common knowledge and facilitate the expression of attacks. Then, the proposed approach is demonstrated through conducting a risk assessment for a communication architecture tailored to the requirements of APSs that were proposed in earlier work. Moreover, we propose a group of graph theory-based metrics for estimating the impact of the identified risks. The use of this method has resulted in the identification of risks and their corresponding countermeasures, in addition to identifying risks with limited existing mitigation mechanisms. The benefits of the proposed approach are the comprehensive, atomic, and descriptive nature of the identified threats, which reduce the need for expert judgment, and the granular impact estimation metrics that reduce the impact of bias. All these features are provided in a semi-automated approach to reduce the required effort and collectively are argued to enrich the design-level risk assessment processes with an updatable industry threat model standard, namely ATT&amp;CK.
DA  - 2023/03//
PY  - 2023
DO  - 10.1145/3571733
VL  - 26
IS  - 2
SN  - 2471-2566
UR  - https://doi.org/10.1145/3571733
KW  - autonomous ship
KW  - CK
KW  - Cyber-Physical System
KW  - FMECA
KW  - MITRE ATT&amp
KW  - Risk assessment
KW  - safety and security
ER  - 

TY  - CONF
TI  - Effective and Efficient Privacy Threat Modeling through Domain Refinements
AU  - Wuyts, Kim
AU  - Van Landuyt, Dimitri
AU  - Hovsepyan, Aram
AU  - Joosen, Wouter
T3  - SAC '18
AB  - Privacy and security are crosscutting in the design of any software system or service, and thus a broad focus on the end-to-end system architecture is required. For this reason, systematic approaches to elicitate security and privacy threats and risks are gaining importance. Such approaches however are highly analytic, require substantial effort and rely extensively on domain expertise. Applying these methods in practice easily leads to the problem of threat explosion, where the effort required to prioritize and consider all threats starts exceeding the benefits of adopting these methods.To address this impediment to practical adoption, we present our approach to improve LINDDUN, an existing privacy engineering method. We create a domain refinement questionnaire, which involves activating and deactivating threat trees nodes by posing specific questions to the privacy engineer or software architect, leading to the a priori exclusion of non-applicable threats from the analysis exercise. The efficiency gain can be strengthened further by incorporating reusable domain knowledge in the approach to instantiate the questionnaire.
C1  - New York, NY, USA
C3  - Proceedings of the 33rd Annual ACM Symposium on Applied Computing
DA  - 2018///
PY  - 2018
DO  - 10.1145/3167132.3167414
SP  - 1175
EP  - 1178
PB  - Association for Computing Machinery
SN  - 978-1-4503-5191-1
UR  - https://doi.org/10.1145/3167132.3167414
KW  - domain knowledge
KW  - privacy by design
KW  - privacy impact assessment
KW  - threat modeling
ER  - 

TY  - CONF
TI  - Privacy Context Model for Dynamic Privacy Adaptation in Ubiquitous Computing
AU  - Schaub, Florian
AU  - Könings, Bastian
AU  - Dietzel, Stefan
AU  - Weber, Michael
AU  - Kargl, Frank
T3  - UbiComp '12
AB  - Ubiquitous computing is characterized by the merger of physical and virtual worlds as physical artifacts gain digital sensing, processing, and communication capabilities. Maintaining an appropriate level of privacy in the face of such complex and often highly dynamic systems is challenging. We argue that context awareness not only enables novel UbiComp applications but can also support dynamic regulation and configuration of privacy mechanisms. We propose a higher level context model that abstracts from low level details and contains only privacy relevant context features. Context changes in our model can trigger reconfiguration of privacy mechanisms or facilitate context-specific privacy recommendations to the user. Based on our model, we analyze potential privacy implications of context changes and discuss how these results could inform actual reconfiguration of privacy mechanisms.
C1  - New York, NY, USA
C3  - Proceedings of the 2012 ACM Conference on Ubiquitous Computing
DA  - 2012///
PY  - 2012
DO  - 10.1145/2370216.2370383
SP  - 752
EP  - 757
PB  - Association for Computing Machinery
SN  - 978-1-4503-1224-0
UR  - https://doi.org/10.1145/2370216.2370383
KW  - context awareness
KW  - personalization
KW  - pervasive computing
KW  - privacy
KW  - privacy impact assessment
KW  - ubiquitous computing
ER  - 

TY  - CONF
TI  - It's All Fun and Games, and Some Legalese: Data Protection Implications for Increasing Cyber-Skills of Employees through Games
AU  - Povse, Danaja Fabcic
T3  - CECC 2018
AB  - In order to combat cyberattacks, an organisation can decide to train its employees. Improving cyber-skills of employees through educational games means their personal data will be processed and therefore it falls under the scope of the General Data Protection Regulation (GDPR). The goal of this paper is to address challenges that organisations are likely to face in practice, such as invalidity of employees' consent and over-intrusive monitoring. It argues that in order to approach training lawfully, organisations should (1) choose their external trainer with due diligence, (2) carry out a data protection impact assessment, and under certain circumstances (3) appoint a data protection officer.
C1  - New York, NY, USA
C3  - Proceedings of the Central European Cybersecurity Conference 2018
DA  - 2018///
PY  - 2018
DO  - 10.1145/3277570.3277580
PB  - Association for Computing Machinery
SN  - 978-1-4503-6515-4
UR  - https://doi.org/10.1145/3277570.3277580
KW  - Cyber hygiene
KW  - cyber resilience
KW  - cyber skills
KW  - GDPR
KW  - human factor
KW  - personal data of employees
KW  - privacy
ER  - 

TY  - CONF
TI  - Privacy and Data Protection Concerns Regarding the Use of Blockchains in Smart Cities
AU  - Ramos, Luis Felipe M.
AU  - Silva, João Marco C.
T3  - ICEGOV '19
AB  - In this work we investigate which aspects of data protection regulation must be carefully observed when implementing Blockchain-based projects in smart cities. This technology provides interesting properties and allows governments to develop flexible and innovative data management systems. Nevertheless, realizing the benefits of using Blockchains requires understanding the government processes along with the legal framework and political setting imposed on government. Though it is a buzzword, Blockchain may not always be the best solution for data processing, and carrying out a Data Protection Impact Assessment could allow an analysis of the necessity and proportionality of the mechanism. Furthermore, principles relating to security of data remain applicable to Blockchains. We discuss points of interaction between Blockchain technology and the European Union data protection framework, and provide recommendations on how to better develop Blockchain-based projects in smart cities. The findings of the study should provide public sector actors with a guideline to assess the real necessity and better format of a Blockchain-based application.
C1  - New York, NY, USA
C3  - Proceedings of the 12th International Conference on Theory and Practice of Electronic Governance
DA  - 2019///
PY  - 2019
DO  - 10.1145/3326365.3326410
SP  - 342
EP  - 347
PB  - Association for Computing Machinery
SN  - 978-1-4503-6644-1
UR  - https://doi.org/10.1145/3326365.3326410
KW  - Blockchain
KW  - E-Gov
KW  - GDPR
KW  - Personal Data
KW  - Privacy
KW  - Smart Cities
ER  - 

TY  - CONF
TI  - PriCal: Context-Adaptive Privacy in Ambient Calendar Displays
AU  - Schaub, Florian
AU  - Könings, Bastian
AU  - Lang, Peter
AU  - Wiedersheim, Björn
AU  - Winkler, Christian
AU  - Weber, Michael
T3  - UbiComp '14
AB  - PriCal is an ambient calendar display that shows a user's schedule similar to a paper wall calendar. PriCal provides context-adaptive privacy to users by detecting present persons and adapting event visibility according to the user's privacy preferences. We present a detailed privacy impact assessment of our system, which provides insights on how to leverage context to enhance privacy without being intrusive. PriCal is based on a decentralized architecture and supports the detection of registered users as well as unknown persons. In a three-week deployment study with seven displays, ten participants used PriCal in their real work environment with their own digital calendars. Our results provide qualitative insights on the implications, acceptance, and utility of context-adaptive privacy in the context of a calendar display system, indicating that it is a viable approach to mitigate privacy implications in ubicomp applications.
C1  - New York, NY, USA
C3  - Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing
DA  - 2014///
PY  - 2014
DO  - 10.1145/2632048.2632087
SP  - 499
EP  - 510
PB  - Association for Computing Machinery
SN  - 978-1-4503-2968-2
UR  - https://doi.org/10.1145/2632048.2632087
KW  - collaboration
KW  - context awareness
KW  - groupware calendar systems
KW  - mobile interaction
KW  - privacy
KW  - public displays
ER  - 

TY  - CONF
TI  - POPCORN: Privacy-Preserving Charging for Emobility
AU  - Höfer, Christina
AU  - Petit, Jonathan
AU  - Schmidt, Robert
AU  - Kargl, Frank
T3  - CyCAR '13
AB  - Upcoming years will see a massive deployment of electric vehicles and, combined with this, of charging infrastructure. This will require protocols and standards that will control authentication, authorization, and billing of electric-vehicle charging. The ISO/IEC 15118 protocol that addresses the communication between the charging station and the vehicle is going to play an important role, at least in Europe. While it foresees security protection, there are no significant mechanisms for privacy protection in place. In this paper, we investigate the privacy protection of ISO/IEC 15118 and the surrounding charging and payment infrastructure by means of a Privacy Impact Assessment (PIA). Based on this we propose modular extensions of the protocol applying state-of-the-art Privacy Enhancing Technologies like anonymous credentials to come to a system with maximum privacy protection. We conducted a second PIA to show the benefits to privacy protection that our POPCORN protocol provides compared to the original ISO/IEC 15118. We also describe a proof-of-concept implementation of our system based on a model of electric vehicle and charging station that shows the feasibility of our approach and allows a first preliminary analysis of performance and other issues.
C1  - New York, NY, USA
C3  - Proceedings of the 2013 ACM Workshop on Security, Privacy &amp; Dependability for Cyber Vehicles
DA  - 2013///
PY  - 2013
DO  - 10.1145/2517968.2517971
SP  - 37
EP  - 48
PB  - Association for Computing Machinery
SN  - 978-1-4503-2487-8
UR  - https://doi.org/10.1145/2517968.2517971
KW  - electric vehicle charging
KW  - iso/iec 15118
KW  - privacy
KW  - privacy enhancing technologies
KW  - security
ER  - 

TY  - CONF
TI  - Modelling Privacy Harms of Compromised Personal Medical Data - beyond Data Breach
AU  - Wairimu, Samuel
AU  - Fritsch, Lothar
T3  - ARES '22
AB  - What harms and consequences do patients experience after a medical data breach? This article aims at the improvement of privacy impact analysis for data breaches that involve personal medical data. The article has two major findings. First, scientific literature does not mention consequences and harms to the data subjects when discussing data breaches in the healthcare sector. For conceptualizing actual documented harm, we had to search court rulings and popular press articles instead. We present the findings of our search for empirically founded harms in the first part of the article. Second, we present a modified PRIAM assessment method with the goal of better assessment of harms and consequences of such data breaches for the patient/employee data subject in healthcare. We split the risk assessment into parallel categories of assessment rather than calculating a single risk score. In addition, we quantify the original PRIAM categories into a calculus for risk assessment. The article presents our modified PRIAM which is the result of these modifications. Our overall contribution is the collection of actual harms and consequences of e-health data breaches that complement the overly theoretical discussion in publications. With our operationalization of PRIAM and by providing a catalog of real harms examples, we focus privacy impact assessment on actual harms to persons.
C1  - New York, NY, USA
C3  - Proceedings of the 17th International Conference on Availability, Reliability and Security
DA  - 2022///
PY  - 2022
DO  - 10.1145/3538969.3544462
PB  - Association for Computing Machinery
SN  - 978-1-4503-9670-7
UR  - https://doi.org/10.1145/3538969.3544462
KW  - consequences
KW  - data breach
KW  - harms
KW  - personal health information
KW  - privacy
KW  - privacy impact
KW  - risk assessment
ER  - 

TY  - CONF
TI  - Enhancing AI Fairness through Impact Assessment in the European Union: A Legal and Computer Science Perspective
AU  - Calvi, Alessandra
AU  - Kotzinos, Dimitris
T3  - FAccT '23
AB  - How to protect people from algorithmic harms? A promising solution, although in its infancy, is algorithmic impact assessment (AIA). AIAs are iterative processes used to investigate the possible short and long terms societal impacts of AI systems before their use, but with ongoing monitoring and periodic revisiting even after their implementation. When conducted in a participatory and transparent fashion, they could create bridges across the legal, social and computer science domains, promoting the accountability of the entity performing them as well as public scrutiny. They could enable to re-attach the societal and regulatory context to the mathematical definition of fairness, thus expanding the formalistic approach thereto. Whilst the regulatory framework in the European Union currently lacks the obligation to perform such AIA, some other provisions are expected to play a role in AI development, leading the way towards more widespread adoption of AIA. These include the Data Protection Impact Assessment (DPIA) under the General Data Protection Regulation (GDPR), the risk assessment process under the Digital Services Act (DSA) and the Conformity Assessment (CA) foreseen under the AI Regulation proposal.In this paper, after briefly introducing the plurality of definitions of fairness in the legal, social and computer science domains, and explaining to which extent the current and upcoming legal framework mandates the adoption of fairness metrics, we will illustrate how AIA could create bridges between all these disciplines, allowing us to build fairer AI solutions. We will then recognise the role of DPIA, DSA risk assessment and CA by discussing the contributions they can offer towards AIA but also identify the aspects lacking therein. We will then identify how these assessment provisions could aid the overall technical discussion of introducing and assessing fairness in AI-based models and processes.
C1  - New York, NY, USA
C3  - Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency
DA  - 2023///
PY  - 2023
DO  - 10.1145/3593013.3594076
SP  - 1229
EP  - 1245
PB  - Association for Computing Machinery
SN  - 9798400701924
UR  - https://doi.org/10.1145/3593013.3594076
ER  - 

TY  - BOOK
TI  - ARES '23: Proceedings of the 18th International Conference on Availability, Reliability and Security
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 9798400707728
ER  - 

TY  - BOOK
TI  - FAccT '23: Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 9798400701924
ER  - 

TY  - BOOK
TI  - ARES '22: Proceedings of the 17th International Conference on Availability, Reliability and Security
CY  - New York, NY, USA
DA  - 2022///
PY  - 2022
PB  - Association for Computing Machinery
SN  - 978-1-4503-9670-7
ER  - 

TY  - CONF
TI  - An Ontology Capturing the Interdependence of the General Data Protection Regulation (GDPR) and Information Security
AU  - Geko, Melisa
AU  - Tjoa, Simon
T3  - CECC 2018
AB  - High returns for processing personal data and low penalties for privacy violations led to the circumstance that protection of privacy was often not considered a priority. To counter this habit and to harmonize data protection laws throughout the European Union, the EU-Commission has adopted the General Data Protection Regulation (GDPR), clarifying data subject rights and ensuring an appropriate level of privacy protection.Through high penalties for non-compliance (i.e. up to 2% - 4% of the annual worldwide turnover), GDPR was able to put high pressure on organizations to comply with the requirements. However, studies have shown that organizations are often overwhelmed by the actual requirements.In this paper, we therefore aim to support organization to understand this complex topic by providing an ontology-based data protection knowledge base, which highlights the interdependency of GDPR and information security.
C1  - New York, NY, USA
C3  - Proceedings of the Central European Cybersecurity Conference 2018
DA  - 2018///
PY  - 2018
DO  - 10.1145/3277570.3277590
PB  - Association for Computing Machinery
SN  - 978-1-4503-6515-4
UR  - https://doi.org/10.1145/3277570.3277590
KW  - Audit
KW  - Compliance
KW  - Data Protection
KW  - EU
KW  - GDPR
KW  - Information Security
KW  - Legal Ontology
ER  - 

TY  - CONF
TI  - Philippine SUCs Compliance Performance on RA 10173: A Case Study on Bukidnon State University
AU  - Flores, Rozanne Tuesday G.
AU  - Ching, Michelle Renee D.
T3  - ICEEG '18
AB  - The advancements in technologies have accelerated educational institutions by improving service delivery while reducing costs. As a result, it provided avenues of learning, the use of online discussions, Virtual Learning Environments (VLEs) and mobile technologies, thus making data security vulnerable. With these, it is imperative that through the lens of R.A. 10173 and NPC's five pillars that data be protected by a policy that is sustained and executed effectively. This qualitative research using case study technique aimed to evaluate, explore and explain the level of compliance of Bukidnon State University (BukSU) with RA 10173. Likewise answering the research question how does PSUCs apply and integrate R.A. 10173 with its Information Systems and Business Processes? Using single case holistic design with common rationale, and pattern matching technique in interpreting the tabulated results. It was found out that BukSU, just like most government agencies in the Philippines, is qualitatively described as Partial Compliant. Furthermore, their compliance was due to moral suasion, where BukSU, considers it as its moral obligation to protect the students and its employees' data. An initiative from PASUC, to come up with a Data Privacy Manual that will serve as a model for all PSUC's in drafting their own manual, where BukSU practices can be aligned with that of PASUC. After the September 11, 2017, deadline, BukSU invested in a UTM Unified Threat Management with a three-year license to safeguard university data resources.
C1  - New York, NY, USA
C3  - Proceedings of the 2nd International Conference on E-Commerce, E-Business and E-Government
DA  - 2018///
PY  - 2018
DO  - 10.1145/3234781.3234790
SP  - 74
EP  - 78
PB  - Association for Computing Machinery
SN  - 978-1-4503-6490-4
UR  - https://doi.org/10.1145/3234781.3234790
KW  - data privacy
KW  - data privacy compliance
KW  - e-governance
KW  - personal information
KW  - security
ER  - 

TY  - CONF
TI  - Investigating Practices and Opportunities for Cross-Functional Collaboration around AI Fairness in Industry Practice
AU  - Deng, Wesley Hanwen
AU  - Yildirim, Nur
AU  - Chang, Monica
AU  - Eslami, Motahhare
AU  - Holstein, Kenneth
AU  - Madaio, Michael
T3  - FAccT '23
AB  - An emerging body of research indicates that ineffective cross-functional collaboration – the interdisciplinary work done by industry practitioners across roles – represents a major barrier to addressing issues of fairness in AI design and development. In this research, we sought to better understand practitioners’ current practices and tactics to enact cross-functional collaboration for AI fairness, in order to identify opportunities to support more effective collaboration. We conducted a series of interviews and design workshops with 23 industry practitioners spanning various roles from 17 companies. We found that practitioners engaged in bridging work to overcome frictions in understanding, contextualization, and evaluation around AI fairness across roles. In addition, in organizational contexts with a lack of resources and incentives for fairness work, practitioners often piggybacked on existing requirements (e.g., for privacy assessments) and AI development norms (e.g., the use of quantitative evaluation metrics), although they worry that these tactics may be fundamentally compromised. Finally, we draw attention to the invisible labor that practitioners take on as part of this bridging and piggybacking work to enact interdisciplinary collaboration for fairness. We close by discussing opportunities for both FAccT researchers and AI practitioners to better support cross-functional collaboration for fairness in the design and development of AI systems.
C1  - New York, NY, USA
C3  - Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency
DA  - 2023///
PY  - 2023
DO  - 10.1145/3593013.3594037
SP  - 705
EP  - 716
PB  - Association for Computing Machinery
SN  - 9798400701924
UR  - https://doi.org/10.1145/3593013.3594037
KW  - AI development
KW  - collaboration
KW  - fairness
KW  - interdisciplinarity
ER  - 

TY  - CONF
TI  - Taking Account of Privacy When Designing Cloud Computing Services
AU  - Pearson, Siani
T3  - CLOUD '09
AB  - Privacy is an important issue for cloud computing, both in terms of legal compliance and user trust, and needs to be considered at every phase of design. In this paper the privacy challenges that software engineers face when targeting the cloud as their production environment to offer services are assessed, and key design principles to address these are suggested.
C1  - USA
C3  - Proceedings of the 2009 ICSE Workshop on Software Engineering Challenges of Cloud Computing
DA  - 2009///
PY  - 2009
DO  - 10.1109/CLOUD.2009.5071532
SP  - 44
EP  - 52
PB  - IEEE Computer Society
SN  - 978-1-4244-3713-9
UR  - https://doi.org/10.1109/CLOUD.2009.5071532
ER  - 

TY  - JOUR
TI  - GDPR Anti-Patterns
AU  - Shastri, Supreeth
AU  - Wasserman, Melissa
AU  - Chidambaram, Vijay
T2  - Commun. ACM
AB  - How design and operation of modern cloud-scale systems conflict with GDPR.
DA  - 2021/01//
PY  - 2021
DO  - 10.1145/3378061
VL  - 64
IS  - 2
SP  - 59
EP  - 65
SN  - 0001-0782
UR  - https://doi.org/10.1145/3378061
ER  - 

TY  - CONF
TI  - Data Privacy Act of 2012 Compliance Performance of Philippine Government Agencies: A Case Study Approach
AU  - Ching, Michelle Renee D.
AU  - Celis, Nelson J.
T3  - ICEEG '18
AB  - After three months of the initial deadline of the National Privacy Commission (NPC), it is vital to know the status of compliance of the Commission on Higher Education (CHED) and Commission on Elections (COMELEC), especially with the data breached that occurred last March 2016. This research study aims to uncover this and how CHED and COMELEC are applying R.A. 10173 to its business processes and strategies. It has been found out that both government agencies are Partially Compliant having its own challenges. It is prevalent in their latest Information Systems Strategic Plan (ISSP) how they incorporated data protection, data privacy, and information security in their Information Systems initiatives. Although, this will not stop here because they need to implement it and comply with the rest of the R.A. 10173 requirements in time for the next deadline, which is on March 8, 2018.
C1  - New York, NY, USA
C3  - Proceedings of the 2nd International Conference on E-Commerce, E-Business and E-Government
DA  - 2018///
PY  - 2018
DO  - 10.1145/3234781.3234784
SP  - 59
EP  - 63
PB  - Association for Computing Machinery
SN  - 978-1-4503-6490-4
UR  - https://doi.org/10.1145/3234781.3234784
KW  - data privacy
KW  - data privacy compliance
KW  - e-governance
KW  - personal information
KW  - security
ER  - 

TY  - CONF
TI  - Understanding Philippine National Agency's Commitment on Data Privacy Act of 2012: A Case Study Perspective
AU  - Pitogo, Vicente A.
AU  - Ching, Michelle Renee D.
T3  - ICEEG '18
AB  - The Republic Act No. 10173 of the Philippines, also known as "Data Privacy Act of 2012" was established to protect and safeguard the personal data of its citizenry whether in public agencies or private entities, thereby creating the National Privacy Commission (NPC) in 2015, as an independent body mandated to administer the DPA of 2012, to monitor and ensure compliance to right to privacy and data protection. This qualitative research using case study technique aims to explore and explain why and how the National Commission on Indigenous Peoples will comply with R.A. 10173 as the subject of the study, and to determine the challenges and best practices encountered by NCIP relative to compliance. Using single case holistic design with common rationale, and pattern matching as an analytic technique as adapted in Robert Yin's methods and design this study resulted to: e-commerce act is a moderating factor in compliance with DPA 2012, and the determinants of compliance, such as general deterrence and legitimacy of regulations has a compelling casual effect on complying with the law. Further, challenges that encountered by the agency was also a factor in compliance with R.A. 10173 such as, (1) lack of awareness, (2) resource constraints, (3) organizational structure and (4) low priority agenda. It is further recommended to conduct a follow-up study once the recent ISSP is available, vis-à-vis to March 8, 2018 extended deadline.
C1  - New York, NY, USA
C3  - Proceedings of the 2nd International Conference on E-Commerce, E-Business and E-Government
DA  - 2018///
PY  - 2018
DO  - 10.1145/3234781.3234788
SP  - 64
EP  - 68
PB  - Association for Computing Machinery
SN  - 978-1-4503-6490-4
UR  - https://doi.org/10.1145/3234781.3234788
KW  - data privacy
KW  - data privacy compliance
KW  - e-governance
KW  - personal data
ER  - 

TY  - JOUR
TI  - In the Virtual Extension
AU  - Staff, CACM
T2  - Commun. ACM
AB  - To ensure the timely publication of articles, Communications created the Virtual Extension (VE) to expand the page limitations of the print edition by bringing readers the same high-quality articles in an online-only format. VE articles undergo the same rigorous review process as those in the print edition and are accepted for publication on merit. The following synopses are from articles now available in their entirety to ACM members via the Digital Library.
DA  - 2011/08//
PY  - 2011
DO  - 10.1145/1978542.1978545
VL  - 54
IS  - 8
SP  - 8
SN  - 0001-0782
UR  - https://doi.org/10.1145/1978542.1978545
ER  - 

TY  - CONF
TI  - SoK: Engineering Privacy-Aware High-Tech Systems
AU  - Riva, Giovanni Maria
AU  - Vasenev, Alexandr
AU  - Zannone, Nicola
T3  - ARES '20
AB  - The processing of personal data is becoming a key business factor, especially for high-tech system industries such as automotive and healthcare service providers. To protect such data, the European Union (EU) has introduced the General Data Protection Regulation (GDPR), with the aim to standardize and strengthen data protection policies across EU countries. The GDPR defines stringent requirements on the collection and processing of personal data and imposes severe fines and penalties on data controllers and processors for non-compliance. Although the GDPR is enforce since 2018, many public and private organizations are still struggling to fully comply with the regulation. A main reason for this is the lack of usable methodologies that can support developers in designing of GDPR-complaint high-tech systems. This paper examines the growing literature on methodologies for the design of privacy-aware systems, and identifies the main challenges to be addressed in order to facilitate developers in the design of such systems. In particular, we investigate to what extent existing methodologies (i) cover GDPR and privacy-by-design principles, (ii) address different levels of system design concerns, and (iii) have demonstrated their suitability for the purpose. Our literature study shows that the domain landscape appears to be heterogeneous and disconnected, as existing methodologies often focus only on subsets of the GDPR principles and/or on specific angles of system design. Based on our findings, we provide recommendations on the definition of comprehensive methodologies tailored to designing GDPR-compliant high-tech systems.
C1  - New York, NY, USA
C3  - Proceedings of the 15th International Conference on Availability, Reliability and Security
DA  - 2020///
PY  - 2020
DO  - 10.1145/3407023.3407061
PB  - Association for Computing Machinery
SN  - 978-1-4503-8833-7
UR  - https://doi.org/10.1145/3407023.3407061
KW  - GDPR
KW  - privacy-by-design
KW  - system engineering
KW  - systematic literature review
ER  - 

TY  - CONF
TI  - RA 10173 and Its Challenges to Philippine State Universities and Colleges' Compliance Performance: The Case of Mindanao State University - General Santos City
AU  - Doce, Lumer Jude P.
AU  - Ching, Michelle Renee D.
T3  - ICEEG '18
AB  - Data privacy has become a major concern in the Philippines owing to the promulgation of Republic Act No. 10173, otherwise known as the Data Privacy Act of 2012, duly enforced by the National Privacy Commission (NPC). This study seeks to determine the level of compliance of Mindanao State University- General Santos City (MSU-GSC) as well as understand the challenges it encounters in accordance with the Data Privacy Act. Using a qualitative single holistic case study design and pattern matching technique, this paper was able to uncover how and why SUCs can comply with the RA 10173 and can apply such law in their information systems and academic processes. It was found out that MSU-GSC is qualitatively described as partially compliant and it further supports deterrence and legitimacy as its determinants. The moderating effect of compliance with RA 8792 or E-Commerce Act of 2000 also significantly affects its abidance with Data Privacy Act as efforts are continuously directed towards automating university processes and transactions. Moreover, three factors were identified that contributes primarily on the challenges of its compliance namely lack of better understanding, budgetary issues and time constraints. The study contributes to the literature by providing inputs about SUCs' continuing efforts toward compliance with RA 10173. It is suggested NPC to diffuse responsibility to SUCs, so as compliance with data privacy act will weigh down less. Further, it is expected a greater appreciation of the law will fuel enthusiasm to overcome challenges of compliance.
C1  - New York, NY, USA
C3  - Proceedings of the 2nd International Conference on E-Commerce, E-Business and E-Government
DA  - 2018///
PY  - 2018
DO  - 10.1145/3234781.3234789
SP  - 69
EP  - 73
PB  - Association for Computing Machinery
SN  - 978-1-4503-6490-4
UR  - https://doi.org/10.1145/3234781.3234789
KW  - data privacy
KW  - data privacy compliance
KW  - e-governance
KW  - personal information
ER  - 

TY  - CONF
TI  - Irish Attitudes Toward COVID Tracker App &amp; Privacy: Sentiment Analysis on Twitter and Survey Data
AU  - Lohar, Pintu
AU  - Xie, Guodong
AU  - Bendechache, Malika
AU  - Brennan, Rob
AU  - Celeste, Edoardo
AU  - Trestian, Ramona
AU  - Tal, Irina
T3  - ARES '21
AB  - Contact tracing apps used in tracing and mitigating the spread of COVID-19 have sparked discussions and controversies worldwide. The major concerns in relation to these apps are around privacy. Ireland was in general praised for the design of its COVID tracker app, and the transparency through which privacy issues were addressed. However, the ”voice” of the Irish public was not really heard or analysed. This study aimed to analyse the Irish public sentiment towards privacy and COVID tracker app. For this purpose we have conducted sentiment analysis on Twitter data collected from public Twitter accounts from Republic of Ireland. We collected COVID-19 related tweets generated in Ireland over a period of time from January 1, 2020 up to December 31, 2020 in order to perform sentiment analysis on this data set. Moreover, the study performed sentiment analysis on the feedback received from a national survey on privacy conducted in Republic of Ireland. The findings of the study reveal a significant criticism towards the app that relate to privacy concerns, but other aspects of the app as well. The findings also reveal some positive attitude towards the fight against COVID-19, but these are not necessarily related to the technological solutions employed for this purpose. The findings of the study contributed to the formulation of useful recommendations communicated to the relevant Irish actors.
C1  - New York, NY, USA
C3  - Proceedings of the 16th International Conference on Availability, Reliability and Security
DA  - 2021///
PY  - 2021
DO  - 10.1145/3465481.3469193
PB  - Association for Computing Machinery
SN  - 978-1-4503-9051-4
UR  - https://doi.org/10.1145/3465481.3469193
KW  - COVID-19
KW  - privacy
KW  - Sentiment Analysis
KW  - tracker app
ER  - 

TY  - BOOK
TI  - SBSI '23: Proceedings of the XIX Brazilian Symposium on Information Systems
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 9798400707599
ER  - 

TY  - JOUR
TI  - Design of an Inclusive Financial Privacy Index (INF-PIE): A Financial Privacy and Digital Financial Inclusion Perspective
AU  - Akanfe, Oluwafemi
AU  - Valecha, Rohit
AU  - Rao, H. Raghav
T2  - ACM Trans. Manage. Inf. Syst.
AB  - Financial privacy is an important part of an individual's privacy, but efforts to enhance financial privacy have often not been given enough prominence by some countries when advancing financial inclusion. This impedes under-served communities from utilizing financial services. This article adopts a design science approach to create an INclusive Financial Privacy IndEx (INF-PIE) from the two perspectives of financial privacy and digital financial inclusion to help ensure financial services for a wide range of populations. This article first examines the privacy policies of Mobile Wallet and Remittance (MWR) apps (a digital financial solution), uses an analytics approach for extracting semi-structured information components; and based on text categorization and topic modeling, creates privacy policy compliance scores. In particular, it analyses the privacy policies using natural language processing techniques such as Term Frequency-Inverse Document Frequency (tf-idf) and Latent Dirichlet Allocation (LDA). This article then develops a digital financial inclusion score through a multivariate analysis of indexes extracted from the global findex dataset using Principal Component Analysis (PCA). Finally, the INF-PIE framework is established to analyze various countries and assess their financial privacy and digital financial inclusion practices. This framework can show how countries’ relative data privacy compliance and digital financial inclusion practices underscore their inclusive financial privacy.
DA  - 2020/12//
PY  - 2020
DO  - 10.1145/3403949
VL  - 12
IS  - 1
SN  - 2158-656X
UR  - https://doi.org/10.1145/3403949
KW  - compliance score
KW  - Digital financial inclusion
KW  - digital payments systems
KW  - GDPR
KW  - inclusive privacy index
KW  - mobile wallet and remittance
ER  - 

TY  - CONF
TI  - PREDICT: A Trusted Framework for Sharing Data for Cyber Security Research
AU  - Scheper, Charlotte
AU  - Cantor, Susanna
AU  - Maughan, Douglas
T3  - BADGERS '11
AB  - In this paper, we describe the formatting guidelines for ACM SIG The Protected Repository for Defense of Infrastructure against Cyber Threats (PREDICT) has established a trusted framework for sharing real-world security-related datasets for cyber security research. In establishing PREDICT, a set of key issues for sharing these data has been addressed: providing secure, centralized access to multiple sources of data; assuring confidentiality to protect the privacy of the individuals and the security of the networks from which the data are collected; assuring data integrity to protect access to the data and ensure its proper use; and protecting proprietary information and reducing legal risks. PREDICT continues to address issues in producing and sharing datasets as it enters its second phase of development, providing more controversial data, adding data providers, and initiating international participation.
C1  - New York, NY, USA
C3  - Proceedings of the First Workshop on Building Analysis Datasets and Gathering Experience Returns for Security
DA  - 2011///
PY  - 2011
DO  - 10.1145/1978672.1978686
SP  - 105
EP  - 106
PB  - Association for Computing Machinery
SN  - 978-1-4503-0768-0
UR  - https://doi.org/10.1145/1978672.1978686
KW  - cyber security
KW  - distributed repository
KW  - internet
KW  - PREDICT
ER  - 

TY  - CONF
TI  - Ensuring Privacy in the Application of the Brazilian General Data Protection Law (LGPD)
AU  - de Castro, Evandro Thalles Vale
AU  - Silva, Geovana R. S.
AU  - Canedo, Edna Dias
T3  - SAC '22
AB  - Currently, many organizations make use of the personal data of their users. Personal data is the set of information that can lead to the identification of a specific person and, therefore, this information is generally vital for the operations and business continuity of organizations. Consequently, the relevance of adopting methodologies that guarantee the protection and privacy of user information is indispensable to prevent the leaking of sensible information. Therefore, laws were created to establish essential requirements for organizations to provide support and protection to the personal data of users, such as the General European Data Protection Regulation (GDPR) and the Brazilian General Data Protection Law (LGPD). This work aims to develop a framework to support ICT professionals in adapting companies to the requirements demanded by the LGPD. To achieve the purpose, a framework based on the BEST methodology (Business Engaged Security Transformation) was proposed. This framework has a sustainable approach and can be implemented by any organization. A survey was carried out to collect the perception of Information and Communication Technology (ICT) practitioners in relation to adherence to LGPD adaptation actions by organizations. As a result, we identified a weakness in the privacy and information security management methodology implemented in organizations, which, in the future, may result in risks and damage to user information.
C1  - New York, NY, USA
C3  - Proceedings of the 37th ACM/SIGAPP Symposium on Applied Computing
DA  - 2022///
PY  - 2022
DO  - 10.1145/3477314.3507023
SP  - 1228
EP  - 1235
PB  - Association for Computing Machinery
SN  - 978-1-4503-8713-2
UR  - https://doi.org/10.1145/3477314.3507023
KW  - compliance
KW  - data privacy
KW  - general data protection law
KW  - ICT governance
KW  - information security
KW  - privacy by design
ER  - 

TY  - CONF
TI  - Commitment on Data Privacy towards E-Governance: The Case of Local Government Units
AU  - Pitogo, Vicente
T3  - ICEGOV '19
AB  - The proliferation of ICT in the government sector is a crucial tactic in achieving different dimensions of public trust and services, especially that government offices and local government units (LGUs) are gearing toward e-governance as a way to manage and utilize ICT infrastructure. Moreover, in engaging ICT services, personal data and other critical information must be safeguarded and not exposed publicly. In the Philippines, data privacy act of 2012 (DPA 2012) was promulgated to vanguard sensitive information and data protection, and impose legal sanctions to any organization breached therein. This empirical study aims to explore LGUs on their commitment to data privacy, assess their level of compliance and examine factors that hinder their defiance. The method used is qualitative research in a case study technique, using a multiple case holistic design. Outcomes pattern matching is also used to triangulate records against expected patterns. Results show that before the enactment of DPA 2012, the LGUs under study are not compliant. However, after the passage and the National Privacy Commission (NPC) took action, a significant leap has observed. Determinants of compliance, such as deterrence, legitimacy and moral obligation have compelling casual factors why LGUs are complying with the law. Upon further assessment, pressing concerns are also perceived, such as lack of awareness, wait-and-see attitude, and resource and time constraints. In sum, LGUs are trying to fast-track, overhaul or re-engineering their processes and operations, including ICT infrastructure acquisition, resource allocation, and qualified ICT personnel apportionment as compliance initiatives; and commit themselves to full compliance towards the establishment of better government and e-governance.
C1  - New York, NY, USA
C3  - Proceedings of the 12th International Conference on Theory and Practice of Electronic Governance
DA  - 2019///
PY  - 2019
DO  - 10.1145/3326365.3326404
SP  - 302
EP  - 309
PB  - Association for Computing Machinery
SN  - 978-1-4503-6644-1
UR  - https://doi.org/10.1145/3326365.3326404
KW  - compliance
KW  - Data privacy
KW  - e-governance
KW  - local government units
ER  - 

TY  - JOUR
TI  - The Challenges of Privacy by Design
AU  - Spiekermann, Sarah
T2  - Commun. ACM
AB  - Heralded by regulators, Privacy by Design holds the promise to solve the digital world's privacy problems. But there are immense challenges, including management commitment and step-by-step methods to integrate privacy into systems.
DA  - 2012/07//
PY  - 2012
DO  - 10.1145/2209249.2209263
VL  - 55
IS  - 7
SP  - 38
EP  - 40
SN  - 0001-0782
UR  - https://doi.org/10.1145/2209249.2209263
ER  - 

TY  - CONF
TI  - Data Federation Approach to Health and Wellbeing Knowledge Base – The Case of Hale&amp;Hearty Project
AU  - Ahmadi Zeleti, Fatemeh
AU  - Campbell, Helena
AU  - Kerins, Rhoda
T3  - ICEGOV '21
AB  - Healthcare is a vital public service for any society. To stay healthy, people are not only interested in acute and primary care services, but also in amenities that promote health and fitness, both physical and mental. However, information pertaining to what services are available to the public is not always readily accessible and easy to find. This work in progress paper builds on an ongoing project of the Irish Government - Hale &amp; Hearty. The aim of the project is to provide a comprehensive Health &amp; Wellbeing Knowledge Base and an easy-to-use web application to provide health and wellbeing information to the public and data managers. This involves the harmonization and linking of data from many sources, including Local Authorities, the Central Statistics Office, and Healthcare Providers. The Hale &amp; Hearty Knowledge Base will be available as Open Data on the National Open Data Portal and the European Data Portal.
C1  - New York, NY, USA
C3  - Proceedings of the 14th International Conference on Theory and Practice of Electronic Governance
DA  - 2022///
PY  - 2022
DO  - 10.1145/3494193.3494268
SP  - 506
EP  - 508
PB  - Association for Computing Machinery
SN  - 978-1-4503-9011-8
UR  - https://doi.org/10.1145/3494193.3494268
KW  - Data federation
KW  - Health application
KW  - Health data
KW  - Healthcare
KW  - Ireland
KW  - Knowledge base
KW  - Open data
KW  - Wellbeing data
ER  - 

TY  - JOUR
TI  - It Is About What They Could Do with the Data: A User Perspective on Privacy in Smart Metering
AU  - Jakobi, Timo
AU  - Patil, Sameer
AU  - Randall, Dave
AU  - Stevens, Gunnar
AU  - Wulf, Volker
T2  - ACM Trans. Comput.-Hum. Interact.
AB  - Smart Meters are a key component of increasing the power efficiency of the Smart Grid. To help manage the grid effectively, these meters are designed to collect information on power consumption and send it to third parties. With Smart Metering, for the first time, these cloud-connected sensing devices are legally mandated to be installed in the homes of millions of people worldwide. Via a multi-staged empirical study that utilized an open-ended questionnaire, focus groups, and a design probe, we examined how people characterize the tension between the utility of Smart Metering and its impact on privacy. Our findings show that people seek to make abstract Smart Metering data accountable by connecting it to their everyday practices. Our insight can inform the design of usable privacy configuration tools that help Smart Metering consumers relate abstract data with the real-world implications of its disclosure.
DA  - 2019/01//
PY  - 2019
DO  - 10.1145/3281444
VL  - 26
IS  - 1
SN  - 1073-0516
UR  - https://doi.org/10.1145/3281444
KW  - design probe
KW  - privacy preferences
KW  - privacy settings
KW  - Smart metering
KW  - smart meters
KW  - usable privacy
ER  - 

TY  - JOUR
TI  - Being Recognized Everywhere
AU  - Kugler, Logan
T2  - Commun. ACM
AB  - How facial and voice recognition are reshaping society.
DA  - 2019/01//
PY  - 2019
DO  - 10.1145/3297803
VL  - 62
IS  - 2
SP  - 17
EP  - 19
SN  - 0001-0782
UR  - https://doi.org/10.1145/3297803
ER  - 

TY  - CONF
TI  - Protection of Personal Data in Security Alert Sharing Platforms
AU  - Stupka, Václav
AU  - Horák, Martin
AU  - Husák, Martin
T3  - ARES '17
AB  - In order to ensure confidentiality, integrity and availability (so called CIA triad) of data within network infrastructure, it is necessary to be able to detect and handle cyber security incidents. For this purpose, it is vital for Computer Security Incident Response Teams (CSIRT) to have enough data on relevant security events and threats. That is why CSIRTs share security alerts and incidents data using various sharing platforms. Even though they do so primarily to protect data and privacy of users, their use also lead to additional processing of personal data, which may cause new privacy risks. European data protection law, especially with the adoption of the new General data protection regulation, sets out very strict rules on processing of personal data which on one hand leads to greater protection of individual's rights, but on the other creates great obstacles for those who need to share any personal data. This paper analyses the General Data Protection Regulation (GDPR), relevant case-law and analyses by the Article 29 Working Party to propose optimal methods and level of personal data processing necessary for effective use of security alert sharing platforms, which would be legally compliant and lead to appropriate balance between risks.
C1  - New York, NY, USA
C3  - Proceedings of the 12th International Conference on Availability, Reliability and Security
DA  - 2017///
PY  - 2017
DO  - 10.1145/3098954.3105822
PB  - Association for Computing Machinery
SN  - 978-1-4503-5257-4
UR  - https://doi.org/10.1145/3098954.3105822
KW  - Alert sharing platform
KW  - Cyber security
KW  - Information sharing
KW  - Intrusion detection
KW  - Personal data
KW  - Privacy
ER  - 

TY  - CONF
TI  - Impossible Explanations? Beyond Explainable AI in the GDPR from a COVID-19 Use Case Scenario
AU  - Hamon, Ronan
AU  - Junklewitz, Henrik
AU  - Malgieri, Gianclaudio
AU  - Hert, Paul De
AU  - Beslay, Laurent
AU  - Sanchez, Ignacio
T3  - FAccT '21
AB  - Can we achieve an adequate level of explanation for complex machine learning models in high-risk AI applications when applying the EU data protection framework? In this article, we address this question, analysing from a multidisciplinary point of view the connection between existing legal requirements for the explainability of AI systems and the current state of the art in the field of explainable AI.We present a case study of a real-life scenario designed to illustrate the application of an AI-based automated decision making process for the medical diagnosis of COVID-19 patients. The scenario exemplifies the trend in the usage of increasingly complex machine-learning algorithms with growing dimensionality of data and model parameters. Based on this setting, we analyse the challenges of providing human legible explanations in practice and we discuss their legal implications following the General Data Protection Regulation (GDPR).Although it might appear that there is just one single form of explanation in the GDPR, we conclude that the context in which the decision-making system operates requires that several forms of explanation are considered. Thus, we propose to design explanations in multiple forms, depending on: the moment of the disclosure of the explanation (either ex ante or ex post); the audience of the explanation (explanation for an expert or a data controller and explanation for the final data subject); the layer of granularity (such as general, group-based or individual explanations); the level of the risks of the automated decision regarding fundamental rights and freedoms. Consequently, explanations should embrace this multifaceted environment.Furthermore, we highlight how the current inability of complex, deep learning based machine learning models to make clear causal links between input data and final decisions represents a limitation for providing exact, human-legible reasons behind specific decisions. This makes the provision of satisfactorily, fair and transparent explanations a serious challenge. Therefore, there are cases where the quality of possible explanations might not be assessed as an adequate safeguard for automated decision-making processes under Article 22(3) GDPR. Accordingly, we suggest that further research should focus on alternative tools in the GDPR (such as algorithmic impact assessments from Article 35 GDPR or algorithmic lawfulness justifications) that might be considered to complement the explanations of automated decision-making.
C1  - New York, NY, USA
C3  - Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency
DA  - 2021///
PY  - 2021
DO  - 10.1145/3442188.3445917
SP  - 549
EP  - 559
PB  - Association for Computing Machinery
SN  - 978-1-4503-8309-7
UR  - https://doi.org/10.1145/3442188.3445917
KW  - AI
KW  - Automated Decision-Making
KW  - Black-Box
KW  - Data Protection
KW  - Explainability
KW  - GDPR
KW  - Machine Learning
ER  - 

TY  - JOUR
TI  - An Analysis of the Consequences of the General Data Protection Regulation on Social Network Research
AU  - Kotsios, Andreas
AU  - Magnani, Matteo
AU  - Vega, Davide
AU  - Rossi, Luca
AU  - Shklovski, Irina
T2  - Trans. Soc. Comput.
AB  - This article examines the principles outlined in the General Data Protection Regulation in the context of social network data. We provide both a practical guide to General Data Protection Regulation–compliant social network data processing, covering aspects such as data collection, consent, anonymization, and data analysis, and a broader discussion of the problems emerging when the general principles on which the regulation is based are instantiated for this research area.
DA  - 2019/12//
PY  - 2019
DO  - 10.1145/3365524
VL  - 2
IS  - 3
UR  - https://doi.org/10.1145/3365524
KW  - GDPR
KW  - General Data Protection Regulation
KW  - social media
KW  - social network analysis
ER  - 

TY  - CONF
TI  - Initial Survey of Smart Grid Activities in the Norwegian Energy Sector: Use Cases, Industrial Challenges and Implications for Research
AU  - Oyetoyan, Tosin Daniel
AU  - Conradi, Reidar
AU  - Sand, Kjell
T3  - SE4SG '12
AB  - Understanding user requirements and technological challenges for Smart Grid is important to deliver competitive and visionary products and services, and thus to shape the direction of research and development. Since Smart Grid is still in the formation stage with many stakeholders, we should quickly develop consensual and pragmatic international standards and strategies. Our goal is to assess the feasibility of proposed Smart Grid requirements, formulated as 16 generic use-cases by an EU working group, and to identify attitudes, products, services and future technologies. Subsequently, we want to provide information on identified gaps between technologies, functionalities and stakeholders' views, and future direction. We have designed and carried out an initial industrial survey in Norway on how generic use-cases for Smart Grid activities are interpreted by 6 representative stakeholders in the Norwegian energy sector. To achieve this goal, we designed a survey with metrics built on and around these use-cases. Our results showed that the users' work experience and views on the functionality expressed in the use-cases revealed a gap in focus and culture. Also, there was no agreement on what the term "Smart Grid" stood for. In addition, the relevance of Smart Grid functionalities is shown to vary over time and with different stakeholders. The pre-study results indicated that there is potential for using information from future data collected from over 270 actors to bridge gaps and focus on Smart Grid research and development.
C3  - Proceedings of the First International Workshop on Software Engineering Challenges for the Smart Grid
DA  - 2012///
PY  - 2012
SP  - 34
EP  - 37
PB  - IEEE Press
SN  - 978-1-4673-1864-8
KW  - Norwegian energy industry
KW  - pre-study
KW  - requirements
KW  - smart grid usage
KW  - stakeholders
KW  - survey
KW  - use-case
ER  - 

TY  - CONF
TI  - Towards Decentralised Learning Analytics (Positioning Paper)
AU  - Ekuban, Audrey
AU  - Domingue, John
T3  - WWW '23 Companion
AB  - When students interact with an online course, the routes they take when navigating through the course can be captured. Learning Analytics is the process of measuring, collecting, recording, and analysing this Student Activity Data. Predictive Learning Analytics, a sub-field of Learning Analytics, can help to identify students who are at risk of dropping out or failing, as well as students who are close to a grade boundary. Course tutors can use the insights provided by the analyses to offer timely assistance to these students. Despite its usefulness, there are privacy and ethical issues with the typically centralised approach to Predictive Learning Analytics. In this positioning paper, it is proposed that the issues associated with Predictive Learning Analytics can be alleviated, in a framework called EMPRESS, by combining 1) self-sovereign data, where data owners control who legitimately has access to data pertaining to them, 2) Federated Learning, where the data remains on the data owner’s device and/or the data is processed by the data owners themselves, and 3) Graph Convolutional Networks for Heterogeneous graphs, which are examples of knowledge graphs.
C1  - New York, NY, USA
C3  - Companion Proceedings of the ACM Web Conference 2023
DA  - 2023///
PY  - 2023
DO  - 10.1145/3543873.3587644
SP  - 1435
EP  - 1438
PB  - Association for Computing Machinery
SN  - 978-1-4503-9419-2
UR  - https://doi.org/10.1145/3543873.3587644
KW  - blockchain
KW  - federated learning
KW  - heterogeneous knowledge graph
KW  - learning analytics
ER  - 

TY  - CONF
TI  - A Sociotechnical Audit: Assessing Police Use of Facial Recognition
AU  - Radiya-Dixit, Evani
AU  - Neff, Gina
T3  - FAccT '23
AB  - Algorithmic audits are increasingly used to hold people accountable for the algorithms they implement. However, much work remains to integrate ethical and legal evaluations of how algorithms are used into audits. In this paper, we present a sociotechnical audit to help external stakeholders evaluate the ethics and legality of police use of facial recognition technology. We developed this audit for the specific legal context of England and Wales, and to bring attention to broader concerns such as whether police consult affected communities and comply with human rights law. To design this audit, we compiled ethical and legal standards for governing facial recognition, based on existing literature and feedback from academia, government, civil society, and police organizations. We then applied the resulting audit tool to three facial recognition deployments by police forces in the UK and found that all three failed to meet these standards. Developing this audit helps us provide insights to researchers in designing their own sociotechnical audits, specifically how audits shift power, how to make audits context-specific, how audits reveal what is not transparent, and how audits lead to accountability.
C1  - New York, NY, USA
C3  - Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency
DA  - 2023///
PY  - 2023
DO  - 10.1145/3593013.3594084
SP  - 1334
EP  - 1346
PB  - Association for Computing Machinery
SN  - 9798400701924
UR  - https://doi.org/10.1145/3593013.3594084
KW  - accountability
KW  - algorithmic audits
KW  - ethical and legal considerations
KW  - facial recognition technology
ER  - 

TY  - CONF
TI  - Analyzing GDPR Compliance of Named Data Networking
AU  - Tran, Casey
AU  - Tourani, Reza
AU  - Misra, Satyajayant
AU  - Machacek, Travis
AU  - Panwar, Gaurav
T3  - ICN '21
AB  - The popularity of social media platforms, Internet of Things (IoT) devices, and the myriad smartphone applications have created opportunities for companies and organizations to collect individuals' personal data and monetize its sharing at a high rate. A standout example was the Facebook–Cambridge Analytica data-sharing arrangement (2018), which allowed Cambridge Analytica to harvest millions of Facebook users' personal data without their consent for political advertisement. In response to such overreach and privacy violations, the European Union introduced the General Data Protection Regulation (GDPR), which mandates data collectors to protect individuals' data privacy and provide the user more control over their personal data. Motivated by this growing interest in personal privacy, we analyze GDPR articles in the context of Named Data Networking (NDN). The context of interest is NDN as the network architecture in a service provider and we investigate GDPR-pertinent NDN features, including naming, caching, forwarding plane, and its built-in trust, for GDPR compliance and present insights on how such compliance can be built, when lacking. We also present experimental results showing compliance overheads and conclude by identifying potential future work.
C1  - New York, NY, USA
C3  - Proceedings of the 8th ACM Conference on Information-Centric Networking
DA  - 2021///
PY  - 2021
DO  - 10.1145/3460417.3482979
SP  - 107
EP  - 117
PB  - Association for Computing Machinery
SN  - 978-1-4503-8460-5
UR  - https://doi.org/10.1145/3460417.3482979
KW  - GDPR
KW  - ICN
KW  - NDN
KW  - privacy
KW  - security
ER  - 

TY  - CONF
TI  - Assessing the Impact of Medical AI: A Survey of Physicians’ Perceptions
AU  - Cabitza, Federico
AU  - Campagner, Andrea
AU  - Cavosi, Valentina
T3  - ICMHI '21
AB  - In this paper we present a lightweight psychometric tool that we developed and published online to involve medical practitioners and specialists in the impact assessment of some general negative effects of medical Artificial Intelligence on their practice and profession. This tool can be adopted in, and possibly adapted to, different settings, to perform more focused AI impact assessment within specific medical settings. We applied the tool to a large and heterogeneous sample of medical doctors (N=121) and we discuss the main findings from this user study.
C1  - New York, NY, USA
C3  - Proceedings of the 5th International Conference on Medical and Health Informatics
DA  - 2021///
PY  - 2021
DO  - 10.1145/3472813.3473195
SP  - 225
EP  - 231
PB  - Association for Computing Machinery
SN  - 978-1-4503-8984-6
UR  - https://doi.org/10.1145/3472813.3473195
KW  - Algorithmic Impact Assessment
KW  - Artificial Intelligence Impact Assessment
KW  - medical artificial intelligence
KW  - unintended consequences of automated decision systems
ER  - 

TY  - CONF
TI  - New Trends on CAATTs: What Are the Chartered Accountants' New Challenges?
AU  - Pedrosa, Isabel
AU  - Costa, Carlos J.
T3  - ISDOC '14
AB  - Computer Assisted Audit Tools and Techniques, CAATTs, represent nowadays a regular presence on Chartered Accountants', CAs, daily tasks: several previous researches state that Generalized Audit Software is present in CAs' routines and some specific tools are conquering their space among these professionals' preferences. Present research reveals that "Data Extraction and Analytics" and "Sampling" tools are the most common Information Technologies on Auditing work. Computer Assisted Techniques related to data mining are still not expressive in this reference group or are only utilized by a small group of experts, mainly at big companies. New trends on CAATTs are rising mainly as a consequence of changes in business and technology. This paper intends to draw the big picture on that topic and anticipate new trends on the area: Big Data, Cloud Auditing, Emerging Technologies will be presented. This paper discusses also how can auditors be prepared to the new trends and proposes a new classification for Computer Assisted Audit Tools and Techniques.
C1  - New York, NY, USA
C3  - Proceedings of the International Conference on Information Systems and Design of Communication
DA  - 2014///
PY  - 2014
DO  - 10.1145/2618168.2618190
SP  - 138
EP  - 142
PB  - Association for Computing Machinery
SN  - 978-1-4503-2713-8
UR  - https://doi.org/10.1145/2618168.2618190
KW  - big data
KW  - BYOD
KW  - chartered accountants
KW  - cloud auditing
KW  - cloud computing
KW  - computer assisted audit tools
KW  - emerging technologies
ER  - 

TY  - CONF
TI  - Integrating Security and Privacy in HCD-Scrum
AU  - Teresa Baldassarre, Maria
AU  - Santa Barletta, Vita
AU  - Caivano, Danilo
AU  - Piccinno, Antonio
T3  - CHItaly '21
AB  - Nowadays, software development must face the challenge of integrating security and privacy elements from the earliest stages of any software development process. A correct and complete implementation starting from the requirements definition allows to significantly increase the security level of each single phase/iteration and consequently of the final system. Therefore, it is necessary to support the team throughout the software lifecycle trying to provide operational guidelines of security by design and privacy by design. Taking these aspects into account, the paper presents a Human Centered Design (HCD) approach of security and privacy-oriented software development, integrated within the Scrum agile methodology, defined as HCD-Security Scrum. The goal is to support developer decisions at all stages of software development in integrating security and privacy requirements through the formalization of key elements defined in a knowledge base, i.e., the Privacy Knowledge Base.
C1  - New York, NY, USA
C3  - Proceedings of the 14th Biannual Conference of the Italian SIGCHI Chapter
DA  - 2021///
PY  - 2021
DO  - 10.1145/3464385.3464746
PB  - Association for Computing Machinery
SN  - 978-1-4503-8977-8
UR  - https://doi.org/10.1145/3464385.3464746
KW  - Agile Methods
KW  - Human-Centered Privacy
KW  - Privacy by Design
KW  - Privacy Software Application
KW  - Security by Design
ER  - 

TY  - CONF
TI  - Agora: A Collaborative Virtual Learning Environment
AU  - Timpson, Corey
AU  - Chartrand, Valérie
T3  - SIGGRAPH '07
AB  - The Virtual Museum of Canada (VMC), developed by the Canadian Heritage Information Network (CHIN), is a portal that brings Canada's rich and diverse heritage into Canadian homes and schools. The VMC gives member museums the ability to reach Canadians and an international audience via the Internet.
C1  - New York, NY, USA
C3  - ACM SIGGRAPH 2007 Educators Program
DA  - 2007///
PY  - 2007
DO  - 10.1145/1282040.1282045
SP  - 4
EP  - es
PB  - Association for Computing Machinery
SN  - 978-1-4503-1830-3
UR  - https://doi.org/10.1145/1282040.1282045
ER  - 

TY  - CONF
TI  - Teaching Data Ethics: We're Going to Ethics the Heck out of This
AU  - Henderson, Tristan
T3  - CEP '19
AB  - This paper outlines a new Data Ethics &amp; Privacy module that was introduced to computer science students in 2018. The module aims to raise student awareness of current debates in computer science such as bias in artificial intelligence, algorithmic accountability, filter bubbles and data protection, and practical mechanisms for addressing these issues. To do this, the module includes interdisciplinary content from ethics, law and computer science, and also adopts some teaching methods from the law. I describe the format of the module, challenges with module design and approval, some initial comments on the first year's cohort, and plans for future improvements. I believe that the topic is currently important and this discussion might be of interest to other computer science departments considering the introduction of similar content.
C1  - New York, NY, USA
C3  - Proceedings of the 3rd Conference on Computing Education Practice
DA  - 2019///
PY  - 2019
DO  - 10.1145/3294016.3294017
PB  - Association for Computing Machinery
SN  - 978-1-4503-6631-1
UR  - https://doi.org/10.1145/3294016.3294017
KW  - algorithmic accountability
KW  - data ethics
KW  - education
ER  - 

TY  - JOUR
TI  - The Privacy Implications of Cyber Security Systems: A Technological Survey
AU  - Toch, Eran
AU  - Bettini, Claudio
AU  - Shmueli, Erez
AU  - Radaelli, Laura
AU  - Lanzi, Andrea
AU  - Riboni, Daniele
AU  - Lepri, Bruno
T2  - ACM Comput. Surv.
AB  - Cyber-security systems, which protect networks and computers against cyber attacks, are becoming common due to increasing threats and government regulation. At the same time, the enormous amount of data gathered by cyber-security systems poses a serious threat to the privacy of the people protected by those systems. To ground this threat, we survey common and novel cyber-security technologies and analyze them according to the potential for privacy invasion. We suggest a taxonomy for privacy risks assessment of information security technologies, based on the level of data exposure, the level of identification of individual users, the data sensitivity and the user control over the monitoring, and collection and analysis of the data. We discuss our results in light of the recent technological trends and suggest several new directions for making these mechanisms more privacy-aware.
DA  - 2018/02//
PY  - 2018
DO  - 10.1145/3172869
VL  - 51
IS  - 2
SN  - 0360-0300
UR  - https://doi.org/10.1145/3172869
KW  - Information security
KW  - network surveillance
KW  - privacy
KW  - privacy-preserving methods
KW  - system monitoring
ER  - 

TY  - CONF
TI  - EPC RFID Tag Security Weaknesses and Defenses: Passport Cards, Enhanced Drivers Licenses, and Beyond
AU  - Koscher, Karl
AU  - Juels, Ari
AU  - Brajkovic, Vjekoslav
AU  - Kohno, Tadayoshi
T3  - CCS '09
AB  - EPC (Electronic Product Code) tags are industry-standard RFID devices poised to supplant optical barcodes in many applications. We explore the systemic risks and challenges created by the increasingly common use of EPC for security applications. As a central case study, we examine the recently issued United States Passport Card and Washington State "enhanced drivers license" (WA EDL), both of which incorporate Gen-2 EPC tags. We measure multiple weaknesses, including susceptibility to cloning, extended read ranges, and the ability to remotely kill a WA EDL. We study the implications of these vulnerabilities to overall system security, and offer suggestions for improvement. We demonstrate anti-cloning techniques for off-the-shelf EPC tags, overcoming practical challenges in a previous proposal to co-opt the EPC "kill" command to achieve tag authentication. Our paper fills a vacuum of experimentally grounded evaluation of and guidance for security applications for EPC tags not just in identity documents, but more broadly in the authentication of objects and people.
C1  - New York, NY, USA
C3  - Proceedings of the 16th ACM Conference on Computer and Communications Security
DA  - 2009///
PY  - 2009
DO  - 10.1145/1653662.1653668
SP  - 33
EP  - 42
PB  - Association for Computing Machinery
SN  - 978-1-60558-894-0
UR  - https://doi.org/10.1145/1653662.1653668
KW  - authentication
KW  - cloning
KW  - epc
KW  - passport card
KW  - rfid
KW  - whti
ER  - 

TY  - CONF
TI  - Compliance Performance of a Large Local Company to Electronic Commerce Act of 2000 and Data Privacy Act of 2012: A Case Study Approach
AU  - Tirante, Geraldine A.
AU  - Ching, Michelle Renee D.
T3  - ICEEG '18
AB  - Electronic commerce and data privacy have become a very important aspect of performing business in the Philippines. This research study aims to ascertain the compliance performance of a large local company to the Electronic Commerce Act of 2000 (R.A. 8792) and Data Privacy Act of 2012 (R.A. 10173). Through Outcome Pattern Matching, it has been determined that, though the company is fully compliant with the applicable sections of R.A. 8792, it is Partially Compliant (High) to R.A. 10173 with few challenge areas. Using Benchmarking Process, this research study also recommends factors that could improve the compliance performance of the company. The following dimensions should be considered: (1) spontaneous compliance, (2) control and (3) sanctions. Further, the company should take into account not just the legal aspects of the Republic Acts but also the value-based ethics and business case of compliance.
C1  - New York, NY, USA
C3  - Proceedings of the 2nd International Conference on E-Commerce, E-Business and E-Government
DA  - 2018///
PY  - 2018
DO  - 10.1145/3234781.3234793
SP  - 84
EP  - 89
PB  - Association for Computing Machinery
SN  - 978-1-4503-6490-4
UR  - https://doi.org/10.1145/3234781.3234793
KW  - benchmarking
KW  - data privacy act of 2012
KW  - electronic commerce act of 2000
KW  - pattern matching
KW  - RA10173
KW  - RA8792
ER  - 

TY  - CONF
TI  - Digital Safety Alarms – Exploring the Understandings of the Cybersecurity Practice in Norwegian Municipalities
AU  - Skjelvik, Alvhild
AU  - Vestad, Arnstein
T3  - EICC '23
AB  - In this paper we describe initial results from a qualitative study on municipal approaches to cybersecurity in welfare technology or medical IoT. The paper is based on interviews with stakeholders from municipal IT and health services where digital safety alarms are used as a case to study how stakeholders with differing perspectives communicate and cooperate to secure these solutions. We identify three key issues related to the factors that motivate the municipalities to perform cybersecurity work and how different perspectives between IT and healthcare affect this, and discuss these findings utilizing protection motivation theory. We further discuss the need for shared understanding of cybersecurity and risk between health and IT as well as how municipalities are approaching to bridge this gap
C1  - New York, NY, USA
C3  - Proceedings of the 2023 European Interdisciplinary Cybersecurity Conference
DA  - 2023///
PY  - 2023
DO  - 10.1145/3590777.3590798
SP  - 129
EP  - 133
PB  - Association for Computing Machinery
SN  - 978-1-4503-9829-9
UR  - https://doi.org/10.1145/3590777.3590798
ER  - 

TY  - CONF
TI  - A Framework for Preserving Privacy in Cloud Computing with User Service Dependent Identity
AU  - Rahaman, Syed Mujib
AU  - Farhatullah, Mohammad
T3  - ICACCI '12
AB  - The widespread focus on the Cloud Computing has necessitated the corresponding mechanisms to ensure privacy and security. Various attempts have been made in the past to safeguard the privacy of the individual or agency trying to utilize the services being provided by the cloud. The most challenging task is to provide services to the users while also preserving the privacy of the user's information. In this paper a model that incorporates a three-level architecture, Preserving cloud computing Privacy (PccP) model is proposed which aims to preserve privacy of information pertaining to cloud users. The Consumer Layer deals with all the aspects which relate to enabling the user of the cloud to access the cloud services being provided by the cloud service provider. The Network Interface Layer creates an appropriate mapping between the original IP addresses of the users with a modified IP address, and thereby ensuring the privacy of the IP address of the users. The Privacy Preserved Layer utilizes the functionality of the Unique User Cloud Identity Generator for which an algorithm is proposed in this paper to generate an unique User Service Dependent Identity (USID) with privacy check by establishing mapping among the existing user identity (ID), if any to ID's available in a pool of User ID's to enhance the privacy of sensitive user information.
C1  - New York, NY, USA
C3  - Proceedings of the International Conference on Advances in Computing, Communications and Informatics
DA  - 2012///
PY  - 2012
DO  - 10.1145/2345396.2345419
SP  - 133
EP  - 136
PB  - Association for Computing Machinery
SN  - 978-1-4503-1196-0
UR  - https://doi.org/10.1145/2345396.2345419
KW  - cloud
KW  - identity
KW  - privacy
ER  - 

TY  - CONF
TI  - A Service Model for Network Security Applications
AU  - Ricciulli, Livio
T3  - CSIIRW '10
AB  - We describe a new architecture designed to outsource the complexity of configuring, deploying and operating network security monitoring systems. Our architecture is designed to allow the concurrent operation of best-of-breed network security applications which include flow analysis, Intrusion Detection Systems (IDS), passive Operating System (OS) fingerprinting and application-level service discovery. In addition, we introduce a new framework for the inclusion of network security intelligence data into the security event correlation. We also provide some preliminary quantification of the effectiveness of this new framework.
C1  - New York, NY, USA
C3  - Proceedings of the Sixth Annual Workshop on Cyber Security and Information Intelligence Research
DA  - 2010///
PY  - 2010
DO  - 10.1145/1852666.1852721
PB  - Association for Computing Machinery
SN  - 978-1-4503-0017-9
UR  - https://doi.org/10.1145/1852666.1852721
KW  - anomaly detection
KW  - cloud computing
KW  - cyber-security
KW  - honeypot
KW  - intrusion detection
KW  - management system
KW  - network security
KW  - sensor
ER  - 

TY  - CONF
TI  - Privacy in Times of COVID-19: A Pilot Study in the Republic of Ireland
AU  - Xie, Guodong
AU  - Lohar, Pintu
AU  - Florea, Claudia
AU  - Bendechache, Malika
AU  - Trestian, Ramona
AU  - Brennan, Rob
AU  - Connolly, Regina
AU  - Tal, Irina
T3  - ARES '21
AB  - Contact tracing apps used in tracing and mitigating the spread of COVID-19 have sparked discussions and controversies worldwide with major concerns around privacy. COVID Tracker app used in the Republic of Ireland was praised in general for the way it addressed privacy and was used as baseline for other contact tracing apps worldwide. The success of the app is dependent on the general public uptake, hence their voice and attitude is the one that really matters. This paper focuses on developing a survey and the methods aiming to examine the attitudes toward privacy during COVID-19 of the general public in the Republic of Ireland and their impact on the uptake of the COVID tracker app. Various privacy models are used and health belief model as well in this purpose. A pilot study with 286 participants show a change in attitude towards privacy during COVID-19 pandemic, with more people willing to share their data in the interest of saving lives. However, privacy attitudes are shown to have impacted the adoption of the app in Ireland.
C1  - New York, NY, USA
C3  - Proceedings of the 16th International Conference on Availability, Reliability and Security
DA  - 2021///
PY  - 2021
DO  - 10.1145/3465481.3470096
PB  - Association for Computing Machinery
SN  - 978-1-4503-9051-4
UR  - https://doi.org/10.1145/3465481.3470096
KW  - COVID-19
KW  - health belief model
KW  - Privacy
KW  - privacy segmentation index
KW  - tracker app
ER  - 

TY  - CONF
TI  - A Study on Developing Framework for Information Privacy Protection
AU  - Jung, Jinwoo
AU  - Kim, Jungduk
T3  - ICEC '15
AB  - Although Information privacy is one of the biggest issues in the enterprises, privacy incidents are relatively increasing because most companies concern privacy protection as a short term project not like an essential factor which needs to be considered consistently. IP3 (Information privacy protection program) means that the program which should be conducted continuously as a background program in enterprises. If the operation or design of privacy protection is inappropriately implemented in an enterprise, they must pay for the failure of information privacy protection because it is closely relative to customer and their trust toward the enterprise. Therefore appropriate information privacy protection program is required to prevent loss of trust. This study intends to analyze the topic of information privacy and proposes an information privacy program framework. The framework consists of 4 domains, 18 indicators and 59 metrics to cover the necessary components of the information privacy program. The proposed framework for information privacy protection program is pilot tested to identify the strength; it is measured by proposed indicators to realize a real condition and feasible object of information privacy protection program framework. The results are positive in terms of their materiality and feasibility by conducting focus group interviews with five privacy managers.
C1  - New York, NY, USA
C3  - Proceedings of the 17th International Conference on Electronic Commerce 2015
DA  - 2015///
PY  - 2015
DO  - 10.1145/2781562.2781599
PB  - Association for Computing Machinery
SN  - 978-1-4503-3461-7
UR  - https://doi.org/10.1145/2781562.2781599
KW  - Information Privacy
KW  - Information Privacy Protection Program
KW  - Privacy Protection model
ER  - 

TY  - CONF
TI  - Privacy Considerations for a Pervasive Eye Tracking World
AU  - Liebling, Daniel J.
AU  - Preibusch, Sören
T3  - UbiComp '14 Adjunct
AB  - Multiple vendors now provide relatively inexpensive desktop eye and gaze tracking devices. With miniature-ization and decreasing manufacturing costs, gaze trackers will follow the path of webcams, becoming ubiquitous and inviting many of the same privacy concerns. However, whereas the privacy loss from webcams may be obvious to the user, gaze tracking is more opaque and deserves special attention. In this paper, we review current research in gaze tracking and pupillometry and argue that gaze data should be protected by both policy and good data hygiene.
C1  - New York, NY, USA
C3  - Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct Publication
DA  - 2014///
PY  - 2014
DO  - 10.1145/2638728.2641688
SP  - 1169
EP  - 1177
PB  - Association for Computing Machinery
SN  - 978-1-4503-3047-3
UR  - https://doi.org/10.1145/2638728.2641688
KW  - biometrics
KW  - eye tracking
KW  - gaze tracking
KW  - privacy
ER  - 

TY  - CONF
TI  - The Value of Personal Data is the Data Protection and Privacy Preliminary Condition: Synthetic Human Profiles on the Web and Ethics
AU  - Fabiano, Nicola
T3  - APPIS 2020
AB  - The EU Regulation 2016/679 (GDPR) is a landmark, and we describe the value of personal data as the main starting point to address any possible issue. Once clarified the meaning of that value as a top-level point from which it not possible prescind and the strict relationship with ethics, we present one of the risks, that is the 'synthetic human profile' and can be realised by the use of faces images available on the web. In conclusion, we propose a blockchain system to guarantee the data subjects identity.
C1  - New York, NY, USA
C3  - Proceedings of the 3rd International Conference on Applications of Intelligent Systems
DA  - 2020///
PY  - 2020
DO  - 10.1145/3378184.3378231
PB  - Association for Computing Machinery
SN  - 978-1-4503-7630-3
UR  - https://doi.org/10.1145/3378184.3378231
KW  - Blockchain
KW  - Data Protection
KW  - Ethics
KW  - Privacy
KW  - Synthetic human profile
KW  - Value of personal data
ER  - 

TY  - CONF
TI  - Accountable Health Care Service Provisioning in the Cloud
AU  - Bernsmed, Karin
T3  - UCC '14
AB  - Cloud computing has received a great deal of attention during the past few years. However, processing data remotely in unknown systems creates a number of challenges related to data privacy and security, which may hinder the adoption of cloud technology in, for example, the health care domain. This paper presents results from the ongoing EU FP7 research project, which aims to provide mechanism and tools to enable organisations involved in cloud service delivery chains to act as responsible stewards for the personal data that they process. We outline a number of accountability obligations that will arise in a health care scenario and explain how the project results can be used to meet these challenges.
C1  - USA
C3  - Proceedings of the 2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing
DA  - 2014///
PY  - 2014
DO  - 10.1109/UCC.2014.147
SP  - 902
EP  - 907
PB  - IEEE Computer Society
SN  - 978-1-4799-7881-6
UR  - https://doi.org/10.1109/UCC.2014.147
KW  - A4Cloud
KW  - accountability
KW  - cloud
KW  - governance
KW  - health care
KW  - privacy
KW  - security
ER  - 

TY  - JOUR
TI  - How Fragmentation Can Undermine the Public Health Response to Covid-19
AU  - Chen, Andrew Tzer-Yeu
T2  - Interactions
DA  - 2021/03//
PY  - 2021
DO  - 10.1145/3448413
VL  - 28
IS  - 2
SP  - 64
EP  - 69
SN  - 1072-5520
UR  - https://doi.org/10.1145/3448413
ER  - 

TY  - CONF
TI  - Forgeability and Membership Inference Attacks
AU  - Kong, Zhifeng
AU  - Roy Chowdhury, Amrita
AU  - Chaudhuri, Kamalika
T3  - AISec'22
AB  - A membership inference (MI) attack predicts whether a data point was used for training a machine learning (ML) model. MI attacks are currently the most widely deployed attack for auditing privacy of a ML model. A recent work by Thudi et. al. [18] show that approximate machine unlearning is ill-defined. For this, they introduce the notion of forgeability where using forged datasets, one could unlearn without modifying the model at all. In this paper, we show a connection between machine unlearning and membership inferencing. Specifically, we study how to leverage forgeability to repudiate claims on membership inferencing. We show that the ability to forge enables the dataset owner to construct a Proof-of-Repudiation (PoR) which empowers the dataset owner to plausibly repudiate the predictions of an MI attack. This casts a doubt on the reliability of MI attacks in practice. Our empirical evaluations show that it is possible to construct PoRs efficiently.
C1  - New York, NY, USA
C3  - Proceedings of the 15th ACM Workshop on Artificial Intelligence and Security
DA  - 2022///
PY  - 2022
DO  - 10.1145/3560830.3563731
SP  - 25
EP  - 31
PB  - Association for Computing Machinery
SN  - 978-1-4503-9880-0
UR  - https://doi.org/10.1145/3560830.3563731
KW  - machine learning privacy
KW  - membership inferencing
ER  - 

TY  - CONF
TI  - Assessing Compliance of Philippine State Universities to the Data Privacy Act of 2012: The Case of Caraga State University
AU  - Presbitero, James V.
AU  - Ching, Michelle Renee D.
T3  - ICEEG '18
AB  - The Philippine Data Privacy Act of 2012 (DPA of 2012) defined the rights of Filipino citizens to data privacy and created the National Privacy Commission to monitor compliance, by both public agencies and private organizations, to the said law to ensure data protection and rights of privacy of its citizens. This study aims to explore and explain why and how public universities of the Philippines, with the Caraga State University as the subject, would comply with DPA of 2012. Using a single case holistic design with common rationale, and pattern matching as an analytic technique as adapted by Yin's method and design. This study has shown that the e-Commerce Act, another law legislated previously, is a moderating factor in compliance with the Data Privacy Act, and that general deterrence and legitimacy of regulations has a compelling casual effect on complying with the DPA of 2012. Factors such as (1) lack of awareness, (2) lack of resources, and (3) low priority in the agenda are found to be critical factors in complying with DPA of 2012. It was also found that the Caraga State University is only partially compliant (Medium-High) to the provisions of DPA 2012.
C1  - New York, NY, USA
C3  - Proceedings of the 2nd International Conference on E-Commerce, E-Business and E-Government
DA  - 2018///
PY  - 2018
DO  - 10.1145/3234781.3234800
SP  - 90
EP  - 94
PB  - Association for Computing Machinery
SN  - 978-1-4503-6490-4
UR  - https://doi.org/10.1145/3234781.3234800
KW  - data privacy
KW  - data privacy compliance
KW  - e-governance
KW  - personal information
ER  - 

TY  - CONF
TI  - Privacy and Information Protection for a New Generation of City Services
AU  - Dominguez, Hector
AU  - Mowry, Judith
AU  - Perez, Elisabeth
AU  - Kendrick, Christine
AU  - Martin, Kevin
T3  - SCC '19
AB  - This paper will showcase the work that the City of Portland has done around developing Privacy and Information Protection Principles considering the current state of technology, the social digital age, and advance inference algorithms like machine learning or other Artificial Intelligence tools. By creating more responsible data stewardship in the public sector, municipalities are set to build trusted information networks involving communities and complex social issues. Particularly, the promotion of data privacy can lead to the emergence of anti-poverty and economic development strategies.The City of Portland has developed seven Privacy and Information Protection Principles: Transparency and accountability, full lifecycle stewardship, equitable data management, ethical and non-discriminatory use of data, data openness, automated decision systems, and data utility. These principles have implications in social equity and the future of technology management in smart cities projects. Principle implementation involves the collaboration of different agencies, particularly focused on ethics and human rights supporting sustainable development.This work is part of emergent strategies for a new generation of city services based on data and information, which aim to improve civic engagement, social benefits to communities in city neighborhoods and better collaboration with partners and other government agencies.
C1  - New York, NY, USA
C3  - Proceedings of the 2nd ACM/EIGSCC Symposium on Smart Cities and Communities
DA  - 2019///
PY  - 2019
DO  - 10.1145/3357492.3358628
PB  - Association for Computing Machinery
SN  - 978-1-4503-6978-7
UR  - https://doi.org/10.1145/3357492.3358628
KW  - Automatic decision systems
KW  - Digital equity
KW  - Digital Inclusion
KW  - government services
KW  - Privacy
ER  - 

TY  - CONF
TI  - A Cloud Adoption Risk Assessment Model
AU  - Cayirci, Erdal
AU  - Garaga, Alexandr
AU  - Santana, Anderson
AU  - Roudier, Yves
T3  - UCC '14
AB  - Cloud Adoption Risk Assessment Model is designed for cloud customers to assess the risks that they face by selecting a specific cloud service provider. It is an expert system to evaluate various background information obtained from cloud customers, cloud service providers and other public external sources, and to analyze various risk scenarios. This would facilitate cloud customers in making informed decision to select the cloud service provider with the most preferable risk profile.
C1  - USA
C3  - Proceedings of the 2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing
DA  - 2014///
PY  - 2014
DO  - 10.1109/UCC.2014.148
SP  - 908
EP  - 913
PB  - IEEE Computer Society
SN  - 978-1-4799-7881-6
UR  - https://doi.org/10.1109/UCC.2014.148
KW  - cloud computing
KW  - risk assessment
KW  - security
ER  - 

TY  - CONF
TI  - Designing a Serious Game: Teaching Developers to Embed Privacy into Software Systems
AU  - Arachchilage, Nalin Asanka Gamagedara
AU  - Hameed, Mumtaz Abdul
T3  - ASE '20
AB  - Software applications continue to challenge user privacy when users interact with them. Privacy practices (e.g. Data Minimisation (DM), Privacy by Design (PbD) or General Data Protection Regulation (GDPR)) and related "privacy engineering" methodologies exist and provide clear instructions for developers to implement privacy into software systems they develop that preserve user privacy. However, those practices and methodologies are not yet a common practice in the software development community. There has been no previous research focused on developing "educational" interventions such as serious games to enhance software developers' coding behaviour. Therefore, this research proposes a game design framework as an educational tool for software developers to improve (secure) coding behaviour, so they can develop privacy-preserving software applications that people can use. The elements of the proposed framework were incorporated into a gaming application scenario that enhances the software developers' coding behaviour through their motivation. The proposed work not only enables the development of privacy-preserving software systems but also helping the software development community to put privacy guidelines and engineering methodologies into practice.
C1  - New York, NY, USA
C3  - Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering
DA  - 2021///
PY  - 2021
DO  - 10.1145/3417113.3422149
SP  - 7
EP  - 12
PB  - Association for Computing Machinery
SN  - 978-1-4503-8128-4
UR  - https://doi.org/10.1145/3417113.3422149
KW  - DevSecOps
KW  - privacy-preserving systems
KW  - secure coding
KW  - usable security and privacy
ER  - 

TY  - CONF
TI  - A Data Masking Guideline for Optimizing Insights and Privacy Under GDPR Compliance
AU  - Tachepun, Chitanut
AU  - Thammaboosadee, Sotarat
T3  - IAIT2020
AB  - The General Data Protection Regulation (GDPR) has been enforced since May 2019 and became a disruptive issue to every organization due to its severe penalties in the data breaches or use of personal data for illegal purposes, e.g., lack of the consent of data subject. Therefore, the data Pseudonymization and Anonymization are one of the employed techniques to protect and reduce the privacy risks from the data breach. Unfortunately, they also destroy the pattern of the data, which represents the fact that it could be analyzed or monetized to gain useful insights by data analytics or data science approaches. This paper focuses on optimizing the privacy and insight method that the data could be useful for analyzing and also compliance with the GDPR. This paper proposes the guideline consists of three techniques: tokenization, suppression, and generalization to protect personal data by calculating risk scores from two methods: data classification and data uniqueness. The criteria in the guideline are experimented to achieve the optimized classification performance in protected data compared with five original open data by analyzing with three data mining algorithms with the hyperparameter tuning process. The results show that the protected data by the proposed guideline can protect adequate information and achieve insignificant classification performance when compared to the unprotected data.
C1  - New York, NY, USA
C3  - Proceedings of the 11th International Conference on Advances in Information Technology
DA  - 2020///
PY  - 2020
DO  - 10.1145/3406601.3406627
PB  - Association for Computing Machinery
SN  - 978-1-4503-7759-1
UR  - https://doi.org/10.1145/3406601.3406627
KW  - Data Analytics
KW  - Data Masking
KW  - Data protection
KW  - Data Pseudonymization
KW  - Data Tokenization
KW  - GDPR
ER  - 

TY  - CONF
TI  - Performance Compliance of Philippine National Government Agency on the Data Privacy Act of 2012: A Qualitative Case Study
AU  - Gonzales, Erwin Carlo
AU  - Ching, Michelle Renee D.
T3  - ICEEG '18
AB  - The "Data Privacy Act of 2012" also known as the Republic Act No. 10173 of the Philippines aims to safeguard the personal data of its citizens, this gave rise to the creation of the National Privacy Commission (NPC) in 2015 and this agency is tasked to oversee and enforce the DPA of 2012. This case study aims to explore and understand the underpinning reasons on how the Department of Health (DOH) will comply with RA 10173 and to identify the challenges and determinants to success of the DOH relative to compliance. The research will implore (Yin, 2014) case study method that uses single case holistic design with common rationale and pattern matching for its analytics. This study uses the e-Commerce Act as the moderating variable with DPA 2012 and the determinants of compliance are deterrence, legitimacy and moral obligation. Also, the challenges that were identified in the research were the lack of awareness, budget priorities, and human capital capacity.
C1  - New York, NY, USA
C3  - Proceedings of the 2nd International Conference on E-Commerce, E-Business and E-Government
DA  - 2018///
PY  - 2018
DO  - 10.1145/3234781.3234792
SP  - 79
EP  - 83
PB  - Association for Computing Machinery
SN  - 978-1-4503-6490-4
UR  - https://doi.org/10.1145/3234781.3234792
KW  - compliance
KW  - data privacy
KW  - information security
ER  - 

TY  - CONF
TI  - Robotics, Intelligent Systems, Ethics and Data Protection: The New Challenge
AU  - Fabiano, Nicola
T3  - APPIS '19
AB  - The contribution provides some possible key points in the relationship among robotics, intelligent systems, Artificial Intelligence, Ethics, data protection and privacy. It is relevant to understand that the starting point is the value of personal data because belonging to a natural person. Ethics is one of the aspects that should be considered by everyone to have an excellent approach to the processing of personal data. The contribute provides some possible solutions to read the GDPR considering ethics and proposing other approaches to avoid misuses of personal information.
C1  - New York, NY, USA
C3  - Proceedings of the 2nd International Conference on Applications of Intelligent Systems
DA  - 2019///
PY  - 2019
DO  - 10.1145/3309772.3309787
PB  - Association for Computing Machinery
SN  - 978-1-4503-6085-2
UR  - https://doi.org/10.1145/3309772.3309787
KW  - data protection
KW  - ethics
KW  - intelligent systems
KW  - privacy
KW  - robotics
ER  - 

TY  - CONF
TI  - Privacy-Aware Linked Widgets
AU  - D. Fernández, Javier
AU  - J. Ekaputra, Fajar
AU  - Ruswono Aryan, Peb
AU  - Azzam, Amr
AU  - Kiesling, Elmar
T3  - WWW '19
AB  - The European General Data Protection Regulation (GDPR) brings new challenges for companies, who must demonstrate that their systems and business processes comply with usage constraints specified by data subjects. However, due to the lack of standards, tools, and best practices, many organizations struggle to adapt their infrastructure and processes to ensure and demonstrate that all data processing is in compliance with users’ given consent. The SPECIAL EU H2020 project has developed vocabularies that can formally describe data subjects’ given consent as well as methods that use this description to automatically determine whether processing of the data according to a given policy is compliant with the given consent. Whereas this makes it possible to determine whether processing was compliant or not, integration of the approach into existing line of business applications and ex-ante compliance checking remains an open challenge. In this short paper, we demonstrate how the SPECIAL consent and compliance framework can be integrated into Linked Widgets, a mashup platform, in order to support privacy-aware ad-hoc integration of personal data. The resulting environment makes it possible to create data integration and processing workflows out of components that inherently respect usage policies of the data that is being processed and are able to demonstrate compliance. We provide an overview of the necessary meta data and orchestration towards a privacy-aware linked data mashup platform that automatically respects subjects’ given consents. The evaluation results show the potential of our approach for ex-ante usage policy compliance checking within the Linked Widgets Platforms and beyond.
C1  - New York, NY, USA
C3  - Companion Proceedings of The 2019 World Wide Web Conference
DA  - 2019///
PY  - 2019
DO  - 10.1145/3308560.3317591
SP  - 508
EP  - 514
PB  - Association for Computing Machinery
SN  - 978-1-4503-6675-5
UR  - https://doi.org/10.1145/3308560.3317591
KW  - Compliance
KW  - GDPR
KW  - Linked Data
KW  - Privacy
ER  - 

TY  - CONF
TI  - Towards an "Ethics by Design" Methodology for AI Research Projects
AU  - d'Aquin, Mathieu
AU  - Troullinou, Pinelopi
AU  - O'Connor, Noel E.
AU  - Cullen, Aindrias
AU  - Faller, Gráinne
AU  - Holden, Louise
T3  - AIES '18
AB  - Addressing ethical issues arising from AI research, and by extension from most areas of Data Science, is a core challenge in both the academic and industry worlds. The nature of research and the specific set of technical skills involved imply that AI and Data Science researchers are not equipped to identify and anticipate such issues arising, or to establish solutions at the time a specific research project is being designed. In this paper, we discuss the need for a methodology for ethical research design that involves a broader set of skills from the start of the project. We specifically identify, from the relevant literature, a set of requirements that we argue to be needed for such a methodology. We then explore two case studies where such ethical considerations have been explored in conjunction with the development of specific research projects, in order to validate those assumptions and generalise them into a set of principles guiding an "Ethics by Design" method for conducting AI and Data Science research.
C1  - New York, NY, USA
C3  - Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society
DA  - 2018///
PY  - 2018
DO  - 10.1145/3278721.3278765
SP  - 54
EP  - 59
PB  - Association for Computing Machinery
SN  - 978-1-4503-6012-8
UR  - https://doi.org/10.1145/3278721.3278765
KW  - ai ethics
KW  - data ethics
KW  - data science ethics
KW  - methodology
KW  - privacy by design
ER  - 

TY  - JOUR
TI  - Privacy-Preserving Linkage of Genomic and Clinical Data Sets
AU  - Baker, Dixie B.
AU  - Knoppers, Bartha M.
AU  - Phillips, Mark
AU  - van Enckevort, David
AU  - Kaufmann, Petra
AU  - Lochmuller, Hanns
AU  - Taruscio, Domenica
T2  - IEEE/ACM Trans. Comput. Biol. Bioinformatics
AB  - The capacity to link records associated with the same individual across data sets is a key challenge for data-driven research. The challenge is exacerbated by the potential inclusion of both genomic and clinical data in data sets that may span multiple legal jurisdictions, and by the need to enable re-identification in limited circumstances. Privacy-Preserving Record Linkage PPRL methods address these challenges. In 2016, the Interdisciplinary Committee of the International Rare Diseases Research Consortium IRDiRC launched a task team to explore approaches to PPRL. The task team is a collaboration with the Global Alliance for Genomics and Health GA4GH Regulatory and Ethics and Data Security Work Streams, and aims to prepare policy and technology standards to enable highly reliable linking of records associated with the same individual without disclosing their identity except under conditions in which the use of the data has led to information of importance to the individual's safety or health, and applicable law allows or requires the return of results. The PPRL Task Force has examined the ethico-legal requirements, constraints, and implications of PPRL, and has applied this knowledge to the exploration of technology methods and approaches to PPRL. This paper reports and justifies the findings and recommendations thus far.
DA  - 2019/07//
PY  - 2019
DO  - 10.1109/TCBB.2018.2855125
VL  - 16
IS  - 4
SP  - 1342
EP  - 1348
SN  - 1545-5963
UR  - https://doi.org/10.1109/TCBB.2018.2855125
ER  - 

TY  - CONF
TI  - Curricula Designer with Enhanced ECSF Analysis
AU  - Hajny, Jan
AU  - Sikora, Marek
AU  - Adamos, Konstantinos
AU  - Di Franco, Fabio
T3  - ARES '23
AB  - In late 2022, the novel European Cybersecurity Skills Framework (ECSF) was officially released by the European Union Agency for Cybersecurity (ENISA). It aims to connect cybersecurity education and training with practical needs of the job market. In particular, it maps role profiles, that reflect jobs, to the knowledge and skills they require. One of the first tools that demonstrated ECSF is the Curricula Designer web application that guides cybersecurity study program administrators in designing and analyzing their curricula. In this paper, we present a major update of the Curricula Designer tool. We develop a novel method for course scoring and quantitative analysis of curricula based on the European Credit Transfer and Accumulation System (ECTS) credits. We describe the underlying methods and show their practical implementation into the publicly-available web application. Furthermore, we update the definitions of the Skills, Knowledge and Role Profiles according to the latest ECSF definition and present the mappings in comprehensive matrices in the appendices.
C1  - New York, NY, USA
C3  - Proceedings of the 18th International Conference on Availability, Reliability and Security
DA  - 2023///
PY  - 2023
DO  - 10.1145/3600160.3604987
PB  - Association for Computing Machinery
SN  - 9798400707728
UR  - https://doi.org/10.1145/3600160.3604987
KW  - cybersecurity
KW  - Education
KW  - knowledge
KW  - profiles
KW  - skills
KW  - tools
KW  - training
ER  - 

TY  - CONF
TI  - Which Authentication Method to Choose. A Legal Perspective on User-Device Authentication in IoT Ecosystems
AU  - Timón López, Cristina
AU  - Alamillo Alamillo Domingo, Ignacio
AU  - Valero Valero Torrijos, Julián
T3  - ARES '21
AB  - The IoT has raised a set of challenges due to the enormous amount of data processed and the complex implementation of mechanisms to guarantee these data are exclusively accessed by authorized users. In these ecosystems some devices represent a first “access door” to data obtained from other sources or stored in the Cloud. Consequently, there is a particular need to introduce strong authentication mechanisms that limit unauthorized accesses to thereof. The aim of this paper is to offer a legal perspective on the forces tensioning in the most common authentication methods implemented in these devices, account taken of the particularities of an IoT ecosystem. Due to the topic subject of discussion, it is necessary to lay the technological ground in order to perform a subsequent legal analysis. The conclusions attempt to answer which authentication method achieves a better balance on the forces tensioning in digital identity as well as offering some lines for further research and development in the area.
C1  - New York, NY, USA
C3  - Proceedings of the 16th International Conference on Availability, Reliability and Security
DA  - 2021///
PY  - 2021
DO  - 10.1145/3465481.3470068
PB  - Association for Computing Machinery
SN  - 978-1-4503-9051-4
UR  - https://doi.org/10.1145/3465481.3470068
KW  - Authentication
KW  - Digital Identity
KW  - IoT
KW  - Privacy
KW  - Security
ER  - 

TY  - CONF
TI  - ASPIDA: An Observatory for Security and Privacy in the Greek e-Business Sector
AU  - Vlachos, Vasileios
AU  - Katevas, Gerasimos
AU  - Katsidimas, Ioannis
AU  - Kerimakis, Emmanouil
AU  - Nikoletseas, Sotiris
AU  - Panagiotou, Stefanos
AU  - Spirakis, Paul
T3  - PCI '21
AB  - Modern e-business policy aims to better frame and steer progress and advancements towards a legal and security aware framework. However, a large percentage of cases neglects the adoption of good security practices, exposing customers to potential risks. In this work, we present a hybrid approach upon self-assessment, self-improvement and self-regulation motivation, offered by the observAtory for Security and PrIvacy DAta (ASPIDA) system. To address privacy and security weaknesses we monitor and analyze a set of security and privacy metrics and indicators. The evaluation of the aforementioned criteria drives an outcome in the form of a digital badge of good practices for the specific website. This digital badge is a recognition and can be used by the e-business owners as an attraction that frames the services and content they offer to the public.
C1  - New York, NY, USA
C3  - Proceedings of the 25th Pan-Hellenic Conference on Informatics
DA  - 2022///
PY  - 2022
DO  - 10.1145/3503823.3503890
SP  - 362
EP  - 368
PB  - Association for Computing Machinery
SN  - 978-1-4503-9555-7
UR  - https://doi.org/10.1145/3503823.3503890
KW  - cybersecurity
KW  - e-business
KW  - privacy
KW  - web application vulnerabilities
KW  - world wide web
ER  - 

TY  - JOUR
TI  - Analysis of Industry-Specific Concentration of CPOs in Fortune 500 Companies
AU  - Shalhoub, Zeinab Karake
T2  - Commun. ACM
DA  - 2009/04//
PY  - 2009
DO  - 10.1145/1498765.1498802
VL  - 52
IS  - 4
SP  - 136
EP  - 141
SN  - 0001-0782
UR  - https://doi.org/10.1145/1498765.1498802
ER  - 

TY  - CONF
TI  - Model for Reducing Risks to Private or Sensitive Data
AU  - Yee, George O. M.
AU  - Yee, George O. M.
T3  - MISE '17
AB  - Software systems can be found in almost every aspect of our lives, as can be seen in social media, online banking and shopping, as well as electronic health monitoring. This widespread involvement in our lives has led to the need to protect privacy, as the use of the software often requires us to input our personal information. Software systems can also hold sensitive data (e.g., a trade secret) that is vulnerable to theft. The key to protecting private or sensitive data in software systems is the knowledge of where the data resides in the system. This paper proposes a new model for visualizing a software system that focuses on the location of private or sensitive data, in order to gain insight into the attendant risks to attacks on the data. The model can then be modified to suggest ways of reducing these risks in the software system.
C3  - Proceedings of the 9th International Workshop on Modelling in Software Engineering
DA  - 2017///
PY  - 2017
SP  - 19
EP  - 25
PB  - IEEE Press
SN  - 978-1-5386-0426-7
KW  - data
KW  - model
KW  - private
KW  - reduction
KW  - risks
KW  - sensitive
KW  - software
KW  - system
ER  - 

TY  - JOUR
TI  - The Illusion of Security
AU  - Wright, David
AU  - Friedewald, Michael
AU  - Schreurs, Wim
AU  - Verlinden, Michiel
AU  - Gutwirth, Serge
AU  - Punie, Yves
AU  - Maghiros, Ioannis
AU  - Vildjiounaite, Elena
AU  - Alahuhta, Petteri
T2  - Commun. ACM
AB  - A fictional scenario of daily life in a world networked with ambient intelligence illustrates the dark side of the technology and the need for appropriate safeguards.
DA  - 2008/03//
PY  - 2008
DO  - 10.1145/1325555.1325567
VL  - 51
IS  - 3
SP  - 56
EP  - 63
SN  - 0001-0782
UR  - https://doi.org/10.1145/1325555.1325567
ER  - 

TY  - CONF
TI  - Participant-Centred Planning Framework for Effective Gender Balance Activities in Tech
AU  - Taylor-Smith, Ella
AU  - Barnett, Camilla
AU  - Smith, Sally
AU  - Barr, Matthew
AU  - Shankland, Carron
T3  - UKICER '22
AB  - The gender imbalance in the tech industry [21], mirrored in computing education [13], is problematic in terms of providing appropriate products and services for the whole population. This lack of diversity and inclusion is also self-perpetuating through gendered stereotypes of computing and women's experience of male-dominated work and study environments [4; 7].Activities to break this cycle aim to encourage women and girls to study computing and pursue careers in digital [18]. This paper presents a new tool: a framework to support teams to design successful activities.The research study aimed to identify factors for success, with a particular focus on using of role models. A typology survey was designed to capture structured descriptions of activities; an online survey asked female and non-binary computing students about their role models and motivations for choosing computing, including any activities to encourage them into computing/STEM; and organisers from successful initiatives were interviewed. The study revealed a wide range of activities, with many potential success factors, but a dearth of rigorous evaluation. The Participant-Centred Planning Framework was developed from the study's findings. Its aim is to support effective design of engaging activities, and collect evaluative evidence over time.This framework was successfully piloted with organisers of initiatives to encourage girls into computing/STEM. Pilot study participants appreciated the framework's structure, guidance, and participant-centred paradigm. The study indicated that the framework could also support activities targeting other currently underrepresented groups.This paper presents the initial study, the pilot, the framework, and plans to extend its use..
C1  - New York, NY, USA
C3  - Proceedings of the 2022 Conference on United Kingdom &amp; Ireland Computing Education Research
DA  - 2022///
PY  - 2022
DO  - 10.1145/3555009.3555016
PB  - Association for Computing Machinery
SN  - 978-1-4503-9742-1
UR  - https://doi.org/10.1145/3555009.3555016
KW  - EDI
KW  - evaluation
KW  - Gender balance
KW  - role models
KW  - stereotypes
KW  - women
ER  - 

TY  - CONF
TI  - An Empirical Study on the Impact of GDPR and Right to Be Forgotten - Organisations and Users Perspective
AU  - Mangini, Vincenzo
AU  - Tal, Irina
AU  - Moldovan, Arghir-Nicolae
T3  - ARES '20
AB  - The General Data Protection Regulation (GDPR) is a prescriptive legislation in the European Union (EU) for privacy and data protection that applies to every organisation within the EU and any organisation outside the EU if they offer goods or services to EU citizens. The enforcement of GDPR created a big challenge for organisations which were required to create new professional figures, system, policies, procedures and standards, budget for new investments, and to set up a project plan or catalogue specific to the GDPR. This paper focuses on the GDPR 'right to be forgotten' and the specific implementation challenges it poses. The research study used two surveys to collect data from both organisations and users. The results show that while organisations are struggling with GDPR and right to be forgotten, there are also positive aspects about its implementation that translate into improved data privacy. The findings related to the users show that they are in general happy with the legislation.
C1  - New York, NY, USA
C3  - Proceedings of the 15th International Conference on Availability, Reliability and Security
DA  - 2020///
PY  - 2020
DO  - 10.1145/3407023.3407080
PB  - Association for Computing Machinery
SN  - 978-1-4503-8833-7
UR  - https://doi.org/10.1145/3407023.3407080
KW  - GDPR
KW  - privacy
KW  - right to be forgotten
ER  - 

TY  - CONF
TI  - Using MCDA for Selecting Criteria of LGPD Compliant Personal Data Security
AU  - Carauta Ribeiro, Renato
AU  - Dias Canedo, Edna
T3  - dg.o '20
AB  - The protection of personal data is a problem that has been discussed in several countries. Most countries create laws and regulations to protect fundamental rights and privacy. The main data protection regulation approved by the European Union (EU) is the General Data Protection Regulation (GDPR). This regulation regulates how personal data should be protected and how data may be shared between other countries. Brazil recently enacted the Brazilian General Data Protection Law (LGPD) with various standards for security and privacy of personal data. This paper aims to select the best alternatives for the implementation of security criteria at the University of Brasília (UnB). We use the Multiple Criteria Decision Analysis (MCDA) process with the Preference Ranking Organization Method for Enriched Evaluation (PROMETHEE) II method to select the best to worst alternatives, according to the criteria selected in the MCDA process using the method Analytic Hierarchy Process (AHP). The results found demonstrate that the Data Privacy Risks criterion is the highest priority criterion for the implementation of personal data security at UnB since LGPD’s main objective is to keep personal data private and accessible only to the data subject. Furthermore, it was found that the LGPD principles with the highest implementation priority were: 0.28 Priority Security, 0.26 Priority Needs and 0.25 Priority Prevention.
C1  - New York, NY, USA
C3  - The 21st Annual International Conference on Digital Government Research
DA  - 2020///
PY  - 2020
DO  - 10.1145/3396956.3398252
SP  - 175
EP  - 184
PB  - Association for Computing Machinery
SN  - 978-1-4503-8791-0
UR  - https://doi.org/10.1145/3396956.3398252
KW  - Data Privacy
KW  - GDPR
KW  - LGPD
KW  - MCDA
KW  - Privacy Criteria
KW  - Security Criteria
ER  - 

TY  - CONF
TI  - Smartphones in a Microwave: Formal and Experimental Feasibility Study on Fingerprinting the Corona-Warn-App
AU  - Graßhoff, Henrik
AU  - Adamsky, Florian
AU  - Schiffner, Stefan
T3  - ARES '23
AB  - Contact Tracing Apps (CTAs) have been developed to contain the coronavirus disease 19 (COVID-19) spread. By design, such apps invade their users’ privacy by recording data about their health, contacts, and—partially—location. Many CTAs frequently broadcast pseudorandom numbers via Bluetooth to detect encounters. These numbers are changed regularly to prevent individual smartphones from being trivially trackable. However, the effectiveness of this procedure has been little studied. We measured real smartphones and observed that the German Corona-Warn-App (CWA) exhibits a device-specific latency between two subsequent broadcasts. These timing differences provide a potential attack vector for fingerprinting smartphones by passively recording Bluetooth messages. This could conceivably lead to the tracking of users’ trajectories and, ultimately, the re-identification of users.
C1  - New York, NY, USA
C3  - Proceedings of the 18th International Conference on Availability, Reliability and Security
DA  - 2023///
PY  - 2023
DO  - 10.1145/3600160.3605011
PB  - Association for Computing Machinery
SN  - 9798400707728
UR  - https://doi.org/10.1145/3600160.3605011
KW  - Anonymity
KW  - contact tracing
KW  - fingerprinting
KW  - privacy
KW  - pseudonymity
ER  - 

TY  - CONF
TI  - Why Developers Cannot Embed Privacy into Software Systems? An Empirical Investigation
AU  - Senarath, Awanthika
AU  - Arachchilage, Nalin A. G.
T3  - EASE '18
AB  - Pervasive use of software applications continue to challenge user privacy when users interact with software systems. Even though privacy practices such as Privacy by Design (PbD), have clear instructions for software developers to embed privacy into software designs, those practices are yet to become a common practice among software developers. The difficulty of developing privacy preserving software systems highlights the importance of investigating software developers and the problems they face when they are asked to embed privacy into application designs. Software developers are the community who can put practices such as PbD into action. Therefore identifying the problems they face when embedding privacy into software applications and providing solutions to those problems are important to enable the development of privacy preserving software systems. This study investigates 36 software developers in a software design task with instructions to embed privacy in order to identify the problems they face. We derive recommendation guidelines to address the problems to enable the development of privacy preserving software systems.
C1  - New York, NY, USA
C3  - Proceedings of the 22nd International Conference on Evaluation and Assessment in Software Engineering 2018
DA  - 2018///
PY  - 2018
DO  - 10.1145/3210459.3210484
SP  - 211
EP  - 216
PB  - Association for Computing Machinery
SN  - 978-1-4503-6403-4
UR  - https://doi.org/10.1145/3210459.3210484
KW  - Privacy Practices
KW  - Software Development
KW  - Usable Privacy
ER  - 

TY  - CONF
TI  - Empowering Dyads of Older Adults With Mild Cognitive Impairment And Their Care Partners Using Conversational Agents
AU  - Zubatiy, Tamara
AU  - Vickers, Kayci L
AU  - Mathur, Niharika
AU  - Mynatt, Elizabeth D
T3  - CHI '21
AB  - Conversational agents (CAs) such as Google Home or Alexa offer empowering opportunities for dyads composed of older adults with mild cognitive impairment (MCI) and their care partners. CAs support coordination and planning between the two, and can amplify the support that the care partner needs to provide. In this study, we observed how ten such dyads interacted with a Google Home over 10 weeks. We logged and analyzed 3,878 total interactions, interviewed the dyads to better understand their experiences, and also surveyed their individual preferences and priorities for automated assistance in the home. We found that CAs empowered both the people who had MCI, and their care partners. We observed that the utility of the CA in the day-to-day lives of users largely depended on how much the care partner scaffolded promising functionality, setting it up and contextualizing it for specific needs and desires.
C1  - New York, NY, USA
C3  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
DA  - 2021///
PY  - 2021
DO  - 10.1145/3411764.3445124
PB  - Association for Computing Machinery
SN  - 978-1-4503-8096-6
UR  - https://doi.org/10.1145/3411764.3445124
KW  - Ambient Devices / Internet of Things
KW  - Assistive Technologies
KW  - Audio/Video
KW  - Field Study
KW  - Health - Wellbeing
KW  - Home
KW  - Individuals with Disabilities &amp
KW  - Older Adults
KW  - Smart Environments / Connected Home
ER  - 

TY  - JOUR
TI  - Will They Use It or Not? Investigating Software Developers’ Intention to Follow Privacy Engineering Methodologies
AU  - Senarath, Awanthika
AU  - Grobler, Marthie
AU  - Arachchilage, Nalin Asanka Gamagedara
T2  - ACM Trans. Priv. Secur.
AB  - With the increasing concerns over privacy in software systems, there is a growing enthusiasm to develop methods to support the development of privacy aware software systems. Inadequate privacy in software system designs could result in users losing their sensitive data, such as health information and financial information, which may cause financial and reputation loss. Privacy Engineering Methodologies (PEMs) are introduced into the software development processes with the goal of guiding software developers to embed privacy into the systems they design. However, for PEMs to be successful it is imperative that software developers have a positive intention to use PEMs. Otherwise, developers may attempt to bypass the privacy methodologies or use them partially and hence develop software systems that may not protect user privacy appropriately. To investigate the factors that affect software developers’ behavioural intention to follow PEMs, in this article, we conducted a study with 149 software developers. Findings of the study show that the usefulness of the PEM to the developers’ existing work to be the strongest determinant that affects software developers’ intention to follow PEMs. Moreover, the compatibility of the PEM with their way of work and how the PEM demonstrates its results when used were also found to be significant. These findings provide important insights in understanding the behaviour of software developers and how they perceive PEMs. The findings could be used to assist organisations and researchers to deploy PEMs and design PEMs that are positively accepted by software developers.
DA  - 2019/11//
PY  - 2019
DO  - 10.1145/3364224
VL  - 22
IS  - 4
SN  - 2471-2566
UR  - https://doi.org/10.1145/3364224
KW  - Privacy engineering
KW  - software development
KW  - technology acceptance
ER  - 

TY  - CONF
TI  - Digital Retail Challenges within the EU: Fulfillment of Holistic Customer Journey Post GDPR
AU  - Nabbosa, Veronica L.
AU  - Iftikhar, Rehan
T3  - ICEBT '19
AB  - Retail customers are demanding better shopping experience whether shopping online or in-store. To provide this experience, retailers use digital technologies such as Artificial Intelligence, Big Data, to name a few. They also collect personal data from customers, process it and integrate it in their business models. Use of the digital technologies and customers' data poses legal challenges with the introduction of GDPR in EU. This paper analyses the challenges faced by digital retailers as they strive to provide fulfilling customer experiences. The authors address in this study, the influence of GDPR on business and technological aspects of digital retail.
C1  - New York, NY, USA
C3  - Proceedings of the 2019 3rd International Conference on E-Education, E-Business and E-Technology
DA  - 2019///
PY  - 2019
DO  - 10.1145/3355166.3355170
SP  - 51
EP  - 58
PB  - Association for Computing Machinery
SN  - 978-1-4503-7256-5
UR  - https://doi.org/10.1145/3355166.3355170
KW  - Customer Journey
KW  - Digital Retail
KW  - EU
KW  - GDPR
KW  - Retail Challenges
ER  - 

TY  - CONF
TI  - The Third Wave? Inclusive Privacy and Security
AU  - Wang, Yang
T3  - NSPW '17
AB  - The field of security and privacy has made steady progresses in developing technical mechanisms, which I refer to as the first wave of security and privacy research. Since the 70's, human factors and usability have been recognized as a key property of effective security and privacy mechanisms. This is what I call the second wave of security and privacy research, focusing on usability. In this article, I propose and advocate for a third wave of research that I call inclusive security and privacy, which is concerned with designing security and privacy mechanisms that are inclusive to people with various characteristics, abilities, needs and values. I present a preliminary research framework and research agenda for advancing inclusive security and privacy.
C1  - New York, NY, USA
C3  - Proceedings of the 2017 New Security Paradigms Workshop
DA  - 2017///
PY  - 2017
DO  - 10.1145/3171533.3171538
SP  - 122
EP  - 130
PB  - Association for Computing Machinery
SN  - 978-1-4503-6384-6
UR  - https://doi.org/10.1145/3171533.3171538
KW  - Accessibility
KW  - Privacy
KW  - Security
KW  - Universal Design
ER  - 

TY  - CONF
TI  - A Model for Policy Interventions in Support of Electronic Governance
AU  - Chauhan, Radha
AU  - Estevez, Elsa
AU  - Janowski, Tomasz
T3  - ICEGOV '08
AB  - A policy framework is the backbone of public governance and a major contributor to its quality. Such a framework is particularly required in the areas where public governance seeks technology support, as is the case for Electronic Governance (e-Governance). This paper explains the need to put in place a comprehensive set of policies, and presents a model for policy interventions supporting e-Governance development. The model comprises a classification of policies based on their nature and applicability, and describes core areas for which policy interventions are required. The paper also presents three major scenarios for using the model: (1) a tool to help design and analyze critical policy interventions by developing and transition nations, (2) a template to understand different alternatives for interventions, and (3) a checklist to review all niche areas to be regulated. In particular, applicability of the model in India is discussed.
C1  - New York, NY, USA
C3  - Proceedings of the 2nd International Conference on Theory and Practice of Electronic Governance
DA  - 2008///
PY  - 2008
DO  - 10.1145/1509096.1509135
SP  - 199
EP  - 205
PB  - Association for Computing Machinery
SN  - 978-1-60558-386-0
UR  - https://doi.org/10.1145/1509096.1509135
KW  - electronic governance
KW  - policy interventions
ER  - 

TY  - CONF
TI  - Critical Analysis of LPL According to Articles 12 - 14 of the GDPR
AU  - Gerl, Armin
AU  - Pohl, Dirk
T3  - ARES '18
AB  - On the 25th May 2018 the General Data Protection Regulation (GDPR) will enter into force implying new challenges to both legal and computer sciences. The Layered Privacy Language (LPL) is intended to model privacy policies to enforce policy-based, privacy-preserving processing. In this paper, we identify requirements for privacy policies based on Art. 12 - 14 of the GDPR, analyze LPL according to the derived requirements, and propose improvements for LPL accordingly.
C1  - New York, NY, USA
C3  - Proceedings of the 13th International Conference on Availability, Reliability and Security
DA  - 2018///
PY  - 2018
DO  - 10.1145/3230833.3233267
PB  - Association for Computing Machinery
SN  - 978-1-4503-6448-5
UR  - https://doi.org/10.1145/3230833.3233267
KW  - GDPR
KW  - LPL
KW  - Privacy Language
KW  - Privacy Policy
KW  - Privacy-Preservation
ER  - 

TY  - CONF
TI  - Methodologies and Ethical Considerations in Phishing Research: A Comprehensive Review
AU  - Thomopoulos, George
AU  - Lyras, Dimitrios
AU  - Fidas, Christos
T3  - CHIGREECE '23
AB  - Phishing is a significant security threat that causes financial and reputational losses to end-users and service providers in modern information systems. Current anti-phishing research is fragmented and does not address the issue from a pervasive computing perspective. As phishing attacks exploit human susceptibility, designing appropriate and personalized anti-phishing security frameworks that consider individual behavior is crucial. Phishing experiments raise ethical and legal concerns. Researchers carry out experiments to measure the probability and frequency that something vulnerable could happen, using this information to identify the most effective protection measures. This paper aims to identify ethical and practical issues related to the creation and execution of phishing experiments. The review examines the types of experiments conducted, ethical rules applied, user consent obtained, and the types of phishing examined in the experiments. Our aim in this review is to focus on identifying legal white spaces and ethical considerations by providing a complete review of the current approaches and processes used in phishing experiments.
C1  - New York, NY, USA
C3  - Proceedings of the 2nd International Conference of the ACM Greek SIGCHI Chapter
DA  - 2023///
PY  - 2023
DO  - 10.1145/3609987.3609990
PB  - Association for Computing Machinery
SN  - 9798400708886
UR  - https://doi.org/10.1145/3609987.3609990
KW  - best practices
KW  - ethics
KW  - methodologies
KW  - phishing
KW  - user consent
ER  - 

TY  - JOUR
TI  - Are the OECD Guidelines at 30 Showing Their Age?
AU  - Wright, David
AU  - De Hert, Paul
AU  - Gutwirth, Serge
T2  - Commun. ACM
AB  - Three decades have passed since the Organisation for Economic Co-operation and Development (OECD) promulgated Guidelines on the Transborder Flows of Personal Data, and still the issue of transborder flows of personal data continues to plague policymakers, industry, and individuals who have no idea what happens to their data once that data is transmitted beyond their national jurisdictions. This article briefly reviews what happened in the 1970s, the factors that led to production of the guidelines, and some of the key points in them. We highlight the success of the guidelines, but also the shortcomings, and what is happening now to bridge the gap and ask whether an international binding convention or standard is needed. We conclude with a few modest suggestions for ensuring a new convention or standard has teeth.In the 1970s, the decade before the OECD Guidelines were promulgated, some countries had already begun to enact privacy laws applicable to the public and private sectors. The world's first data protection law was passed in the German Land of Hessen in 1970. In 1977, a Federal Data Protection Act (Bundesdatenschutzgesetz or BDSG) followed. Sweden's Data Act of 1973 was the first comprehensive national act on privacy in the world. France's Data Protection Act, enacted in 1978 and amended in 2004, covers personal information held by government agencies and private entities.In the U.S., antecedents of the 1974 Privacy Act were the American Fair Credit Reporting Act of 1970 and a 1973 report of the Department of Health Education and Welfare (HEW) on fair information practices (FIP).In the seven-year stint between 1973 and 1980, one-third of the OECD's 30 Member countries enacted legislation intended to protect in dividuals against abuse of data related to them and to give individuals the right of access to data with a view to checking their accuracy and appropriateness. Some countries were enacting statutes that dealt exclusively with computers and computer-supported activities. Other countries preferred a more general approach irrespective of the particular data processing technology involved. The OECD became concerned that these disparities in legislation might "create obstacles to the free flow of information between countries."The OECD Council recognized that Member countries have a common interest in protecting privacy "and in reconciling fundamental but competing values such as privacy and the free flow of information." This persisting tension between data protection and the free flow of information is already obvious in the OECD Guidelines of 1980, which were intended to facilitate a harmonization of national legislation, without precluding the establishment of an international Convention at a later date.As it turned out, the Council of Europe (CoE), another international organization mainly concerned with the fostering of human rights and democracy in Europe, was working simultaneously in that direction—that of an international convention. As European countries began to adopt data protection laws, pressure grew for more uniformity of these laws. From a human rights perspective, the CoE began preparing an international convention on data protection that nevertheless also included provisions dealing with data processing abroad. Efforts were made to avoid unnecessary differences between the texts produced by the two organizations; thus, the set of basic principles of protection proposed by the OECD and the CoE are similar in many respects.On Sept. 17, 1980, the Committee of Ministers of the CoE adopted the Convention for the Protection of Individuals with regard to Automatic Processing of Personal Data, the first legally binding international instrument in data protection. The convention sought to establish basic principles of data protection, to reduce restrictions on transborder data flows on the basis of reciprocity, and to bring about cooperation between national data protection authorities (DPAs). Parties to the convention are required to apply the principles in their domestic legislation.Six days later, on Sept. 23, 1980, the OECD Council adopted its guidelines on transborder data flows. Although efforts were made to minimize the differences, some do occur nevertheless. The OECD Guidelines are not legally binding, whereas the CoE convention is binding on those countries that ratify it. The CoE convention only applies to personal data that are "automatically" processed, whereas the guidelines are valid for the processing of data in general, irrespective of the particular technology employed. The OECD Guidelines, unlike the CoE convention, do not mention the need to establish national data protection authorities, a crucial requirement in European data protection rules. But, all in all, the principles formulated are similar.The OECD Guidelines and the CoE convention both recognize the need to harmonize data protection standards. Like the CoE convention, the OECD Guidelines aimed to prevent interruptions in the international flow of data, but are not to be construed as a set of general privacy protection principles per se. The guidelines explicitly say that invasions of privacy by candid photography, physical maltreatment, or defamation are outside their scope.
DA  - 2011/02//
PY  - 2011
DO  - 10.1145/1897816.1897848
VL  - 54
IS  - 2
SP  - 119
EP  - 127
SN  - 0001-0782
UR  - https://doi.org/10.1145/1897816.1897848
ER  - 

TY  - CONF
TI  - To Be High-Risk, or Not To Be—Semantic Specifications and Implications of the AI Act’s High-Risk AI Applications and Harmonised Standards
AU  - Golpayegani, Delaram
AU  - Pandit, Harshvardhan J.
AU  - Lewis, Dave
T3  - FAccT '23
AB  - The EU’s proposed AI Act sets out a risk-based regulatory framework to govern the potential harms emanating from use of AI systems. Within the AI Act’s hierarchy of risks, the AI systems that are likely to incur “high-risk” to health, safety, and fundamental rights are subject to the majority of the Act’s provisions. To include uses of AI where fundamental rights are at stake, Annex III of the Act provides a list of applications wherein the conditions that shape high-risk AI are described. For high-risk AI systems, the AI Act places obligations on providers and users regarding use of AI systems and keeping appropriate documentation through the use of harmonised standards. In this paper, we analyse the clauses defining the criteria for high-risk AI in Annex III to simplify identification of potential high-risk uses of AI by making explicit the “core concepts” whose combination makes them high-risk. We use these core concepts to develop an open vocabulary for AI risks (VAIR) to represent and assist with AI risk assessments in a form that supports automation and integration. VAIR is intended to assist with identification and documentation of risks by providing a common vocabulary that facilitates knowledge sharing and interoperability between actors in the AI value chain. Given that the AI Act relies on harmonised standards for much of its compliance and enforcement regarding high-risk AI systems, we explore the implications of current international standardisation activities undertaken by ISO and emphasise the necessity of better risk and impact knowledge bases such as VAIR that can be integrated with audits and investigations to simplify the AI Act’s application.
C1  - New York, NY, USA
C3  - Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency
DA  - 2023///
PY  - 2023
DO  - 10.1145/3593013.3594050
SP  - 905
EP  - 915
PB  - Association for Computing Machinery
SN  - 9798400701924
UR  - https://doi.org/10.1145/3593013.3594050
KW  - AI Act
KW  - harmonised standards
KW  - high-risk AI
KW  - semantic web
KW  - taxonomy
ER  - 

TY  - CONF
TI  - Accept - Maybe - Decline: Introducing Partial Consent for the Permission-Based Access Control Model of Android
AU  - Momen, Nurul
AU  - Bock, Sven
AU  - Fritsch, Lothar
T3  - SACMAT '20
AB  - The consent to personal data sharing is an integral part of modern access control models on smart devices. This paper examines the possibility of registering conditional consent which could potentially increase trust in data sharing. We introduce an indecisive state of consenting to policies that will enable consumers to evaluate data services before fully committing to their data sharing policies. We address technical, regulatory, social, individual and economic perspectives for inclusion of partial consent within an access control mechanism. Then, we look into the possibilities to integrate it within the access control model of Android by introducing an additional button in the interface–Maybe. This article also presents a design for such implementation and demonstrates feasibility by showcasing a prototype built on Android platform. Our effort is exploratory and aims to shed light on the probable research direction.
C1  - New York, NY, USA
C3  - Proceedings of the 25th ACM Symposium on Access Control Models and Technologies
DA  - 2020///
PY  - 2020
DO  - 10.1145/3381991.3395603
SP  - 71
EP  - 80
PB  - Association for Computing Machinery
SN  - 978-1-4503-7568-9
UR  - https://doi.org/10.1145/3381991.3395603
KW  - access control
KW  - data protection
KW  - partial consent
KW  - privacy
ER  - 

TY  - JOUR
TI  - Trustworthy AI: From Principles to Practices
AU  - Li, Bo
AU  - Qi, Peng
AU  - Liu, Bo
AU  - Di, Shuai
AU  - Liu, Jingen
AU  - Pei, Jiquan
AU  - Yi, Jinfeng
AU  - Zhou, Bowen
T2  - ACM Comput. Surv.
AB  - The rapid development of Artificial Intelligence (AI) technology has enabled the deployment of various systems based on it. However, many current AI systems are found vulnerable to imperceptible attacks, biased against underrepresented groups, lacking in user privacy protection. These shortcomings degrade user experience and erode people’s trust in all AI systems. In this review, we provide AI practitioners with a comprehensive guide for building trustworthy AI systems. We first introduce the theoretical framework of important aspects of AI trustworthiness, including robustness, generalization, explainability, transparency, reproducibility, fairness, privacy preservation, and accountability. To unify currently available but fragmented approaches toward trustworthy AI, we organize them in a systematic approach that considers the entire lifecycle of AI systems, ranging from data acquisition to model development, to system development and deployment, finally to continuous monitoring and governance. In this framework, we offer concrete action items for practitioners and societal stakeholders (e.g., researchers, engineers, and regulators) to improve AI trustworthiness. Finally, we identify key opportunities and challenges for the future development of trustworthy AI systems, where we identify the need for a paradigm shift toward comprehensively trustworthy AI systems.
DA  - 2023/01//
PY  - 2023
DO  - 10.1145/3555803
VL  - 55
IS  - 9
SN  - 0360-0300
UR  - https://doi.org/10.1145/3555803
KW  - accountability
KW  - explainability
KW  - fairness
KW  - generalization
KW  - privacy protection
KW  - reproducibility
KW  - robustness
KW  - transparency
KW  - Trustworthy AI
ER  - 

TY  - CONF
TI  - Assessing Software Privacy Using the Privacy Flow-Graph
AU  - Tang, Feiyang
AU  - Østvold, Bjarte M.
T3  - MSR4P&amp;S 2022
AB  - We increasingly rely on digital services and the conveniences they provide. Processing of personal data is integral to such services and thus privacy and data protection are a growing concern, and governments have responded with regulations such as the EU's GDPR. Following this, organisations that make software have legal obligations to document the privacy and data protection of their software. This work must involve both software developers that understand the code and the organisation's data protection officer or legal department that understands privacy and the requirements of a Data Protection and Impact Assessment (DPIA). To help developers and non-technical people such as lawyers document the privacy and data protection behaviour of software, we have developed an automatic software analysis technique. This technique is based on static program analysis to characterise the flow of privacy-related data. The results of the analysis can be presented as a graph of privacy flows and operations—that is understandable also for non-technical people. We argue that our technique facilitates collaboration between technical and non-technical people in documenting the privacy behaviour of the software. We explain how to use the results produced by our technique to answer a series of privacy-relevant questions needed for a DPIA. To illustrate our work, we show both detailed and abstract analysis results from applying our analysis technique to the secure messaging service Signal and to the client of the cloud service NextCloud and show how their privacy flow-graphs inform the writing of a DPIA.
C1  - New York, NY, USA
C3  - Proceedings of the 1st International Workshop on Mining Software Repositories Applications for Privacy and Security
DA  - 2022///
PY  - 2022
DO  - 10.1145/3549035.3561185
SP  - 7
EP  - 15
PB  - Association for Computing Machinery
SN  - 978-1-4503-9457-4
UR  - https://doi.org/10.1145/3549035.3561185
KW  - data protection and privacy
KW  - GDPR
KW  - Program analysis
KW  - software design documentation
ER  - 

TY  - CONF
TI  - A Combined Rule-Based and Machine Learning Approach for Automated GDPR Compliance Checking
AU  - Hamdani, Rajaa El
AU  - Mustapha, Majd
AU  - Amariles, David Restrepo
AU  - Troussel, Aurore
AU  - Meeùs, Sébastien
AU  - Krasnashchok, Katsiaryna
T3  - ICAIL '21
AB  - The General Data Protection Regulation (GDPR) requires data controllers to implement end-to-end compliance. Controllers must therefore ensure that the terms agreed with the data subject and their own obligations under GDPR are respected in the data flows from data subject to controllers, processors and sub processors (i.e. data supply chain). This paper seeks to contribute to bridge both ends of compliance checking through a two-pronged study. First, we conceptualize a framework to implement a document-centric approach to compliance checking in the data supply chain. Second, we develop specific methods to automate compliance checking of privacy policies. We test a two-modules system, where the first module relies on NLP to extract data practices from privacy policies. The second module encodes GDPR rules to check the presence of mandatory information. The results show that the text-to-text approach outperforms local classifiers and enables the extraction of both coarse-grained and fine-grained information with only one model. We implement full evaluation of our system on a dataset of 30 privacy policies annotated by legal experts. We conclude that this approach could be generalized to other documents in the data supply as a means to improve end-to-end compliance.
C1  - New York, NY, USA
C3  - Proceedings of the Eighteenth International Conference on Artificial Intelligence and Law
DA  - 2021///
PY  - 2021
DO  - 10.1145/3462757.3466081
SP  - 40
EP  - 49
PB  - Association for Computing Machinery
SN  - 978-1-4503-8526-8
UR  - https://doi.org/10.1145/3462757.3466081
ER  - 

TY  - CONF
TI  - Child-Centered Design in the Digital World: Investigating the Implications of the Age-Appropriate Design Code for Interactive Digital Media
AU  - Grace, Thomas D
AU  - Abel, Christie
AU  - Salen, Katie
T3  - IDC '23
AB  - In this paper, we conduct a content analysis to investigate the implications of the "Age-Appropriate Design Code" for the design of interactive digital media children are likely to use. The "Age-Appropriate Design Code" policy framework, implemented in the United Kingdom in 2021 with a modified version later signed into law in California in 2022, shifts the focus beyond just the protection of children's data to a broader focus on how the interaction with digital technologies might affect or even harm children. Our content analysis of both the UK and California codes identifies a number of design considerations framed around four main categories namely design values, communication of information, interactions with technology, and data management. While recognizing the robustness of the Age-Appropriate Design Codes, we also identify certain uncertainties and challenges in implementing guidelines in the context of interactive digital media. Our findings contribute to the ongoing conversation about designing safe and age-appropriate online spaces for children.
C1  - New York, NY, USA
C3  - Proceedings of the 22nd Annual ACM Interaction Design and Children Conference
DA  - 2023///
PY  - 2023
DO  - 10.1145/3585088.3589370
SP  - 289
EP  - 297
PB  - Association for Computing Machinery
SN  - 9798400701313
UR  - https://doi.org/10.1145/3585088.3589370
KW  - age-appropriate design
KW  - child centered design
KW  - content analysis
KW  - policy analysis
ER  - 

TY  - CONF
TI  - Privacy and DRM Requirements for Collaborative Development of AI Applications
AU  - Mehri, Vida Ahmadi
AU  - Ilie, Dragos
AU  - Tutschku, Kurt
T3  - ARES '18
AB  - The use of data is essential for the capabilities of Data-driven Artificial intelligence (AI), Deep Learning and Big Data analysis techniques. This data usage, however, raises intrinsically the concerns on data privacy. In addition, supporting collaborative development of AI applications across organisations has become a major need in AI system design. Digital Rights Management (DRM) is required to protect intellectual property in such collaboration. As a consequence of DRM, privacy threats and privacy-enforcing mechanisms will interact with each other.This paper describes the privacy and DRM requirements in collaborative AI system design using AI pipelines. It describes the relationships between DRM and privacy and outlines the threats against these non-functional features. Finally, the paper provides first security architecture to protect against the threats on DRM and privacy in collaborative AI design using AI pipelines.
C1  - New York, NY, USA
C3  - Proceedings of the 13th International Conference on Availability, Reliability and Security
DA  - 2018///
PY  - 2018
DO  - 10.1145/3230833.3233268
PB  - Association for Computing Machinery
SN  - 978-1-4503-6448-5
UR  - https://doi.org/10.1145/3230833.3233268
ER  - 

TY  - CONF
TI  - Personalized Privacy-Aware Image Classification
AU  - Spyromitros-Xioufis, Eleftherios
AU  - Papadopoulos, Symeon
AU  - Popescu, Adrian
AU  - Kompatsiaris, Yiannis
T3  - ICMR '16
AB  - Information sharing in online social networks is a daily practice for billions of users. The sharing process facilitates the maintenance of users' social ties but also entails privacy disclosure in relation to other users and third parties. Depending on the intentions of the latter, this disclosure can become a risk. It is thus important to propose tools that empower the users in their relations to social networks and third parties connected to them. As part of USEMP, a coordinated research effort aimed at user empowerment, we introduce a system that performs privacy-aware classification of images. We show that generic privacy models perform badly with real-life datasets in which images are contributed by individuals because they ignore the subjective nature of privacy. Motivated by this, we develop personalized privacy classification models that, utilizing small amounts of user feedback, provide significantly better performance than generic models. The proposed semi-personalized models lead to performance improvements for the best generic model ranging from 4%, when 5 user-specific examples are provided, to 18% with 35 examples. Furthermore, by using a semantic representation space for these models we manage to provide intuitive explanations of their decisions and to gain novel insights with respect to individuals' privacy concerns stemming from image sharing. We hope that the results reported here will motivate other researchers and practitioners to propose new methods of exploiting user feedback and of explaining privacy classifications to users.
C1  - New York, NY, USA
C3  - Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval
DA  - 2016///
PY  - 2016
DO  - 10.1145/2911996.2912018
SP  - 71
EP  - 78
PB  - Association for Computing Machinery
SN  - 978-1-4503-4359-6
UR  - https://doi.org/10.1145/2911996.2912018
KW  - image privacy
KW  - online social networks
KW  - personalization
KW  - privacy-aware image classification
ER  - 

TY  - CONF
TI  - User Configurable Privacy Requirements Elicitation in Cyber-Physical Systems
AU  - Omitola, Tope
AU  - Tsakalakis, Niko
AU  - Wills, Gary
AU  - Gomer, Richard
AU  - Waterson, Ben
AU  - Cherret, Tom
AU  - STALLA-BOURDILLON, Sophie
T3  - UMAP '22 Adjunct
AB  - The combination of our need for efficient mobility systems coupled with cyber-physical systems has brought about the evolution of Mobility-as-a-Service (MaaS), integrating transport services to provide one-stop access through a custom interface. Our interactions with these MaaS systems lead to a surfeit of data generation and consumption. And for MaaS growth to be sustained, users’ trust in the system, especially in their data privacy, needs to be addressed. In this paper, we use LINDDUN privacy analysis framework to elicit privacy requirements of MaaS systems. We show how User-Dependent Analysis, i.e. modularizing complete use cases to different usage contexts and analysing these usages, can help guide us to discern that usage’s privacy requirements, which can be enacted by relevant MaaS participants.
C1  - New York, NY, USA
C3  - Adjunct Proceedings of the 30th ACM Conference on User Modeling, Adaptation and Personalization
DA  - 2022///
PY  - 2022
DO  - 10.1145/3511047.3537683
SP  - 109
EP  - 119
PB  - Association for Computing Machinery
SN  - 978-1-4503-9232-7
UR  - https://doi.org/10.1145/3511047.3537683
KW  - Cyberphysical systems
KW  - cybersecurity
KW  - Privacy
KW  - user configuration
ER  - 

TY  - CONF
TI  - Automatic Online Quantification and Prioritization of Data Protection Risks
AU  - Zmiewski, Sascha Sven
AU  - Laufer, Jan
AU  - Mann, Zoltán Ádám
T3  - ARES '22
AB  - Data processing systems operate in increasingly dynamic environments, such as in cloud or edge computing. In such environments, changes at run time can result in the dynamic appearance of data protection vulnerabilities, i.e., configurations in which an attacker could gain unauthorized access to confidential data. An autonomous system can mitigate such vulnerabilities by means of automated self-adaptations. If there are several data protection vulnerabilities at the same time, the system has to decide which ones to address first. In other areas of cybersecurity, risk-based approaches have proven useful for prioritizing where to focus efforts for increasing security. Traditionally, risk assessment is a manual and time-consuming process. On the other hand, addressing run-time risks requires timely decision-making, which in turn necessitates automated risk assessment. In this paper, we propose a mathematical model for quantifying data protection risks at run time. This model accounts for the specific properties of data protection risks, such as the time it takes to exploit a data protection vulnerability and the damage caused by such exploitation. Using this risk quantification, our approach can make, in an automated process, sound decisions on prioritizing data protection vulnerabilities dynamically. Experimental results show that our risk prioritization method leads to a reduction of up to 15.8% in the damage caused by data protection vulnerabilities.
C1  - New York, NY, USA
C3  - Proceedings of the 17th International Conference on Availability, Reliability and Security
DA  - 2022///
PY  - 2022
DO  - 10.1145/3538969.3539005
PB  - Association for Computing Machinery
SN  - 978-1-4503-9670-7
UR  - https://doi.org/10.1145/3538969.3539005
KW  - data protection
KW  - risk assessment
KW  - risk prioritization
KW  - self-adaptation
KW  - vulnerability
ER  - 

TY  - CONF
TI  - CPIQ - A Privacy Impact Quantification for Digital Medical Consent
AU  - Appenzeller, Arno
AU  - Kadow, Thomas
AU  - Krempel, Erik
AU  - Beyerer, Jürgen
T3  - PETRA '21
AB  - Increasing digitization in healthcare promises easier exchange and more efficient use of medical information for patients, institutions and research. The number of sharing options for medical data increases, e.g., through personal health records, as well as the volume of data. To use this data in medical research patients’ consent is important. As more and more data access is regulated by consent forms and their complexity also increases. For the patient, it becomes less comprehensible which information could be gained from his or her disclosed data. This becomes more important when pressumably anonymized data has the risk of potential re-identification of an individual. In this paper we introduce a consent-privacy-impact-quantification (CPIQ) as a risk model of consent forms for the release of personal medical data for use within research projects. CPIQ evaluates how reasonable a consent decision is for the patient. It takes relevant factors such as the patient’s preferences into account, the circumstances and benefits of the research project, and the potential risk to the patient. The model can be parameterized so that different aspects such as the benefit of the research project, the risk of a data leak or the risk of a patient’s confidential data becoming known can be represented. We present the feasibility of this model by including it in an existing consent management system.
C1  - New York, NY, USA
C3  - Proceedings of the 14th PErvasive Technologies Related to Assistive Environments Conference
DA  - 2021///
PY  - 2021
DO  - 10.1145/3453892.3461653
SP  - 534
EP  - 543
PB  - Association for Computing Machinery
SN  - 978-1-4503-8792-7
UR  - https://doi.org/10.1145/3453892.3461653
KW  - data sovereignty
KW  - digital consent
KW  - e-health
KW  - formal consent model
KW  - medical consent
KW  - medical data
KW  - risk quantification
ER  - 

TY  - CONF
TI  - Ethics of AI: A Systematic Literature Review of Principles and Challenges
AU  - Khan, Arif Ali
AU  - Badshah, Sher
AU  - Liang, Peng
AU  - Waseem, Muhammad
AU  - Khan, Bilal
AU  - Ahmad, Aakash
AU  - Fahmideh, Mahdi
AU  - Niazi, Mahmood
AU  - Akbar, Muhammad Azeem
T3  - EASE '22
AB  - Ethics in AI becomes a global topic of interest for both policymakers and academic researchers. In the last few years, various research organizations, lawyers, think tankers, and regulatory bodies get involved in developing AI ethics guidelines and principles. However, there is still debate about the implications of these principles. We conducted a systematic literature review (SLR) study to investigate the agreement on the significance of AI principles and identify the challenging factors that could negatively impact the adoption of AI ethics principles. The results reveal that the global convergence set consists of 22 ethical principles and 15 challenges. Transparency, privacy, accountability and fairness are identified as the most common AI ethics principles. Similarly, lack of ethical knowledge and vague principles are reported as the significant challenges for considering ethics in AI. The findings of this study are the preliminary inputs for proposing a maturity model that assesses the ethical capabilities of AI systems and provides best practices for further improvements.
C1  - New York, NY, USA
C3  - Proceedings of the 26th International Conference on Evaluation and Assessment in Software Engineering
DA  - 2022///
PY  - 2022
DO  - 10.1145/3530019.3531329
SP  - 383
EP  - 392
PB  - Association for Computing Machinery
SN  - 978-1-4503-9613-4
UR  - https://doi.org/10.1145/3530019.3531329
KW  - AI Ethics
KW  - Challenges
KW  - Machine Ethics
KW  - Principles
KW  - Systematic Literature Review
ER  - 

TY  - CONF
TI  - Autonomous Vehicles: Data Protection and Ethical Considerations
AU  - Krontiris, Ioannis
AU  - Grammenou, Kalliroi
AU  - Terzidou, Kalliopi
AU  - Zacharopoulou, Marina
AU  - Tsikintikou, Marina
AU  - Baladima, Foteini
AU  - Sakellari, Chrysi
AU  - Kaouras, Konstantinos
T3  - CSCS '20
AB  - Autonomous vehicles (AVs) are increasingly becoming part of the emerging Intelligent Transportation Systems (ITS) and they are positioned to advance smart mobility. To enable this, new on-board sensors collect and transmit growing types and quantities of data. This raises new and unique privacy considerations around what happens with this data. As the automotive industry becomes more data-driven, getting consumer privacy rights will become increasingly important for establishing trust and customer acceptance of this technology. At the same time, the algorithmic decision making in AVs raises several new ethical issues that can create new safety risks and discriminatory outcomes. In this paper we analyze what are the new privacy and data protection challenges that emerge in AVs and investigate the ethical and liability concerns surrounding algorithmic decision-making, highlighting research gaps and the need to mitigate these issues by acting swiftly.
C1  - New York, NY, USA
C3  - Proceedings of the 4th ACM Computer Science in Cars Symposium
DA  - 2020///
PY  - 2020
DO  - 10.1145/3385958.3430481
PB  - Association for Computing Machinery
SN  - 978-1-4503-7621-1
UR  - https://doi.org/10.1145/3385958.3430481
KW  - autonomous driving
KW  - connected car
KW  - data protection
KW  - privacy
ER  - 

TY  - CONF
TI  - Land of the Lost: Privacy Patterns' Forgotten Properties: Enhancing Selection-Support for Privacy Patterns
AU  - Al-Momani, Ala'a
AU  - Wuyts, Kim
AU  - Sion, Laurens
AU  - Kargl, Frank
AU  - Joosen, Wouter
AU  - Erb, Benjamin
AU  - Bösch, Christoph
T3  - SAC '21
AB  - Privacy patterns describe core aspects of privacy-enhancing solutions to recurring problems and can, therefore, be instrumental to the privacy-by-design paradigm. However, the privacy patterns domain is still evolving. While the main focus is currently put on compiling and structuring high-quality privacy patterns in catalogs, the support for developers to select suitable privacy patterns is still limited. Privacy patterns selection-support means, in essence, the quick and easy scoping of a collection of patterns to the most applicable ones based on a set of predefined criteria. To evaluate patterns against these criteria, a thorough understanding of the privacy patterns landscape is required. In this paper, (i) we show that there is currently a lack of extensive support for privacy patterns selection due to the insufficient understanding of pattern properties, (ii) we propose additional properties that need to be analyzed and can serve as a first step towards a robust selection criteria, (iii) we analyze and present the properties for 70 privacy patterns, and (iv) we discuss a potential approach of how such a selection-support method can be realized.
C1  - New York, NY, USA
C3  - Proceedings of the 36th Annual ACM Symposium on Applied Computing
DA  - 2021///
PY  - 2021
DO  - 10.1145/3412841.3441996
SP  - 1217
EP  - 1225
PB  - Association for Computing Machinery
SN  - 978-1-4503-8104-8
UR  - https://doi.org/10.1145/3412841.3441996
KW  - privacy engineering
KW  - privacy patterns
KW  - software design
ER  - 

TY  - CONF
TI  - The User-Centered Privacy-Aware Control System PRICON: An Interdisciplinary Evaluation
AU  - Walter, J.
AU  - Abendroth, B.
AU  - von Pape, T.
AU  - Plappert, C.
AU  - Zelle, D.
AU  - Krauß, C.
AU  - Gagzow, G.
AU  - Decke, H.
T3  - ARES '18
AB  - The advent of connected vehicles has increased the relevance of privacy in cars. While current approaches to increase security and privacy in connected vehicles are mainly driven from technological perspectives, users do not have active control over their personal data. Therefore, the user-centered privacy-aware control system PrivacyController (PRICON) has been developed which incorporates expertise from judicial, technical and user-centered perspectives. PRICON provides users with a user-friendly possibility to define self-determined privacy policies which are applied to the vehicular system. In this paper, we report the evaluation of PRICON from a legal, technical and user-centered point-of-view. The evaluation results are discussed and practical implications are derived.
C1  - New York, NY, USA
C3  - Proceedings of the 13th International Conference on Availability, Reliability and Security
DA  - 2018///
PY  - 2018
DO  - 10.1145/3230833.3233269
PB  - Association for Computing Machinery
SN  - 978-1-4503-6448-5
UR  - https://doi.org/10.1145/3230833.3233269
KW  - Automotive
KW  - Legal Evaluation
KW  - Technical Evaluation
KW  - User-centered privacy-aware control system
KW  - User-centric Evaluation
ER  - 

TY  - CONF
TI  - Fine-Grained Privacy Control for the RFID Middleware of EPCglobal Networks
AU  - Tounsi, Wiem
AU  - Cuppens-Boulahia, Nora
AU  - Cuppens, Frédéric
AU  - Garcia-Alfaro, Joaquin
T3  - MEDES '13
AB  - The Electronic Product Code (EPC) is a Radio Frequency IDentification (RFID) that offers a new way of automating identification. However, once RFID tags carry more than just an identifier, privacy may be violated. Treating the privacy in early stages helps to master the data view before interpreting and storing it in databases. An RFID middleware is the entity that sits between tag readers and database applications. It is in charge of collecting, filtering, aggregating and grouping the requested events from heterogeneous RFID environments. Thus, the system, at this point, is likely to suffer from parameter manipulation and eavesdropping, raising privacy concerns. We propose a privacy controller module that enhances the Filtering and Collection middleware of the RFID EPCglobal network. We provide a privacy policy-driven model using some enhanced contextual concepts of the extended Role Based Access Control model. To show the feasibility of our privacy-enhanced model, we provide a proof-of-concept prototype integrated into the middleware of the Fosstrak framework, an open-source implementation of the EPCglobal specifications.
C1  - New York, NY, USA
C3  - Proceedings of the Fifth International Conference on Management of Emergent Digital EcoSystems
DA  - 2013///
PY  - 2013
DO  - 10.1145/2536146.2536154
SP  - 60
EP  - 67
PB  - Association for Computing Machinery
SN  - 978-1-4503-2004-7
UR  - https://doi.org/10.1145/2536146.2536154
KW  - access control
KW  - EPCglobal
KW  - middleware
KW  - privacy assurance
KW  - privacy policy
KW  - RFID
ER  - 

TY  - CONF
TI  - Data Augmentation for Fairness-Aware Machine Learning: Preventing Algorithmic Bias in Law Enforcement Systems
AU  - Pastaltzidis, Ioannis
AU  - Dimitriou, Nikolaos
AU  - Quezada-Tavarez, Katherine
AU  - Aidinlis, Stergios
AU  - Marquenie, Thomas
AU  - Gurzawska, Agata
AU  - Tzovaras, Dimitrios
T3  - FAccT '22
AB  - Researchers and practitioners in the fairness community have highlighted the ethical and legal challenges of using biased datasets in data-driven systems, with algorithmic bias being a major concern. Despite the rapidly growing body of literature on fairness in algorithmic decision-making, there remains a paucity of fairness scholarship on machine learning algorithms for the real-time detection of crime. This contribution presents an approach for fairness-aware machine learning to mitigate the algorithmic bias / discrimination issues posed by the reliance on biased data when building law enforcement technology. Our analysis is based on RWF-2000, which has served as the basis for violent activity recognition tasks in data-driven law enforcement projects. We reveal issues of overrepresentation of minority subjects in violence situations that limit the external validity of the dataset for real-time crime detection systems and propose data augmentation techniques to rebalance the dataset. The experiments on real world data show the potential to create more balanced datasets by synthetically generated samples, thus mitigating bias and discrimination concerns in law enforcement applications.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency
DA  - 2022///
PY  - 2022
DO  - 10.1145/3531146.3534644
SP  - 2302
EP  - 2314
PB  - Association for Computing Machinery
SN  - 978-1-4503-9352-2
UR  - https://doi.org/10.1145/3531146.3534644
ER  - 

TY  - CONF
TI  - What Does It Mean to 'solve' the Problem of Discrimination in Hiring? Social, Technical and Legal Perspectives from the UK on Automated Hiring Systems
AU  - Sánchez-Monedero, Javier
AU  - Dencik, Lina
AU  - Edwards, Lilian
T3  - FAT* '20
AB  - Discriminatory practices in recruitment and hiring are an ongoing issue that is a concern not just for workplace relations, but also for wider understandings of economic justice and inequality. The ability to get and keep a job is a key aspect of participating in society and sustaining livelihoods. Yet the way decisions are made on who is eligible for jobs, and why, are rapidly changing with the advent and growth in uptake of automated hiring systems (AHSs) powered by data-driven tools. Evidence of the extent of this uptake around the globe is scarce, but a recent report estimated that 98% of Fortune 500 companies use Applicant Tracking Systems of some kind in their hiring process, a trend driven by perceived efficiency measures and cost-savings. Key concerns about such AHSs include the lack of transparency and potential limitation of access to jobs for specific profiles. In relation to the latter, however, several of these AHSs claim to detect and mitigate discriminatory practices against protected groups and promote diversity and inclusion at work. Yet whilst these tools have a growing user-base around the world, such claims of 'bias mitigation' are rarely scrutinised and evaluated, and when done so, have almost exclusively been from a US socio-legal perspective.In this paper, we introduce a perspective outside the US by critically examining how three prominent automated hiring systems (AHSs) in regular use in the UK, HireVue, Pymetrics and Applied, understand and attempt to mitigate bias and discrimination. These systems have been chosen as they explicitly claim to address issues of discrimination in hiring and, unlike many of their competitors, provide some information about how their systems work that can inform an analysis. Using publicly available documents, we describe how their tools are designed, validated and audited for bias, highlighting assumptions and limitations, before situating these in the socio-legal context of the UK. The UK has a very different legal background to the US in terms not only of hiring and equality law, but also in terms of data protection (DP) law. We argue that this might be important for addressing concerns about transparency and could mean a challenge to building bias mitigation into AHSs definitively capable of meeting EU legal standards. This is significant as these AHSs, especially those developed in the US, may obscure rather than improve systemic discrimination in the workplace.
C1  - New York, NY, USA
C3  - Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency
DA  - 2020///
PY  - 2020
DO  - 10.1145/3351095.3372849
SP  - 458
EP  - 468
PB  - Association for Computing Machinery
SN  - 978-1-4503-6936-7
UR  - https://doi.org/10.1145/3351095.3372849
KW  - algorithmic decision-making
KW  - automated hiring
KW  - discrimination
KW  - fairness
KW  - GDPR
KW  - social justice
KW  - socio-technical systems
ER  - 

TY  - CONF
TI  - Privacy by Design and Software Engineering: A Systematic Literature Review
AU  - Andrade, Vinícius Camargo
AU  - Gomes, Rhodrigo Deda
AU  - Reinehr, Sheila
AU  - Freitas, Cinthia Obladen De Almendra
AU  - Malucelli, Andreia
T3  - SBQS '22
AB  - Service providers increasingly collect, process, store, and share data from their users to understand their preferences to make better decisions and make accurate estimates for the delivery of advertisements, products, and services. However, the misuse of personal data puts the privacy of the data subjects at risk. In addition, privacy can directly affect the quality of the software product. In an attempt to minimize these problems, the Privacy by Design approach has been proposed to ensure that privacy requirements are incorporated from the early stages of system development and applied to the entire data lifecycles. Meanwhile, Privacy by Design is often criticized due to its lack of specific methodology and tools capable of translating its principles into practical Software Engineering activities. Therefore, this research aims to investigate, through a systematic literature review, how Privacy by Design principles have been applied in the Software Engineering area. The search retrieved 6046 primary articles, published up to May 2022. After applying the inclusion and exclusion criteria, 75 primary studies were selected for analysis. The results show that there is a lack of models, processes, and tools to support Privacy by Design throughout the software development lifecycle and that it has become more relevant considering the requirements of the General Data Protection Regulation (GDPR).
C1  - New York, NY, USA
C3  - Proceedings of the XXI Brazilian Symposium on Software Quality
DA  - 2023///
PY  - 2023
DO  - 10.1145/3571473.3571480
PB  - Association for Computing Machinery
SN  - 978-1-4503-9999-9
UR  - https://doi.org/10.1145/3571473.3571480
KW  - Personal Data Protection
KW  - Privacy
KW  - Privacy by Design
KW  - Software Engineering
ER  - 

TY  - CONF
TI  - Learning from Online Regrets: From Deleted Posts to Risk Awareness in Social Network Sites
AU  - Díaz Ferreyra, Nicolás Emilio
AU  - Meis, Rene
AU  - Heisel, Maritta
T3  - UMAP'19 Adjunct
AB  - Social Network Sites (SNSs) like Facebook or Instagram are spaces where people expose their lives to wide and diverse audiences. This practice can lead to unwanted incidents such as reputation damage, job loss or harassment when pieces of private information reach unintended recipients. As a consequence, users often regret to have posted private information in these platforms and proceed to delete such content after having a negative experience. Risk awareness is a strategy that can be used to persuade users towards safer privacy decisions. However, many risk awareness technologies for SNSs assume that information about risks is retrieved and measured by an expert in the field. Consequently, risk estimation is an activity that is often passed over despite its importance. In this work we introduce an approach that employs deleted posts as risk information vehicles to measure the frequency and consequence level of self-disclosure patterns in SNSs. In this method, consequence is reported by the users through an ordinal scale and used later on to compute a risk criticality index. We thereupon show how this index can serve in the design of adaptive privacy nudges for SNSs.
C1  - New York, NY, USA
C3  - Adjunct Publication of the 27th Conference on User Modeling, Adaptation and Personalization
DA  - 2019///
PY  - 2019
DO  - 10.1145/3314183.3323849
SP  - 117
EP  - 125
PB  - Association for Computing Machinery
SN  - 978-1-4503-6711-0
UR  - https://doi.org/10.1145/3314183.3323849
KW  - adaptive privacy
KW  - awareness
KW  - privacy nudges
KW  - risk management
KW  - self-disclosure
KW  - social network sites
ER  - 

TY  - JOUR
TI  - Ethical Dimensions of User Centric Regulation
AU  - Urquhart, Lachlan
T2  - SIGCAS Comput. Soc.
AB  - In this paper, we question the role of information technology (IT) designers in IT regulation. Through our concept of user centric regulation (UCR) we unpack what a closer alignment of IT design and regulation could mean. We also situate how they can respond to their ethical and legal duties to end users. Our concept asserts that human computer interaction (HCI) designers are now regulators and as designers are not traditionally involved in the practice of regulation hence the nature of their role is ill-defined. We believe designers need support in understanding what their new role entails, particularly managing ethical dimensions that go beyond law and compliance. We use conceptual analysis to consolidate perspectives from across Human Computer Interaction and Information Technology Law and Regulation, Computer Ethics, Philosophy of Technology, and beyond. We focus in this paper on the importance of mediation and responsibility and illustrate our argument by drawing on the emerging technological setting of smart cities.
DA  - 2018/07//
PY  - 2018
DO  - 10.1145/3243141.3243151
VL  - 47
IS  - 4
SP  - 81
EP  - 95
SN  - 0095-2737
UR  - https://doi.org/10.1145/3243141.3243151
KW  - human computer interaction
KW  - information technology law and regulation
KW  - smart cities
ER  - 

TY  - CONF
TI  - A Critique of EU Digital COVID-19 Certificates: Do Vaccine Passports Endanger Privacy?
AU  - Halpin, Harry
T3  - ARES '22
AB  - Do COVID-19 vaccine passports come at a fundamental cost for personal privacy? Reviewing proposed COVID-19 credentials from a security and privacy standpoint raises concerns that make deploying COVID-19 digital certificates difficult at best. A closer look into the privacy of the EU Digital COVID-19 certificate presents a fundamental contradiction between two essential security properties: unforgeability and privacy. A substantial reconsideration of the very concept of vaccine passports may be needed to preserve fundamental privacy rights.
C1  - New York, NY, USA
C3  - Proceedings of the 17th International Conference on Availability, Reliability and Security
DA  - 2022///
PY  - 2022
DO  - 10.1145/3538969.3544459
PB  - Association for Computing Machinery
SN  - 978-1-4503-9670-7
UR  - https://doi.org/10.1145/3538969.3544459
KW  - COVID-19 certificates
KW  - privacy
KW  - security
KW  - standards
KW  - vaccine passports
ER  - 

TY  - CONF
TI  - A Risk Assessment Framework for Automotive Embedded Systems
AU  - Islam, Mafijul Md.
AU  - Lautenbach, Aljoscha
AU  - Sandberg, Christian
AU  - Olovsson, Tomas
T3  - CPSS '16
AB  - The automotive industry is experiencing a paradigm shift towards autonomous and connected vehicles. Coupled with the increasing usage and complexity of electrical and/or electronic systems, this introduces new safety and security risks. Encouragingly, the automotive industry has relatively well-known and standardised safety risk management practices, but security risk management is still in its infancy. In order to facilitate the derivation of security requirements and security measures for automotive embedded systems, we propose a specifically tailored risk assessment framework, and we demonstrate its viability with an industry use-case. Some of the key features are alignment with existing processes for functional safety, and usability for non-security specialists.The framework begins with a threat analysis to identify the assets, and threats to those assets. The following risk assessment process consists of an estimation of the threat level and of the impact level. This step utilises several existing standards and methodologies, with changes where necessary. Finally, a security level is estimated which is used to formulate high-level security requirements.The strong alignment with existing standards and processes should make this framework well-suited for the needs in the automotive industry.
C1  - New York, NY, USA
C3  - Proceedings of the 2nd ACM International Workshop on Cyber-Physical System Security
DA  - 2016///
PY  - 2016
DO  - 10.1145/2899015.2899018
SP  - 3
EP  - 14
PB  - Association for Computing Machinery
SN  - 978-1-4503-4288-9
UR  - https://doi.org/10.1145/2899015.2899018
KW  - automotive security
KW  - risk assessment
KW  - security requirements
KW  - threat analysis
ER  - 

TY  - CONF
TI  - The Bureaucratic Challenge to AI Governance: An Empirical Assessment of Implementation at U.S. Federal Agencies
AU  - Lawrence, Christie
AU  - Cui, Isaac
AU  - Ho, Daniel
T3  - AIES '23
AB  - Can government govern artificial intelligence (AI)? One of the central questions of AI governance surrounds state capacity, namely whether government has the ability to accomplish its policy goals. We study this question by assessing how well the U.S. federal government has implemented three binding laws around AI governance: two executive orders—concerning trustworthy AI in the public sector (E.O. 13,960) and AI leadership (E.O. 13,859)—and the AI in Government Act. We conduct the first systematic empirical assessment of the implementation status of these three laws, which have each been described as central to US AI innovation. First, we track, through extensive research, line-level adoption of each mandated action. Based on publicly available information, we find that fewer than 40 percent of 45 legal requirements could be verified as having been implemented. Second, we research the specific implementation of transparency requirements at up to 220 federal agencies. We find that nearly half of agencies failed to publicly issue AI use case inventories—even when these agencies have demonstrable use cases of machine learning. Even when agencies have complied with these requirements, efforts are inconsistent. Our work highlights the weakness of U.S. state capacity to carry out AI governance mandates and we discuss implications for how to address bureaucratic capacity challenges.
C1  - New York, NY, USA
C3  - Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society
DA  - 2023///
PY  - 2023
DO  - 10.1145/3600211.3604701
SP  - 606
EP  - 652
PB  - Association for Computing Machinery
SN  - 9798400702310
UR  - https://doi.org/10.1145/3600211.3604701
KW  - AI policy
KW  - bureaucracy
KW  - policy implementation
KW  - regulation
ER  - 

TY  - CONF
TI  - Opening Privacy Sensitive Microdata Sets in Light of GDPR
AU  - S. Bargh, Mortaza
AU  - Meijer, Ronald
AU  - Vink, Marco
AU  - van Den Braak, Susan
AU  - Schirm, Walter
AU  - Choenni, Sunil
T3  - dg.o 2019
AB  - To enhance the transparency, accountability and efficiency of the Dutch Ministry of Justice and Security, the ministry has set up an open data program to proactively stimulate sharing its (publicly funded) data sets with the public. Disclosure of personal data is considered as one of the main threats for data opening. In this contribution we argue that, according to Dutch laws, the criminal data within the Dutch justice domain are sensitive data in GDPR terms and that the criminal data can only be opened if these sensitive data are transformed to have no personal information. Subsequently, having no personal information in data sets is related to two GDPR concepts: the data being anonymous in its GDPR sense or the data being pseudonymized in its GDPR sense. These two GDPR concepts, i.e., being anonymous data or pseudonymized data in a GDPR sense, can be distinguished in our setting based on whether the data controller cannot or can revert the data protection process, respectively. (Note that the terms anonymous and pseudonymized are interpreted differently in the technical domain.) We examine realizing these GDPR concepts with the Statistical Disclosure Control (SDC) technology and subsequently argue that pseudonymized data in a GDPR sense delivers a better data utility than the other. At the end, we present a number of the consequences of adopting either of these concepts, which can inform legislators and policymakers to define their strategy for opening privacy sensitive microdata sets, like those pertaining to the Dutch criminal justice domain.
C1  - New York, NY, USA
C3  - Proceedings of the 20th Annual International Conference on Digital Government Research
DA  - 2019///
PY  - 2019
DO  - 10.1145/3325112.3325222
SP  - 314
EP  - 323
PB  - Association for Computing Machinery
SN  - 978-1-4503-7204-6
UR  - https://doi.org/10.1145/3325112.3325222
KW  - Criminal justice data
KW  - Data protection
KW  - GDPR
KW  - Justice domain data
KW  - Microdata
KW  - Open data
KW  - Privacy
ER  - 

TY  - CONF
TI  - Exploiting Data Analytics for Social Services: On Searching for Profiles of Unlawful Use of Social Benefits
AU  - Netten, Niels
AU  - Bargh, Mortaza S.
AU  - Choenni, Sunil
T3  - ICEGOV '18
AB  - In this paper we present a data-driven profiling approach that we have adopted and implemented for a municipality. Our aim was to make profiles transparent and meaningful for citizens, policymakers and authorities so that they can validate, scrutinize and challenge the profiles. Our approach relies on a Genetic Algorithm (GA) that searches for useful and human understandable group profiles. Furthermore, we discuss some of the challenges encountered, show a selection of the profiles that were found by the GA, and discuss the necessity and a number of ways of validating these profiles in accordance with, e.g., privacy and non-discrimination laws and guidelines before using them in practice.
C1  - New York, NY, USA
C3  - Proceedings of the 11th International Conference on Theory and Practice of Electronic Governance
DA  - 2018///
PY  - 2018
DO  - 10.1145/3209415.3209481
SP  - 550
EP  - 559
PB  - Association for Computing Machinery
SN  - 978-1-4503-5421-9
UR  - https://doi.org/10.1145/3209415.3209481
KW  - Data analytics
KW  - Genetic Algorithm
KW  - profiling
KW  - social benefits
ER  - 

TY  - CONF
TI  - Privacy Analysis Using Ontologies
AU  - Kost, Martin
AU  - Freytag, Johann Christoph
T3  - CODASPY '12
AB  - As information systems extensively exchange information between participants, privacy concerns may arise from potential misuse. Existing design approaches consider non-technical privacy requirements of different stakeholders during the design and the implementation of a system. However, a technical approach for privacy analysis is largely missing.This paper introduces a formal approach for technically evaluating an information system with respect to its designed or implemented privacy protection. In particular, we introduce a system model that describes various system aspects such as its information flow. We define the semantics of this system model by using ontologies. Based on the system model together with a given privacy ontology, and given privacy requirements we analyze the modeled system to detect privacy leakages and to calculate privacy indicators. The proposed method provides a technical approach to check whether a system conforms to the privacy requirements of the stakeholders or not.
C1  - New York, NY, USA
C3  - Proceedings of the Second ACM Conference on Data and Application Security and Privacy
DA  - 2012///
PY  - 2012
DO  - 10.1145/2133601.2133627
SP  - 205
EP  - 216
PB  - Association for Computing Machinery
SN  - 978-1-4503-1091-8
UR  - https://doi.org/10.1145/2133601.2133627
KW  - analysis
KW  - ontologies
KW  - privacy
KW  - requirements
KW  - system model
ER  - 

TY  - CONF
TI  - Tackling Algorithmic Disability Discrimination in the Hiring Process: An Ethical, Legal and Technical Analysis
AU  - Buyl, Maarten
AU  - Cociancig, Christina
AU  - Frattone, Cristina
AU  - Roekens, Nele
T3  - FAccT '22
AB  - Tackling algorithmic discrimination against persons with disabilities (PWDs) demands a distinctive approach that is fundamentally different to that applied to other protected characteristics, due to particular ethical, legal, and technical challenges. We address these challenges specifically in the context of artificial intelligence (AI) systems used in hiring processes (or automated hiring systems, AHSs), in which automated assessment procedures are subject to unique ethical and legal considerations and have an undeniable adverse impact on PWDs. In this paper, we discuss concerns and opportunities raised by AI-driven hiring in relation to disability discrimination. Ultimately, we aim to encourage further research into this topic. Hence, we establish some starting points and design a roadmap for ethicists, lawmakers, advocates as well as AI practitioners alike.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency
DA  - 2022///
PY  - 2022
DO  - 10.1145/3531146.3533169
SP  - 1071
EP  - 1082
PB  - Association for Computing Machinery
SN  - 978-1-4503-9352-2
UR  - https://doi.org/10.1145/3531146.3533169
KW  - algorithmic discrimination
KW  - Artificial Intelligence Act
KW  - automated hiring systems
KW  - data protection law
KW  - equality law
KW  - ethics of discrimination
KW  - persons with disabilities
KW  - reasonable accommodation
KW  - social justice
ER  - 

TY  - CONF
TI  - Promises and Perils of Inferring Personality on GitHub
AU  - van Mil, Frenk C.J.
AU  - Rastogi, Ayushi
AU  - Zaidman, Andy
T3  - ESEM '21
AB  - Background: Personality plays a pivotal role in our understanding of human actions and behavior. Today, the applications of personality are widespread, built on the solutions from psychology to infer personality. Aim: In software engineering, for instance, one widely used solution to infer personality uses textual communication data. As studies on personality in software engineering continue to grow, it is imperative to understand the performance of these solutions. Method: This paper compares the inferential ability of three widely studied text-based personality tests against each other and the ground truth on GitHub. We explore the challenges and potential solutions to improve the inferential ability of personality tests. Results: Our study shows that solutions for inferring personality are far from being perfect. Software engineering communications data can infer individual developer personality with an average error rate of 41%. In the best case, the error rate can be reduced up to 36% by following our recommendations1.
C1  - New York, NY, USA
C3  - Proceedings of the 15th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)
DA  - 2021///
PY  - 2021
DO  - 10.1145/3475716.3475775
PB  - Association for Computing Machinery
SN  - 978-1-4503-8665-4
UR  - https://doi.org/10.1145/3475716.3475775
KW  - LIWC
KW  - Mining Software Repositories
KW  - Personality
KW  - Personality Insights
KW  - Software Developer
ER  - 

TY  - JOUR
TI  - A Narrative Review of Factors Affecting the Implementation of Privacy and Security Practices in Software Development
AU  - Nurgalieva, Leysan
AU  - Frik, Alisa
AU  - Doherty, Gavin
T2  - ACM Comput. Surv.
AB  - Privacy and security are complex topics, raising a variety of considerations and requirements that can be challenging to implement in software development. Determining the security and privacy related factors that have an influence on software systems development and deployment project outcomes has been the focus of extensive and ongoing research over the past two decades. To understand and categorize the factors that have an impact on developers’ adoption and implementation of privacy and security considerations and practices in software development, we carried out a narrative review of the literature. The resulting mapping of factors provides a foundation for future interventions targeting organizational and individual behavior change, to increase the adoption of privacy and security practices in software development.
DA  - 2023/07//
PY  - 2023
DO  - 10.1145/3589951
VL  - 55
IS  - 14s
SN  - 0360-0300
UR  - https://doi.org/10.1145/3589951
KW  - design
KW  - Privacy
KW  - security
KW  - software teams
ER  - 

TY  - CONF
TI  - Open Data Policies Analysis Disputes Mediation Cases in Korea: Based on OUR Data Index and ODB
AU  - Seo, Jeongeun
AU  - Kim, Beopyeon
AU  - Kwon, Hun Yeong
T3  - DG.O'21
AB  - Data is a critical driving force for industrial development and new value creation in the fourth industrial revolution era. As a result, the government's disclosure of data to the public has become an issue worldwide, leading to an increase in the trend of open data. Simultaneously, in providing and using data due to open data policies, disputes increasingly arise due to the refusal or discontinuation of data provided by public institutions. To solve this problem, policies were introduced to mediate disputes over the provision of public data. This paper analyzes the policies on Mediation of Disputes over the Provision of Public Data, which is part of The Republic of Korea's open data policy, and its cases, and examines the current policies on Mediation of Disputes over the Provision of Public Data in The Republic of Korea. It also uses the OECD's Open, Useful, Reusable (OUR) Data Index and WWW Foundation's Open Data Barometer (ODB) to identify The Republic of Korea's policies on Mediation of Disputes over Provision of Public Data and to identify its excellence and improvements. It can be seen as the first paper to use two globally accepted indexes to analyze cases of public data dispute mediation, identify current circumstances, and present their excellence and direction of improvement. At the same time, we explain to the open government latecomers what they should benchmark through The Republic of Korean cases.
C1  - New York, NY, USA
C3  - DG.O2021: The 22nd Annual International Conference on Digital Government Research
DA  - 2021///
PY  - 2021
DO  - 10.1145/3463677.3463735
SP  - 153
EP  - 167
PB  - Association for Computing Machinery
SN  - 978-1-4503-8492-6
UR  - https://doi.org/10.1145/3463677.3463735
ER  - 

TY  - CONF
TI  - Bringing Design to the Privacy Table: Broadening “Design” in “Privacy by Design” Through the Lens of HCI
AU  - Wong, Richmond Y.
AU  - Mulligan, Deirdre K.
T3  - CHI '19
AB  - In calls for privacy by design (PBD), regulators and privacy scholars have investigated the richness of the concept of "privacy." In contrast, "design" in HCI is comprised of rich and complex concepts and practices, but has received much less attention in the PBD context. Conducting a literature review of HCI publications discussing privacy and design, this paper articulates a set of dimensions along which design relates to privacy, including: the purpose of design, which actors do design work in these settings, and the envisioned beneficiaries of design work. We suggest new roles for HCI and design in PBD research and practice: utilizing values- and critically-oriented design approaches to foreground social values and help define privacy problem spaces. We argue such approaches, in addition to current "design to solve privacy problems" efforts, are essential to the full realization of PBD, while noting the politics involved when choosing design to address privacy.
C1  - New York, NY, USA
C3  - Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems
DA  - 2019///
PY  - 2019
DO  - 10.1145/3290605.3300492
SP  - 1
EP  - 17
PB  - Association for Computing Machinery
SN  - 978-1-4503-5970-2
UR  - https://doi.org/10.1145/3290605.3300492
KW  - critically oriented design
KW  - design approaches
KW  - design research
KW  - privacy by design
ER  - 

TY  - JOUR
TI  - 'Transparency is Meant for Control' and Vice Versa: Learning from Co-Designing and Evaluating Algorithmic News Recommenders
AU  - Storms, Elias
AU  - Alvarado, Oscar
AU  - Monteiro-Krebs, Luciana
T2  - Proc. ACM Hum.-Comput. Interact.
AB  - Algorithmic systems that recommend content often lack transparency about how they come to their suggestions. One area in which recommender systems are increasingly prevalent is online news distribution. In this paper, we explore how a lack of transparency of (news) recommenders can be tackled by involving users in the design of interface elements. In the context of automated decision-making, legislative frameworks such as the GDPR in Europe introduce a specific conception of transparency, granting 'data subjects' specific rights and imposing obligations on service providers. An important related question is how people using personalized recommender systems relate to the issue of transparency, not as legal data subjects but as users. This paper builds upon a two-phase study on how users conceive of transparency and related issues in the context of algorithmic news recommenders. We organized co-design workshops to elicit participants' 'algorithmic imaginaries' and invited them to ideate interface elements for increased transparency. This revealed the importance of combining legible transparency features with features that increase user control. We then conducted a qualitative evaluation of mock-up prototypes to investigate users' preferences and concerns when dealing with design features to increase transparency and control. Our investigation illustrates how users' expectations and impressions of news recommenders are closely related to their news reading practices. On a broader level, we show how transparency and control are conceptually intertwined. Transparency without control leaves users frustrated. Conversely, without a basic level of transparency into how a system works, users remain unsure of the impact of controls.
DA  - 2022/11//
PY  - 2022
DO  - 10.1145/3555130
VL  - 6
IS  - CSCW2
UR  - https://doi.org/10.1145/3555130
KW  - algorithms
KW  - co-design
KW  - news recommenders
KW  - transparency
ER  - 

TY  - CONF
TI  - In-Depth Technical and Legal Analysis of Tracking on Health Related Websites with ERNIE Extension
AU  - Wesselkamp, Vera
AU  - Fouad, Imane
AU  - Santos, Cristiana
AU  - Boussad, Yanis
AU  - Bielova, Nataliia
AU  - Legout, Arnaud
T3  - WPES '21
AB  - Searching the Web to find doctors and make appointments online is a common practice nowadays. However, simply visiting a doctors website might disclose health related information. As the GDPR only allows processing of health data with explicit user consent, health related websites must ask consent before any data processing, in particular when they embed third party trackers.Admittedly, it is very hard for owners of such websites to both detect the complex tracking practices that exist today and to ensure legal compliance.In this paper, we present ERNIE, a browser extension we designed to visualise six state-of-the-art tracking techniques based on cookies. Using ERNIE, we analysed 385 health related websites that users would visit when searching for doctors in Germany, Austria, France, Belgium, and Ireland. More specifically, we explored the tracking behavior before any interaction with the consent pop-up and after rejection of cookies on websites of doctors, hospitals, and health related online phone-books. We found that at least one form of tracking occurs on 62% of the websites before interacting with the consent pop-up, and 15% of websites include tracking after rejection. Finally, we performed a detailed technical and legal analysis of three health related websites that demonstrate impactful legal violations.This paper shows that while, from a legal point of view, health related websites are more privacy-sensitive than other kinds of websites, they are exposed to the same technical difficulties to implement a legally compliant website. We believe ERNIE, the browser extension we developed, to be an invaluable tool for policy-makers and regulators to improve detection and visualization of the complex tracking techniques used on these websites.
C1  - New York, NY, USA
C3  - Proceedings of the 20th Workshop on Workshop on Privacy in the Electronic Society
DA  - 2021///
PY  - 2021
DO  - 10.1145/3463676.3485603
SP  - 151
EP  - 166
PB  - Association for Computing Machinery
SN  - 978-1-4503-8527-5
UR  - https://doi.org/10.1145/3463676.3485603
KW  - browser extension
KW  - explicit consent
KW  - gdpr
KW  - health data
KW  - tracking
ER  - 

TY  - CONF
TI  - How Attacker Knowledge Affects Privacy Risks: An Analysis Using Probabilistic Programming
AU  - Halvorsen, Louise
AU  - Steffensen, Siv L.
AU  - Rafnsson, Willard
AU  - Kulyk, Oksana
AU  - Pardo, Raúl
T3  - IWSPA '22
AB  - Governments and businesses routinely disclose large amounts of private data on individuals, for data analytics. However, despite attempts by data controllers to anonymise data, attackers frequently deanonymise disclosed data by matching it with their prior knowledge. When is a chosen anonymisation method adequate? For this, a data controller must consider attackers befitting their scenario; how does attacker knowledge affect disclosure risk? We present a multi-dimensional conceptual framework for assessing privacy risks given prior knowledge about data. The framework defines three dimensions: distinctness (of input records), informedness (of attacker), and granularity (of anonymisation program output). We model three well-known types of disclosure risk: identity disclosure, attribute disclosure, and quantitative attribute disclosure. We demonstrate how to apply this framework in a health record privacy scenario: We analyse how informing the attacker with COVID-19 infection rates affects privacy risks. We perform this analysis using Privug, a method that uses probabilistic programming to do standard statistical analysis with Bayesian Inference.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 ACM on International Workshop on Security and Privacy Analytics
DA  - 2022///
PY  - 2022
DO  - 10.1145/3510548.3519380
SP  - 55
EP  - 65
PB  - Association for Computing Machinery
SN  - 978-1-4503-9230-3
UR  - https://doi.org/10.1145/3510548.3519380
KW  - anonymization
KW  - health privacy
KW  - privacy
KW  - probabilistic programming
ER  - 

TY  - CONF
TI  - Privacy by Design in Aged Care Monitoring Devices? Well, Not Quite Yet!
AU  - Alkhatib, Sami
AU  - Waycott, Jenny
AU  - Buchanan, George
AU  - Grobler, Marthie
AU  - Wang, Shuo
T3  - OzCHI '20
AB  - Aged Care Monitoring Devices (ACMDs) collect and share information about older adults to ensure their wellbeing. While monitoring devices enable older adults to live independently at home, they pose significant privacy challenges. Within HCI, research has sought to understand users’ privacy concerns, but technology developers’ perceptions of privacy have been explored less. According to the Privacy by Design (PbD) framework, developers should incorporate privacy safeguards into devices prior to deployment. However, little is known about how this is done in practice. To better understand developers’ views on privacy, we interviewed 12 developers from ACMD companies and found five factors that affect how they address privacy: 1) users’ requirements, 2) presumptions about users’ privacy perceptions, 3) privacy laws and regulations, 4) third-party providers, and 5) financial challenges. These factors interconnect with other internal organisational challenges. Our research demonstrates the constraints that make it difficult for developers to implement PbD in practice.
C1  - New York, NY, USA
C3  - Proceedings of the 32nd Australian Conference on Human-Computer Interaction
DA  - 2021///
PY  - 2021
DO  - 10.1145/3441000.3441049
SP  - 492
EP  - 505
PB  - Association for Computing Machinery
SN  - 978-1-4503-8975-4
UR  - https://doi.org/10.1145/3441000.3441049
ER  - 

TY  - CONF
TI  - A Collaborative Approach to Support Medication Management in Older Adults with Mild Cognitive Impairment Using Conversational Assistants (CAs)
AU  - Mathur, Niharika
AU  - Dhodapkar, Kunal
AU  - Zubatiy, Tamara
AU  - Li, Jiachen
AU  - Jones, Brian
AU  - Mynatt, Elizabeth
T3  - ASSETS '22
AB  - Improving medication management for older adults with Mild Cognitive Impairment (MCI) requires designing systems that support functional independence and provide compensatory strategies as their abilities change. Traditional medication management interventions emphasize forming new habits alongside the traditional path of learning to use new technologies. In this study, we navigate designing for older adults with gradual cognitive decline by creating a conversational “check-in” system for routine medication management. We present the design of MATCHA - Medication Action To Check-In for Health Application, informed by exploratory focus groups and design sessions conducted with older adults with MCI and their caregivers, alongside our evaluation based on a two-phased deployment period of 20 weeks. Our results indicate that a conversational “check-in” medication management assistant increased system acceptance while also potentially decreasing the likelihood of accidental over-medication, a common concern for older adults dealing with MCI.
C1  - New York, NY, USA
C3  - Proceedings of the 24th International ACM SIGACCESS Conference on Computers and Accessibility
DA  - 2022///
PY  - 2022
DO  - 10.1145/3517428.3544830
PB  - Association for Computing Machinery
SN  - 978-1-4503-9258-7
UR  - https://doi.org/10.1145/3517428.3544830
KW  - conversational assistants
KW  - medication management
KW  - mild cognitive impairment
KW  - older adults
ER  - 

TY  - CONF
TI  - Enhanced Membership Inference Attacks against Machine Learning Models
AU  - Ye, Jiayuan
AU  - Maddi, Aadyaa
AU  - Murakonda, Sasi Kumar
AU  - Bindschaedler, Vincent
AU  - Shokri, Reza
T3  - CCS '22
AB  - How much does a machine learning algorithm leak about its training data, and why? Membership inference attacks are used as an auditing tool to quantify this leakage. In this paper, we present a comprehensivehypothesis testing framework that enables us not only to formally express the prior work in a consistent way, but also to design new membership inference attacks that use reference models to achieve a significantly higher power (true positive rate) for any (false positive rate) error. More importantly, we explainwhy different attacks perform differently. We present a template for indistinguishability games, and provide an interpretation of attack success rate across different instances of the game. We discuss various uncertainties of attackers that arise from the formulation of the problem, and show how our approach tries to minimize the attack uncertainty to the one bit secret about the presence or absence of a data point in the training set. We perform adifferential analysis between all types of attacks, explain the gap between them, and show what causes data points to be vulnerable to an attack (as the reasons vary due to different granularities of memorization, from overfitting to conditional memorization). Our auditing framework is openly accessible as part of thePrivacy Meter software tool.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security
DA  - 2022///
PY  - 2022
DO  - 10.1145/3548606.3560675
SP  - 3093
EP  - 3106
PB  - Association for Computing Machinery
SN  - 978-1-4503-9450-5
UR  - https://doi.org/10.1145/3548606.3560675
KW  - indistinguishability game
KW  - membership inference
KW  - privacy auditing
ER  - 

TY  - JOUR
TI  - From Privacy Methods to a Privacy Toolbox: Evaluation Shows That Heuristics Are Complementary
AU  - Iachello, Giovanni
AU  - Abowd, Gregory D.
T2  - ACM Trans. Comput.-Hum. Interact.
AB  - We describe the two-year-long development and evaluation of the Proportionality Method, a design method intended to aid HCI practitioners in designing advanced IT applications with complex privacy implications. The method is inspired by Data Protection Authorities' (DPA) and Courts' practice and proposes to balance the impact on privacy of IT applications with their usefulness. We discuss the results of an evaluation of the design method to verify its usability, usefulness and effectiveness vis-à-vis other design methods proposed in the HCI literature to address similar issues. Results suggest that different design methods for privacy highlight different sets of issues and a combination of methods should be employed in a comprehensive design process. We propose to judge design methods based on their overall quantitative and qualitative merits, including the type of application and technology for which they are most fit and their methodological approach. We finally propose to develop a privacy toolbox, that is, a set of heuristic methods that designers can choose from with knowledge and understanding of their relative advantages and limitations.
DA  - 2008/07//
PY  - 2008
DO  - 10.1145/1375761.1375763
VL  - 15
IS  - 2
SN  - 1073-0516
UR  - https://doi.org/10.1145/1375761.1375763
KW  - design methods
KW  - Privacy
KW  - proportionality
KW  - requirements analysis
KW  - risk analysis
KW  - social issues
KW  - ubiquitous computing
ER  - 

TY  - CONF
TI  - Data Protection Law and Multi-Party Computation: Applications to Information Exchange between Law Enforcement Agencies
AU  - Treiber, Amos
AU  - Müllmann, Dirk
AU  - Schneider, Thomas
AU  - Spiecker genannt Döhmann, Indra
T3  - WPES'22
AB  - Pushes for increased power of Law Enforcement (LE) for data retention and centralized storage result in legal challenges with data protection law and courts-and possible violations of the right to privacy. This is motivated by a desire for better cooperation and exchange between LE Agencies (LEAs), which is difficult due to data protection regulations, was identified as a main factor of major public security failures, and is a frequent criticism of LE. Secure Multi-Party Computation (MPC) is often seen as a technological means to solve privacy conflicts where actors want to exchange and analyze data that needs to be protected due to data protection laws. In this interdisciplinary work, we investigate the problem of private information exchange between LEAs from both a legal and technical angle. We give a legal analysis of secret-sharing based MPC techniques in general and, as a particular application scenario, consider the case of matching LE databases for lawful information exchange between LEAs. We propose a system for lawful information exchange between LEAs using MPC and private set intersection and show its feasibility by giving a legal analysis for data protection and a technical analysis for workload complexity. Towards practicality, we present insights from qualitative feedback gathered within exchanges with a major European LEA.
C1  - New York, NY, USA
C3  - Proceedings of the 21st Workshop on Privacy in the Electronic Society
DA  - 2022///
PY  - 2022
DO  - 10.1145/3559613.3563192
SP  - 69
EP  - 82
PB  - Association for Computing Machinery
SN  - 978-1-4503-9873-2
UR  - https://doi.org/10.1145/3559613.3563192
KW  - data protection law
KW  - law enforcement
KW  - secure computation
ER  - 

TY  - CONF
TI  - Close-up and Whispering: An Understanding of Multimodal and Parasocial Interactions in YouTube ASMR Videos
AU  - Niu, Shuo
AU  - Manon, Hugh S.
AU  - Bartolome, Ava
AU  - Ha, Nguyen Binh
AU  - Veazey, Keegan
T3  - CHI '22
AB  - ASMR (Autonomous Sensory Meridian Response) has grown to immense popularity on YouTube and drawn HCI designers’ attention to its effects and applications in design. YouTube ASMR creators incorporate visual elements, sounds, motifs of touching and tasting, and other scenarios in multisensory video interactions to deliver enjoyable and relaxing experiences to their viewers. ASMRtists engage viewers by social, physical, and task attractions. Research has identified the benefits of ASMR in mental wellbeing. However, ASMR remains an understudied phenomenon in the HCI community, constraining designers’ ability to incorporate ASMR in video-based designs. This work annotates and analyzes the interaction modalities and parasocial attractions of 2663 videos to identify unique experiences. YouTube comment sections are also analyzed to compare viewers’ responses to different ASMR interactions. We find that ASMR videos are experiences of multimodal social connection, relaxing physical intimacy, and sensory-rich activity observation. Design implications are discussed to foster future ASMR-augmented video interactions.
C1  - New York, NY, USA
C3  - Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems
DA  - 2022///
PY  - 2022
DO  - 10.1145/3491102.3517563
PB  - Association for Computing Machinery
SN  - 978-1-4503-9157-3
UR  - https://doi.org/10.1145/3491102.3517563
KW  - ASMR
KW  - experience
KW  - multimodal
KW  - parasocial
KW  - video
KW  - YouTube
ER  - 

TY  - CONF
TI  - Rethinking the Proposition of Privacy Engineering
AU  - Ceross, Aaron
AU  - Simpson, Andrew
T3  - NSPW '18
AB  - The field of privacy engineering proposes a methodological framework for designing privacy-protecting information systems. Recognising that the utilisation of privacy-enhancing techniques for data storage and analysis does not address the entire scope of individual privacy, privacy engineering incorporates influences from user sentiment, legal norms and risk analysis in order to provide a holistic approach. Framed by related design principles, such as 'Privacy-by-Design', privacy engineering purports to provide a practical, deployable set of methods by which to achieve such a holistic outcome. Yet, despite this aim, there have been difficulties in adequately articulating the value proposition of privacy engineering. Without being able to adequately define privacy or map its contours, any proposed methodology or framework will be difficult to implement in practice, if not self-defeating. This paper identifies and examines the assumptions that underpin privacy engineering, linking them to shortcomings and open questions. Further, we explore possible research avenues that may give rise to alternative frameworks.
C1  - New York, NY, USA
C3  - Proceedings of the New Security Paradigms Workshop
DA  - 2018///
PY  - 2018
DO  - 10.1145/3285002.3285006
SP  - 89
EP  - 102
PB  - Association for Computing Machinery
SN  - 978-1-4503-6597-0
UR  - https://doi.org/10.1145/3285002.3285006
ER  - 

TY  - JOUR
TI  - Technical Requirements and Approaches in Personal Data Control
AU  - Sim, Junsik
AU  - Kim, Beomjoong
AU  - Jeon, Kiseok
AU  - Joo, Moonho
AU  - Lim, Jihun
AU  - Lee, Junghee
AU  - Choo, Kim-Kwang Raymond
T2  - ACM Comput. Surv.
AB  - There has been a trend of moving from simply de-identification to providing extended data control to their owner (e.g., data portability and right to be forgotten), partly due to the introduction of the General Data Protection Regulation (GDPR). Hence, in this paper, we survey the literature to provide an in-depth understanding of the existing approaches for personal data control (e.g., we observe that most existing approaches are generally designed to facilitate compliance), as well as the privacy regulations in Europe, United Kingdom, California, South Korea, and Japan. Based on the review, we identify the associated technical requirements, as well as a number of research gaps and potential future directions (e.g., the need for transparent processing of personal data and establishment of clear procedure in ensuring personal data control).
DA  - 2023/01//
PY  - 2023
DO  - 10.1145/3558766
VL  - 55
IS  - 9
SN  - 0360-0300
UR  - https://doi.org/10.1145/3558766
KW  - compliance
KW  - control rights
KW  - Personal data
ER  - 

TY  - CONF
TI  - Privacy Champions in Software Teams: Understanding&nbsp;Their&nbsp;Motivations,&nbsp;Strategies,&nbsp;and&nbsp;Challenges
AU  - Tahaei, Mohammad
AU  - Frik, Alisa
AU  - Vaniea, Kami
T3  - CHI '21
AB  - Software development teams are responsible for making and implementing software design decisions that directly impact end-user privacy, a challenging task to do well. Privacy Champions—people who strongly care about advocating privacy—play a useful role in supporting privacy-respecting development cultures. To understand their motivations, challenges, and strategies for protecting end-user privacy, we conducted 12 interviews with Privacy Champions in software development teams. We find that common barriers to implementing privacy in software design include: negative privacy culture, internal prioritisation tensions, limited tool support, unclear evaluation metrics, and technical complexity. To promote privacy, Privacy Champions regularly use informal discussions, management support, communication among stakeholders, and documentation and guidelines. They perceive code reviews and practical training as more instructive than general privacy awareness and on-boarding training. Our study is a first step towards understanding how Privacy Champions work to improve their organisation’s privacy approaches and improve the privacy of end-user products.
C1  - New York, NY, USA
C3  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
DA  - 2021///
PY  - 2021
DO  - 10.1145/3411764.3445768
PB  - Association for Computing Machinery
SN  - 978-1-4503-8096-6
UR  - https://doi.org/10.1145/3411764.3445768
KW  - privacy champions
KW  - software development
KW  - user privacy
ER  - 

TY  - JOUR
TI  - One More Bite? Inferring Food Consumption Level of College Students Using Smartphone Sensing and Self-Reports
AU  - Meegahapola, Lakmal
AU  - Ruiz-Correa, Salvador
AU  - Robledo-Valero, Viridiana del Carmen
AU  - Hernandez-Huerfano, Emilio Ernesto
AU  - Alvarez-Rivera, Leonardo
AU  - Chenu-Abente, Ronald
AU  - Gatica-Perez, Daniel
T2  - Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.
AB  - While the characterization of food consumption level has been extensively studied in nutrition and psychology research, advancements in passive smartphone sensing have not been fully utilized to complement mobile food diaries in characterizing food consumption levels. In this study, a new dataset regarding the holistic food consumption behavior of 84 college students in Mexico was collected using a mobile application combining passive smartphone sensing and self-reports. We show that factors such as sociability and activity types and levels have an association to food consumption levels. Finally, we define and assess a novel ubicomp task, by using machine learning techniques to infer self-perceived food consumption level (eating as usual, overeating, undereating) with an accuracy of 87.81% in a 3-class classification task by using passive smartphone sensing and self-report data. Furthermore, we show that an accuracy of 83.49% can be achieved for the same classification task by using only smartphone sensing data and time of eating, which is an encouraging step towards building context-aware mobile food diaries and making food diary based apps less tedious for users.
DA  - 2021/03//
PY  - 2021
DO  - 10.1145/3448120
VL  - 5
IS  - 1
UR  - https://doi.org/10.1145/3448120
KW  - eating behavior
KW  - food consumption
KW  - health
KW  - overeating
KW  - passive mobile sensing
KW  - well-being
ER  - 

TY  - CONF
TI  - Analyzing the Use of Public and In-House Secure Development Guidelines in U.S. and Japanese Industries
AU  - Kanei, Fumihiro
AU  - Hasegawa, Ayako A.
AU  - Shioji, Eitaro
AU  - Akiyama, Mitsuaki
T3  - CHI '23
AB  - Secure development guidelines contribute to improving software security from the development stage by making developers aware of the risks to be assumed, the necessary security countermeasures, and how to implement them. In this study, we investigated the actual utilization of guidelines and their usability in the industry through a survey of software development professionals in the U.S. and Japan (N=396 in the U.S. and N=474 in Japan). Our quantitative analysis revealed that “in-house” guidelines not examined in most existing studies are in fact widely utilized in the industry and also clarified how they are related to the use of public guidelines. In addition, we found that the practices for implementing guidelines recommended by existing studies are difficult for software development professionals with certain attributes, e.g., those who are working on small projects. The findings demonstrate the need for lightweight recommended practices taking into account organizational issues at industrial development sites that are easy for developers to implement.
C1  - New York, NY, USA
C3  - Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544548.3580705
PB  - Association for Computing Machinery
SN  - 978-1-4503-9421-5
UR  - https://doi.org/10.1145/3544548.3580705
KW  - HCI for development
KW  - Secure programming
KW  - Security
KW  - Survey
ER  - 

TY  - JOUR
TI  - DAISY: Dynamic-Analysis-Induced Source Discovery for Sensitive Data
AU  - Zhang, Xueling
AU  - Heaps, John
AU  - Slavin, Rocky
AU  - Niu, Jianwei
AU  - Breaux, Travis
AU  - Wang, Xiaoyin
T2  - ACM Trans. Softw. Eng. Methodol.
AB  - Mobile apps are widely used and often process users’ sensitive data. Many taint analysis tools have been applied to analyze sensitive information flows and report data leaks in apps. These tools require a list of sources (where sensitive data is accessed) as input, and researchers have constructed such lists within the Android platform by identifying Android API methods that allow access to sensitive data. However, app developers may also define methods or use third-party library’s methods for accessing data. It is difficult to collect such source methods, because they are unique to the apps, and there are a large number of third-party libraries available on the market that evolve over time. To address this problem, we propose DAISY, a Dynamic-Analysis-Induced Source discoverY approach for identifying methods that return sensitive information from apps and third-party libraries. Trained on an automatically labeled dataset of methods and their calling context, DAISY identifies sensitive methods in unseen apps. We evaluated DAISY on real-world apps, and the results show that DAISY can achieve an overall precision of 77.9% when reporting the most confident results. Most of the identified sources and leaks cannot be detected by existing technologies.
DA  - 2023/05//
PY  - 2023
DO  - 10.1145/3569936
VL  - 32
IS  - 4
SN  - 1049-331X
UR  - https://doi.org/10.1145/3569936
KW  - mobile application
KW  - natural language processing
KW  - Privacy leak
ER  - 

TY  - CONF
TI  - Privacy is a Process, Not a PET: A Theory for Effective Privacy Practice
AU  - Morton, Anthony
AU  - Sasse, M. Angela
T3  - NSPW '12
AB  - Privacy research has not helped practitioners – who struggle to reconcile users' demands for information privacy with information security, legislation, information management and use – to improve privacy practice. Beginning with the principle that information security is necessary but not sufficient for privacy, we present an innovative layered framework - the Privacy Security Trust (PST) Framework - which integrates, in one model, the different activities practitioners must undertake for effective privacy practice. The PST Framework considers information security, information management and data protection legislation as privacy hygiene factors, representing the minimum processes for effective privacy practice. The framework also includes privacy influencers - developed from previous research in information security culture, information ethics and information culture - and privacy by design principles. The framework helps to deliver good privacy practice by providing: 1) a clear hierarchy of the activities needed for effective privacy practice; 2) delineation of information security and privacy; and 3) justification for placing data protection at the heart of those activities involved in maintaining information privacy. We present a proof-of-concept application of the PST Framework to an example technology – electricity smart meters.
C1  - New York, NY, USA
C3  - Proceedings of the 2012 New Security Paradigms Workshop
DA  - 2012///
PY  - 2012
DO  - 10.1145/2413296.2413305
SP  - 87
EP  - 104
PB  - Association for Computing Machinery
SN  - 978-1-4503-1794-8
UR  - https://doi.org/10.1145/2413296.2413305
KW  - framework
KW  - privacy
KW  - security
KW  - trust
ER  - 

TY  - JOUR
TI  - Touch-Dynamics Based Behavioural Biometrics on Mobile Devices – A Review from a Usability and Performance Perspective
AU  - Ellavarason, Elakkiya
AU  - Guest, Richard
AU  - Deravi, Farzin
AU  - Sanchez-Riello, Raul
AU  - Corsetti, Barbara
T2  - ACM Comput. Surv.
AB  - Over the past few years, there has been an exponential increase in the percentage of people owning and using a smart phone. These devices have sensor-rich touchscreens that can capture sensitive biometric features such as keystroke typing and finger-swiping patterns. Touch-dynamics based behavioural biometrics is a time-based assessment of how a user performs a particular touch task on a mobile device. Several performance-focused surveys already exist. In this article, building upon the existing reviews, we have examined studies on touch-dynamics based behavioural biometrics based on usability and its impact on authentication performance. We also emphasize the need for shifting the focus on usability during performance evaluations by presenting a consolidated list of usability and ergonomic-based factors that influence user interaction and cause performance variations. In this article, we report and review the usability evaluations: user acceptance studies and performance-based studies influencing the user interaction process on three specific touch-dynamics based modalities—signature, keystroke, and swipe. With regards to performance, we present a comparative analysis of error rates and accuracy of various research works undertaken. Additionally, we present a consolidated list of public datasets and discuss evolving vulnerabilities of touch-dynamics based behavioural biometrics, their adopted attack models, and their feasibility. Finally, we present our assessment of this domain's existing unresolved problems that could pave the way for future research.
DA  - 2020/12//
PY  - 2020
DO  - 10.1145/3394713
VL  - 53
IS  - 6
SN  - 0360-0300
UR  - https://doi.org/10.1145/3394713
KW  - Behavioural biometrics
KW  - dynamic signature
KW  - keystroke dynamics
KW  - mobile biometrics
KW  - performance
KW  - swipe
KW  - touch dynamics
KW  - usability
ER  - 

TY  - JOUR
TI  - A Perspective Analysis of Handwritten Signature Technology
AU  - Diaz, Moises
AU  - Ferrer, Miguel A.
AU  - Impedovo, Donato
AU  - Malik, Muhammad Imran
AU  - Pirlo, Giuseppe
AU  - Plamondon, Réjean
T2  - ACM Comput. Surv.
AB  - Handwritten signatures are biometric traits at the center of debate in the scientific community. Over the last 40 years, the interest in signature studies has grown steadily, having as its main reference the application of automatic signature verification, as previously published reviews in 1989, 2000, and 2008 bear witness. Ever since, and over the last 10 years, the application of handwritten signature technology has strongly evolved and much research has focused on the possibility of applying systems based on handwritten signature analysis and processing to a multitude of new fields. After several years of haphazard growth of this research area, it is time to assess its current developments for their applicability in order to draw a structured way forward. This perspective reports a systematic review of the last 10 years of the literature on handwritten signatures with respect to the new scenario, focusing on the most promising domains of research and trying to elicit possible future research directions in this subject.
DA  - 2019/01//
PY  - 2019
DO  - 10.1145/3274658
VL  - 51
IS  - 6
SN  - 0360-0300
UR  - https://doi.org/10.1145/3274658
KW  - automatic signature verification
KW  - biometrics
KW  - Offline and online handwritten signature
KW  - surveys
ER  - 

TY  - JOUR
TI  - "I Don't Know How to Help with That" - Learning from Limitations of Modern Conversational Agent Systems in Caregiving Networks
AU  - Zubatiy, Tamara
AU  - Mathur, Niharika
AU  - Heck, Larry
AU  - Vickers, Kayci L.
AU  - Rozga, Agata
AU  - Mynatt, Elizabeth D.
T2  - Proc. ACM Hum.-Comput. Interact.
AB  - While commercial conversational agents (CA) (i.e. Google assistant, Siri, Alexa) are widely used, these systems have limitations in error-handling, flexibility, personalization and overall dialogue management that are amplified in care coordination settings. In this paper, we synthesize and articulate these limitations through quantitative and qualitative analysis of 56 older adults interacting with a commercial CA deployed in their home for a 10 week period. We look at the CA as a compensatory technology in an older adult's care network. We argue that the CA limitations are rooted in the rigid cue-and-response style of task-oriented interactions common in CAs. We then propose a redesign for CA conversation flow to favor flexibility and personalization that is nonetheless viable within the limitations of current AI and machine learning technologies. We explore design tradeoffs to better support the usability needs of older adults compared to current design optimizations driven by efficiency and privacy goals.
DA  - 2023/10//
PY  - 2023
DO  - 10.1145/3610170
VL  - 7
IS  - CSCW2
UR  - https://doi.org/10.1145/3610170
KW  - audio interfaces
KW  - conversational agents
KW  - older adults
ER  - 

TY  - CHAP
TI  - Chapter 4: Content of the Cybersecurity Curricular Framework
T2  - Cybersecurity Curricula 2017: Curriculum Guidelines for Post-Secondary Degree Programs in Cybersecurity
CY  - New York, NY, USA
DA  - 2020///
PY  - 2020
PB  - Association for Computing Machinery
SN  - 978-1-4503-8919-8
ER  - 

TY  - JOUR
TI  - Trustworthy Artificial Intelligence: A Review
AU  - Kaur, Davinder
AU  - Uslu, Suleyman
AU  - Rittichier, Kaley J.
AU  - Durresi, Arjan
T2  - ACM Comput. Surv.
AB  - Artificial intelligence (AI) and algorithmic decision making are having a profound impact on our daily lives. These systems are vastly used in different high-stakes applications like healthcare, business, government, education, and justice, moving us toward a more algorithmic society. However, despite so many advantages of these systems, they sometimes directly or indirectly cause harm to the users and society. Therefore, it has become essential to make these systems safe, reliable, and trustworthy. Several requirements, such as fairness, explainability, accountability, reliability, and acceptance, have been proposed in this direction to make these systems trustworthy. This survey analyzes all of these different requirements through the lens of the literature. It provides an overview of different approaches that can help mitigate AI risks and increase trust and acceptance of the systems by utilizing the users and society. It also discusses existing strategies for validating and verifying these systems and the current standardization efforts for trustworthy AI. Finally, we present a holistic view of the recent advancements in trustworthy AI to help the interested researchers grasp the crucial facets of the topic efficiently and offer possible future research directions.
DA  - 2022/01//
PY  - 2022
DO  - 10.1145/3491209
VL  - 55
IS  - 2
SN  - 0360-0300
UR  - https://doi.org/10.1145/3491209
KW  - acceptance
KW  - accountability
KW  - Artificial intelligence
KW  - black-box problem
KW  - explainability
KW  - explainable AI
KW  - fairness
KW  - machine learning
KW  - privacy
KW  - trustworthy AI
ER  - 

TY  - JOUR
TI  - A Comprehensive Review of the State-of-the-Art on Security and Privacy Issues in Healthcare
AU  - López Martínez, Antonio
AU  - Gil Pérez, Manuel
AU  - Ruiz-Martínez, Antonio
T2  - ACM Comput. Surv.
AB  - Currently, healthcare is critical environment in our society, which attracts attention to malicious activities and has caused an important number of damaging attacks. In parallel, the recent advancements in technologies, computing systems, and wireless communications are changing healthcare environment by adding different improvements and complexity to it. This article reviews the current state of the literature and provides a holistic view of cybersecurity in healthcare. With this purpose in mind, the article enumerates the main stakeholders and architecture implemented in the healthcare environment, as well as the main security issues (threats, attacks, etc.) produced in healthcare. In this context, this work maps the threats collected with a widely used knowledge-based framework, MITRE ATT&amp;CK, building a contribution not seen so far. This article also enumerates the security mechanisms created to protect healthcare, identifying the principal research lines addressed in the literature, and listing the available public security-focused datasets used in machine-learning to provide security in the medical domain. To conclude, the research challenges that need to be addressed for future research works in this area are presented.
DA  - 2023/03//
PY  - 2023
DO  - 10.1145/3571156
VL  - 55
IS  - 12
SN  - 0360-0300
UR  - https://doi.org/10.1145/3571156
KW  - framework alignment
KW  - Healthcare datasets
KW  - review
KW  - safety
KW  - threat taxonomy
ER  - 

TY  - JOUR
TI  - Informing Children about Privacy: A Review and Assessment of Age-Appropriate Information Designs in Kids-Oriented F2P Video Games
AU  - Sas, Martin
AU  - Denoo, Maarten
AU  - Mühlberg, Jan Tobias
T2  - Proc. ACM Hum.-Comput. Interact.
AB  - With the rise of free-to-play (F2P) games, the profitability of video-gaming apps critically depends on the ability of developers to acquire, retain, and monetize large numbers of players. In this context, most game designers have no viable alternative than massively collecting players' personal data and monitoring their behavior to target them with personalized advertising and in-game purchases. Given the risks associated with such data practices, players, in particular children, need to be aware that a video game might compromise their privacy. Game designers should therefore ensure that players receive appropriate information about the data practices associated with their games. This might, however, be challenging, especially when the game is directed at children, given the complexity of privacy information and the limited literacy capacities of children and their parents. To answer game designers' need for comprehensive guidance regarding the communication of privacy information to children, we provide a survey of the age-appropriate information design strategies which been recommended by data protection authorities, children protection organizations and the relevant scientific literature. On this occasion, we also refer to illustrative examples of designs which can be considered good practices. Finally, by using an "evaluation matrix", we reviewed and assessed the implementation of those design strategies in nine F2P mobile games committed to following Google Play's Families Policies. Our findings show that, despite being child-oriented, the reviewed games largely fail at communicating privacy information in an age-appropriate way.
DA  - 2023/10//
PY  - 2023
DO  - 10.1145/3611036
VL  - 7
IS  - CHI PLAY
UR  - https://doi.org/10.1145/3611036
KW  - Age-Appropriate Design
KW  - Children's Privacy Literacy
KW  - Children's Rights
KW  - Dark Patterns
KW  - Data Protection
KW  - Gaming
KW  - GDPR
KW  - Privacy Notice
KW  - Transparency
KW  - Video Games
ER  - 

TY  - JOUR
TI  - "Oh Yes! Over-Preparing for Meetings is My Jam :)": The Gendered Experiences of System Administrators
AU  - Kaur, Mannat
AU  - Sri Ramulu, Harshini
AU  - Acar, Yasemin
AU  - Fiebig, Tobias
T2  - Proc. ACM Hum.-Comput. Interact.
AB  - In the system and network administration domain, gender diversity remains a distant target. The experiences and perspectives of sysadmins who belong to marginalized genders (non cis-men) are not well understood beyond the fact that sysadmin work environments are generally not equitable. We address this knowledge gap in our study by focusing on the ways in which sysadmins from marginalized genders manage their work in men-dominated sysadmin work spaces and by understanding what an inclusive workplace would look like. Using a feminist research approach, we engaged with a group of 16 sysadmins who are not cis-men via six online focus groups. We found that managing the impact of gender identity in the sysadmin workplace means demonstrating excellence and going above and beyond in system administration tasks, and also requires performing additional care work not expected from cis men. Furthermore, our participants handle additional layers of work due to gender considerations and to actively find community in the workplace. We found that sysadmins manage by going above and beyond in their tasks, performing care work and doing extra layers of work because of gender considerations, and finding community in the workplace. To mitigate this additional workload, we recommend more care for care work. For future research, we recommend the use of feminist lenses when studying sysadmin work in order to provide more equitable solutions that ultimately contribute to improving system security by fostering a just workplace.
DA  - 2023/04//
PY  - 2023
DO  - 10.1145/3579617
VL  - 7
IS  - CSCW1
UR  - https://doi.org/10.1145/3579617
KW  - care work
KW  - feminism
KW  - feminist approach
KW  - gender
KW  - human factors
KW  - sysadmin
KW  - system administration
ER  - 

TY  - JOUR
TI  - Lean Privacy Review: Collecting Users’ Privacy Concerns of Data Practices at a Low Cost
AU  - Jin, Haojian
AU  - Shen, Hong
AU  - Jain, Mayank
AU  - Kumar, Swarun
AU  - Hong, Jason I.
T2  - ACM Trans. Comput.-Hum. Interact.
AB  - Today, industry practitioners (e.g., data scientists, developers, product managers) rely on formal privacy reviews (a combination of user interviews, privacy risk assessments, etc.) in identifying potential customer acceptance issues with their organization’s data practices. However, this process is slow and expensive, and practitioners often have to make ad-hoc privacy-related decisions with little actual feedback from users. We introduce Lean Privacy Review (LPR), a fast, cheap, and easy-to-access method to help practitioners collect direct feedback from users through the proxy of crowd workers in the early stages of design. LPR takes a proposed data practice, quickly breaks it down into smaller parts, generates a set of questionnaire surveys, solicits users’ opinions, and summarizes those opinions in a compact form for practitioners to use. By doing so, LPR can help uncover the range and magnitude of different privacy concerns actual people have at a small fraction of the cost and wait-time for a formal review. We evaluated LPR using 12 real-world data practices with 240 crowd users and 24 data practitioners. Our results show that (1) the discovery of privacy concerns saturates as the number of evaluators exceeds 14 participants, which takes around 5.5 hours to complete (i.e., latency) and costs 3.7 hours of total crowd work ( $80 in our experiments); and (2) LPR finds 89% of privacy concerns identified by data practitioners as well as 139% additional privacy concerns that practitioners are not aware of, at a 6% estimated false alarm rate.
DA  - 2021/08//
PY  - 2021
DO  - 10.1145/3463910
VL  - 28
IS  - 5
SN  - 1073-0516
UR  - https://doi.org/10.1145/3463910
KW  - data ethics
KW  - heuristic evaluation
KW  - Privacy concern
KW  - privacy engineering
ER  - 

TY  - BOOK
TI  - MSR4P&amp;S 2022: Proceedings of the 1st International Workshop on Mining Software Repositories Applications for Privacy and Security
AB  - On behalf of the Program Committee, we are pleased to present the proceedings of the 1st International Workshop on Mining Software Repositories for Privacy and Security (MSR4P&amp;S 2022). MSR4P&amp;S is co-located with the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE). This year, because of the Covid-19 pandemic, MSR4P&amp;S (as part of ESEC/FSE) is held virtually with an adapted program that will bring together international researchers to exchange ideas, share experiences, investigate problems, and propose promising solutions concerning the application of Mining Software Repositories (MSR) to investigate the different stages of privacy and security. The workshop topics cover a wide range of MSR applications for cybersecurity research, including empirical and mixed-method approaches, as well as datasets and tools.
CY  - New York, NY, USA
DA  - 2022///
PY  - 2022
PB  - Association for Computing Machinery
SN  - 978-1-4503-9457-4
ER  - 

TY  - BOOK
TI  - Cybersecurity Curricula 2017: Curriculum Guidelines for Post-Secondary Degree Programs in Cybersecurity
AU  - Education, Joint Task Force on Cybersecurity
CY  - New York, NY, USA
DA  - 2018///
PY  - 2018
PB  - Association for Computing Machinery
SN  - 978-1-4503-8919-8
ER  - 

TY  - BOOK
TI  - UKICER '22: Proceedings of the 2022 Conference on United Kingdom &amp; Ireland Computing Education Research
CY  - New York, NY, USA
DA  - 2022///
PY  - 2022
PB  - Association for Computing Machinery
SN  - 978-1-4503-9742-1
ER  - 

TY  - BOOK
TI  - CHIGREECE '23: Proceedings of the 2nd International Conference of the ACM Greek SIGCHI Chapter
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 9798400708886
ER  - 

TY  - BOOK
TI  - EICC '23: Proceedings of the 2023 European Interdisciplinary Cybersecurity Conference
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 978-1-4503-9829-9
ER  - 

TY  - BOOK
TI  - SBQS '22: Proceedings of the XXI Brazilian Symposium on Software Quality
CY  - New York, NY, USA
DA  - 2022///
PY  - 2022
PB  - Association for Computing Machinery
SN  - 978-1-4503-9999-9
ER  - 

TY  - BOOK
TI  - AIES '23: Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 9798400702310
ER  - 

TY  - BOOK
TI  - IDC '23: Proceedings of the 22nd Annual ACM Interaction Design and Children Conference
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 9798400701313
ER  - 

TY  - BOOK
TI  - ASSETS '22: Proceedings of the 24th International ACM SIGACCESS Conference on Computers and Accessibility
CY  - New York, NY, USA
DA  - 2022///
PY  - 2022
PB  - Association for Computing Machinery
SN  - 978-1-4503-9258-7
ER  - 

TY  - BOOK
TI  - WWW '19: Companion Proceedings of The 2019 World Wide Web Conference
AB  - It is our great pleasure to welcome you to <i>The Web Conference 2019</i>. The Web Conference is the premier venue focused on understanding the current state and the evolution of the Web through the lens of computer science, computational social science, economics, policy, and many other disciplines. The 2019 edition of the conference is a reflection point as we celebrate the 30th anniversary of the Web.
CY  - New York, NY, USA
DA  - 2019///
PY  - 2019
PB  - Association for Computing Machinery
SN  - 978-1-4503-6675-5
ER  - 

TY  - BOOK
TI  - CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
CY  - New York, NY, USA
DA  - 2021///
PY  - 2021
PB  - Association for Computing Machinery
SN  - 978-1-4503-8096-6
ER  - 

